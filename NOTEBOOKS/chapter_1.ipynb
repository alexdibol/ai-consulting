{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPNWYQJ18j0l3VtgbDraiPa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**AI CONSULTING CHAPTER 1: CHATBOTS**\n","\n","---"],"metadata":{"id":"cnQK8yTVMAhC"}},{"cell_type":"markdown","source":["##0.REFERENCE"],"metadata":{"id":"tw2-7uYoMGHg"}},{"cell_type":"markdown","source":["https://claude.ai/share/52d6369b-8859-493e-b640-6afe72ddfc15"],"metadata":{"id":"axSMA0YpNnYX"}},{"cell_type":"markdown","source":["##1.CONTEXT"],"metadata":{"id":"4LFo5LtiMIff"}},{"cell_type":"markdown","source":["**Introduction: AI-Assisted Consulting with Governance-First Design**\n","\n","**The Promise and the Peril**\n","\n","Artificial intelligence has arrived in professional services, and its capabilities are remarkable. Large language models like Claude can draft emails in seconds, structure complex memos in minutes, and generate meeting agendas that would have taken hours of manual work. For management consultants and corporate strategy professionals, this represents a dramatic productivity opportunity. A partner reviewing client correspondence, an associate preparing board materials, or an internal strategist developing transformation workplans can now delegate substantial drafting work to AI assistants.\n","\n","Yet this very capability creates profound risks. When you ask ChatGPT or Claude to \"draft an email to the client about our market entry analysis,\" what happens to the confidential information you provide? When the AI generates impressive-sounding statistics or market insights, how do you know they're accurate rather than plausible fabrications? When you copy that AI-generated paragraph directly into a client deliverable, who owns the professional liability if it's wrong? And when your firm's quality assurance team asks how a particular recommendation was developed, can you provide an audit trail proving what the AI did versus what you contributed?\n","\n","These questions distinguish casual chatbot use from professional-grade AI deployment. Typing prompts into a web interface and copying results into your documents might feel productive, but it creates governance gaps that can undermine your credibility, expose confidential information, introduce errors into critical work products, and leave you unable to explain or defend your process when questioned.\n","\n","**What Makes This Notebook Different**\n","\n","This notebook teaches you to use AI for consulting work the right way‚Äîwith governance, traceability, and accountability built into every step. It represents what we call a \"governance-first\" approach to AI adoption, where controls and capabilities advance together rather than retrofitting safeguards onto uncontrolled experimentation.\n","\n","The fundamental difference from casual chatbot use lies in five design principles that permeate every cell of this notebook.\n","\n","First, confidentiality protection is not optional or assumed‚Äîit's enforced through explicit redaction utilities that strip sensitive information before it ever reaches the AI system. When you work with client data, you're operating under non-disclosure agreements, regulatory confidentiality requirements, and professional obligations. This notebook treats that reality seriously by building automatic detection and removal of emails, phone numbers, deal values, client names, and other private information. More importantly, it warns you when patterns suggest sensitive content that automated systems might miss, forcing you to manually review before proceeding. Casual chatbot use relies on you remembering to be careful. This notebook makes carefulness structural.\n","\n","Second, outputs are explicitly marked as unverified drafts requiring human review. When you get a response from a casual chatbot, it arrives with no metadata, no warnings, and no systematic flagging of what might be wrong. The polished, confident tone encourages treating it as authoritative. This notebook does the opposite. Every single AI output includes structured fields separating facts provided from assumptions made, listing open questions that need answers, identifying specific risks like potential hallucinations or missing data, and carrying a verification status that always reads \"Not verified.\" This format forces you to engage critically with the content rather than passively accepting it.\n","\n","Third, every interaction generates a permanent audit trail. Casual chatbot conversations disappear when you close the browser or scroll past them in your history. This notebook creates timestamped logs with cryptographic fingerprints proving what you asked and what the AI returned, without storing the actual confidential content. If someone later questions how a deliverable was created, you have verifiable evidence. If your firm implements AI usage policies requiring documentation, you have the records. If a client or regulator asks about your process, you can demonstrate responsible practices.\n","\n","Fourth, the notebook separates AI capability levels and enforces boundaries. This is Chapter One, Level One‚Äîchatbots for drafting support only. You make one explicit request, the AI generates one response, and you review it. There are no autonomous agents running multiple steps without your oversight, no automated web searches pulling in unvetted information, no multi-turn conversations where context and accountability become murky. This clear boundary prevents the subtle drift where \"help me draft this email\" becomes \"analyze this situation and tell me what to do,\" crossing from drafting support into decision-making that should remain human-owned.\n","\n","Fifth, the notebook embeds quality controls that catch common failure modes. It validates that AI responses match expected structure rather than accepting whatever format emerges. It automatically scans drafts for numbers not present in your source facts, flagging potential hallucinations. It detects phrases like \"we analyzed\" or \"our research shows\" that falsely imply completed work, catching decision laundering before it enters deliverables. It notices when you've asked for recommendations rather than neutral drafting, flagging scope creep. These controls operate automatically, creating safety nets for moments when you're rushing or distracted.\n","\n","**Your Learning Journey**\n","\n","This notebook walks you through ten carefully designed cells that build from foundations to practical application. You'll start by understanding the Level One safety envelope and what governance artifacts get created. You'll set up your computational environment and API access. You'll see confidentiality protection in action through redaction demonstrations. You'll examine the quality control wrapper that validates every AI interaction. You'll learn the document lifecycle functions that track assumptions, verification needs, and approval workflows.\n","\n","Then you'll experience four realistic consulting scenarios‚Äîmarket entry analysis, cost transformation, capital allocation decisions, and operating model redesign. For each scenario, you'll see how the governance infrastructure handles typical drafting tasks like client emails, memo shells, workplan narratives, meeting agendas, and stakeholder updates. You'll observe how the system flags missing information, identifies assumptions requiring validation, and prevents overconfident claims unsupported by facts.\n","\n","Finally, you'll try it yourself in a hands-on exercise where you provide your own consulting scenario and request a deliverable. You'll experience the redaction process, see what gets flagged for manual review, and receive a complete governance package for your draft. By the end, you'll understand not just how to use AI for drafting, but how to do so in a way that maintains professional standards, protects confidential information, and creates defensible documentation of your process.\n","\n","**Why This Matters for Your Career**\n","\n","As AI capabilities expand rapidly, your profession will increasingly differentiate between practitioners who use these tools responsibly and those who don't. Clients will ask whether your firm has AI governance policies. Regulators will scrutinize how confidential data flows through AI systems. Quality assurance teams will demand audit trails showing human oversight of AI outputs. Professional liability insurers will inquire about your controls and documentation practices.\n","\n","Learning to use AI with governance-first principles positions you as someone who understands both the technology and the professional obligations surrounding it. You're not just faster at drafting‚Äîyou're demonstrably careful, transparent, and accountable. These qualities become competitive advantages as AI becomes ubiquitous and the market begins distinguishing competent users from reckless ones.\n","\n","More fundamentally, this approach protects you from the subtle erosion of professional judgment that can occur when powerful AI tools enter your workflow. By forcing explicit separation of facts from assumptions, requiring verification planning for every claim, and maintaining clear boundaries between drafting support and decision-making, you preserve the critical thinking that makes you valuable as a consultant. The AI handles the mechanical work of turning bullet points into prose, but you remain firmly in control of strategy, judgment, and accountability.\n","\n","**Ready to Begin**\n","\n","The notebook ahead represents hundreds of hours of careful design balancing capability with control. It embodies lessons learned from real consulting engagements about what goes wrong when AI is deployed without adequate governance, and what works when proper safeguards are in place. You're not learning to use AI like a consumer chatbot‚Äîyou're learning to integrate it into professional practice the way serious organizations will require as this technology matures.\n","\n","Take your time with each cell. Read the explanations carefully. Run the demonstrations. Try the hands-on exercise. And most importantly, internalize the governance mindset that capability and control must advance together. This is how responsible AI adoption happens in high-stakes professional services work."],"metadata":{"id":"6n-x0MLbMKUs"}},{"cell_type":"markdown","source":["##2.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"HzSSYRQ0MKs8"}},{"cell_type":"code","source":["\n","# Cell 2\n","# Type: Code\n","# Goal: Install + Imports + Run Directory\n","# Output: Print run directory path and deliverables path\n","\n","# Install Anthropic SDK\n","!pip install -q anthropic\n","\n","# Standard library imports\n","import json\n","import os\n","import re\n","import hashlib\n","import platform\n","import textwrap\n","from pathlib import Path\n","from datetime import datetime, timezone\n","import subprocess\n","import uuid\n","\n","# Create unique run directory\n","timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n","short_id = str(uuid.uuid4())[:8]\n","run_id = f\"run_{timestamp}_{short_id}\"\n","\n","base_dir = Path(\"/content/ai_consulting_ch1_runs\")\n","run_dir = base_dir / run_id\n","deliverables_dir = run_dir / \"deliverables\"\n","\n","# Create directories\n","run_dir.mkdir(parents=True, exist_ok=True)\n","deliverables_dir.mkdir(exist_ok=True)\n","\n","print(\"=\" * 70)\n","print(\"ENVIRONMENT SETUP COMPLETE\")\n","print(\"=\" * 70)\n","print(f\"Run Directory:        {run_dir}\")\n","print(f\"Deliverables Folder:  {deliverables_dir}\")\n","print(f\"Run ID:               {run_id}\")\n","print(\"=\" * 70)"],"metadata":{"id":"TOYUwL9vMKKC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768824822758,"user_tz":360,"elapsed":15788,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"f89cb6a0-c88a-4004-8d5b-fcb80d4d0adb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/390.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m389.1/390.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h======================================================================\n","ENVIRONMENT SETUP COMPLETE\n","======================================================================\n","Run Directory:        /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781\n","Deliverables Folder:  /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781/deliverables\n","Run ID:               run_20260119_121343_14b2e781\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##3.API AND CLIENT INITIALIZATION"],"metadata":{"id":"STtjBQgwMNHi"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"ShWjt_vyMO17"}},{"cell_type":"markdown","source":["\n","\n","**What this cell does:**\n","\n","This cell establishes the connection between your notebook and Anthropic's Claude AI service. Think of it like logging into a secure system‚Äîyou need proper credentials to access the tool.\n","\n","**Why you need this:**\n","\n","Without this connection, the notebook cannot send your drafting requests to Claude or receive AI-generated outputs. This is the foundational step that enables everything else in the workflow.\n","\n","**How it works in practice:**\n","\n","When you run consulting projects, you often need to access specialized tools or databases. Similarly, to use Claude for drafting support, you need an API key‚Äîessentially a secure password that proves you have permission to use Anthropic's service.\n","\n","The cell retrieves your API key from Google Colab's secure storage system (called \"Secrets\"). This is intentionally designed to keep your credentials safe‚Äîthey're never exposed in the notebook code itself, preventing accidental sharing of sensitive access credentials.\n","\n","Once the key is loaded, the cell initializes a \"client\" object. Think of this as opening a dedicated communication channel to Claude. Every time you need Claude to draft an email, memo, or agenda later in the notebook, you'll use this client to send your request.\n","\n","**Important details:**\n","\n","The cell also specifies which version of Claude you're using: claude-sonnet-4-5-20250929. This matters for governance and reproducibility. Just as you'd document which version of Excel or financial modeling software you used for analysis, documenting the AI model version ensures others can understand and potentially reproduce your work.\n","\n","The parameters are also set here: temperature of 0.2 (which controls creativity‚Äîlower means more consistent, focused outputs) and max_tokens of 4128 (which sets the maximum length of responses). These are governance choices, not technical details‚Äîthey reflect your preference for reliable, professional drafting over creative experimentation.\n","\n","**If something goes wrong:**\n","\n","The cell includes clear error handling. If your API key isn't found, you'll see friendly instructions explaining exactly how to add it to Colab Secrets. This prevents confusion and wasted time troubleshooting.\n","\n","**The governance angle:**\n","\n","Notice the cell prints confirmation of what's loaded‚Äîthe model name, parameters, and whether the key was successfully retrieved. This transparency is essential for audit trails. Anyone reviewing your work later can see exactly which AI system was used and how it was configured."],"metadata":{"id":"n_uMwdv8MRcU"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"Xml9f9GoMR7J"}},{"cell_type":"code","source":["# Cell 3\n","# Type: Code\n","# Goal: API Key + Client Initialization (Anthropic)\n","# Output: Print API key status and model name\n","\n","import anthropic\n","from google.colab import userdata\n","\n","# Load API key from Colab Secrets\n","try:\n","    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n","    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n","    client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n","    MODEL = \"claude-sonnet-4-5-20250929\"\n","    api_key_loaded = True\n","except Exception as e:\n","    api_key_loaded = False\n","    print(\"‚ùå ERROR: Could not load ANTHROPIC_API_KEY from Colab Secrets\")\n","    print(\"‚û°Ô∏è  Instructions:\")\n","    print(\"   1. Click the üîë key icon in the left sidebar (Secrets)\")\n","    print(\"   2. Add a new secret named: ANTHROPIC_API_KEY\")\n","    print(\"   3. Paste your Anthropic API key as the value\")\n","    print(\"   4. Re-run this cell\")\n","    raise e\n","\n","print(\"=\" * 70)\n","print(\"ANTHROPIC API CLIENT INITIALIZED\")\n","print(\"=\" * 70)\n","print(f\"API Key Loaded:  {'‚úÖ Yes' if api_key_loaded else '‚ùå No'}\")\n","print(f\"Model:           {MODEL}\")\n","print(f\"Max Tokens:      4128\")\n","print(f\"Temperature:     0.2\")\n","print(\"=\" * 70)"],"metadata":{"id":"UExynb0iMJwm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768825057501,"user_tz":360,"elapsed":338,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"70428dd8-e08c-4ff9-8d23-b5a011bd75d4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","ANTHROPIC API CLIENT INITIALIZED\n","======================================================================\n","API Key Loaded:  ‚úÖ Yes\n","Model:           claude-sonnet-4-5-20250929\n","Max Tokens:      4128\n","Temperature:     0.2\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##4.GOVERNANCE ARTIFACTS"],"metadata":{"id":"zSjFjeDuMaZn"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"6OWXlpZoMcHa"}},{"cell_type":"markdown","source":["\n","\n","**What this cell does:**\n","\n","This cell creates the infrastructure for tracking and documenting everything that happens during your AI-assisted drafting session. Think of it as setting up a comprehensive filing system before starting a consulting engagement‚Äîyou're preparing to capture every important detail for future reference and accountability.\n","\n","**Why governance matters in consulting:**\n","\n","In professional consulting work, you need clear documentation of how you arrived at recommendations, what assumptions you made, and what still needs verification. When AI enters the picture, this documentation becomes even more critical. Clients, regulators, and your own quality assurance teams need to understand what the AI did, what it was told, and how outputs were generated.\n","\n","**The artifacts created:**\n","\n","The cell generates six essential governance files, each serving a specific purpose. The run manifest acts like a project cover sheet‚Äîit records when this session started, which AI model was used, what settings were applied, and creates a unique identifier for this specific run. This is your proof that you can distinguish this Tuesday's draft from last Thursday's version.\n","\n","The prompts log functions as a detailed activity register. Every time you ask Claude to draft something, this log records a secure fingerprint of what you asked and what you received. Importantly, it stores cryptographic hashes rather than raw text‚Äîprotecting client confidentiality while maintaining traceability. If someone later questions whether a draft truly came from the AI or was human-edited, you have verifiable proof.\n","\n","The risk log accumulates every concern flagged during the session‚Äîmissing information, potential hallucinations, scope creep beyond drafting into decision-making. This mirrors how you'd track project risks in traditional consulting.\n","\n","The verification register maintains a running list of claims that need human fact-checking before use. If the AI draft mentions market share figures or regulatory timelines, those get logged here as requiring verification.\n","\n","**The reproducibility angle:**\n","\n","The cell also captures your computational environment‚Äîwhich version of Python, which libraries were installed. This is like documenting which version of Excel you used for financial models. If someone needs to recreate or audit your work months later, they'll know the exact technical context.\n","\n","**Configuration hash explained:**\n","\n","Perhaps most importantly, the cell generates a configuration hash‚Äîa unique fingerprint of your AI settings. If you run this notebook twice with identical settings, you'll get the same hash, proving consistency. If someone changes the temperature or model version, the hash changes, immediately flagging that outputs may differ.\n","\n","**Why this matters for your career:**\n","\n","As AI becomes embedded in professional services, your ability to demonstrate responsible, traceable, auditable use of these tools will differentiate you from colleagues who treat AI as a black box."],"metadata":{"id":"XdRc9-nEMeIF"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"GvnsRIc6Mefx"}},{"cell_type":"code","source":["# Cell 4\n","# Type: Code\n","# Goal: Governance Artifacts - Manifest + Logging Utilities\n","# Output: Print paths of all created governance files + config_hash\n","\n","def now_iso():\n","    \"\"\"Return current timestamp in ISO format (UTC)\"\"\"\n","    return datetime.now(timezone.utc).isoformat()\n","\n","def sha256_text(s):\n","    \"\"\"Return SHA256 hash of text\"\"\"\n","    return hashlib.sha256(s.encode('utf-8')).hexdigest()\n","\n","def write_json(path, obj):\n","    \"\"\"Write JSON object to file\"\"\"\n","    with open(path, 'w', encoding='utf-8') as f:\n","        json.dump(obj, f, indent=2, ensure_ascii=False)\n","\n","def read_json(path):\n","    \"\"\"Read JSON file with safe defaults\"\"\"\n","    try:\n","        with open(path, 'r', encoding='utf-8') as f:\n","            return json.load(f)\n","    except FileNotFoundError:\n","        return None\n","    except json.JSONDecodeError:\n","        return None\n","\n","def append_jsonl(path, record):\n","    \"\"\"Append a JSON record to a JSONL file\"\"\"\n","    with open(path, 'a', encoding='utf-8') as f:\n","        f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n","\n","def get_env_fingerprint():\n","    \"\"\"Get environment fingerprint (Python version, platform, pip freeze)\"\"\"\n","    pip_freeze_path = run_dir / \"pip_freeze.txt\"\n","    try:\n","        result = subprocess.run(['pip', 'freeze'], capture_output=True, text=True, timeout=10)\n","        pip_freeze_path.write_text(result.stdout)\n","    except Exception as e:\n","        pip_freeze_path.write_text(f\"Error capturing pip freeze: {e}\")\n","\n","    return {\n","        \"python_version\": platform.python_version(),\n","        \"platform\": platform.platform(),\n","        \"pip_freeze_file\": str(pip_freeze_path)\n","    }\n","\n","def stable_config_hash(obj):\n","    \"\"\"Create stable hash of config object (canonical JSON)\"\"\"\n","    canonical = json.dumps(obj, sort_keys=True, ensure_ascii=False)\n","    return sha256_text(canonical)\n","\n","# Get environment fingerprint\n","env_fingerprint = get_env_fingerprint()\n","\n","# Create run manifest\n","run_manifest = {\n","    \"run_id\": run_id,\n","    \"timestamp\": now_iso(),\n","    \"chapter\": \"1\",\n","    \"level\": \"Chatbots\",\n","    \"model\": MODEL,\n","    \"params\": {\n","        \"temperature\": 0.2,\n","        \"max_tokens\": 4128\n","    },\n","    \"env_fingerprint\": env_fingerprint,\n","    \"notebook_purpose\": \"Level 1 consulting drafting with governance artifacts (Not verified)\",\n","    \"config_hash\": \"\"  # Will be filled after computing\n","}\n","\n","# Compute config hash\n","config_obj = {\n","    \"model\": run_manifest[\"model\"],\n","    \"params\": run_manifest[\"params\"]\n","}\n","config_hash = stable_config_hash(config_obj)\n","run_manifest[\"config_hash\"] = config_hash\n","\n","# Write manifest\n","manifest_path = run_dir / \"run_manifest.json\"\n","write_json(manifest_path, run_manifest)\n","\n","# Initialize empty governance files\n","prompts_log_path = run_dir / \"prompts_log.jsonl\"\n","prompts_log_path.touch()\n","\n","risk_log_path = run_dir / \"risk_log.json\"\n","write_json(risk_log_path, {\"risks\": []})\n","\n","verification_register_path = run_dir / \"verification_register.json\"\n","write_json(verification_register_path, {\"items\": []})\n","\n","change_log_path = run_dir / \"change_log.json\"\n","write_json(change_log_path, {\"changes\": []})\n","\n","approvals_log_path = run_dir / \"approvals_log.json\"\n","write_json(approvals_log_path, {\"approvals\": []})\n","\n","print(\"=\" * 70)\n","print(\"GOVERNANCE ARTIFACTS INITIALIZED\")\n","print(\"=\" * 70)\n","print(f\"‚úÖ run_manifest.json          ‚Üí {manifest_path}\")\n","print(f\"‚úÖ prompts_log.jsonl          ‚Üí {prompts_log_path}\")\n","print(f\"‚úÖ risk_log.json              ‚Üí {risk_log_path}\")\n","print(f\"‚úÖ verification_register.json ‚Üí {verification_register_path}\")\n","print(f\"‚úÖ change_log.json            ‚Üí {change_log_path}\")\n","print(f\"‚úÖ approvals_log.json         ‚Üí {approvals_log_path}\")\n","print(\"=\" * 70)\n","print(f\"Config Hash: {config_hash}\")\n","print(\"=\" * 70)\n"],"metadata":{"id":"AY_6OY4SMbAv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768825122564,"user_tz":360,"elapsed":1715,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"dcc71be1-451e-41e9-db33-ca99a68149d6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","GOVERNANCE ARTIFACTS INITIALIZED\n","======================================================================\n","‚úÖ run_manifest.json          ‚Üí /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781/run_manifest.json\n","‚úÖ prompts_log.jsonl          ‚Üí /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781/prompts_log.jsonl\n","‚úÖ risk_log.json              ‚Üí /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781/risk_log.json\n","‚úÖ verification_register.json ‚Üí /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781/verification_register.json\n","‚úÖ change_log.json            ‚Üí /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781/change_log.json\n","‚úÖ approvals_log.json         ‚Üí /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781/approvals_log.json\n","======================================================================\n","Config Hash: b97d036cde0cc27c58b3804cd947018964f1d2f764a8358191303cb5dbcc3b76\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##5.PROTECTING CLIENT CONFIDENTIALITY"],"metadata":{"id":"aFfOfCZmMgx4"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"tIlOMU-SMjni"}},{"cell_type":"markdown","source":["\n","\n","**What this cell does:**\n","\n","This cell builds protective barriers around sensitive information before it ever reaches the AI system. Think of it as a confidentiality firewall‚Äîautomatically detecting and removing client names, financial figures, contact details, and other private information from text before you send drafting requests to Claude.\n","\n","**Why this is non-negotiable:**\n","\n","In consulting and corporate strategy work, you routinely handle information covered by non-disclosure agreements, regulatory confidentiality requirements, or competitive sensitivity concerns. The moment you paste client data into an external AI system, you potentially breach those obligations. This cell addresses that risk head-on.\n","\n","**How the redaction works:**\n","\n","The cell includes a sophisticated redaction function that scans text for common patterns of sensitive information. It identifies and masks email addresses, phone numbers, government identification numbers, currency amounts, and bracketed placeholders like client company names. When it finds these patterns, it replaces them with generic labels like EMAIL REDACTED or PHONE REDACTED.\n","\n","This is imperfect by design‚Äîautomated redaction cannot catch everything, which is why the cell also flags warnings. If it detects multiple capitalized words that might be person names, or terms like \"Inc\" or \"LLC\" that suggest company names, it alerts you to manually review those sections. The system errs on the side of caution.\n","\n","**The minimum necessary principle:**\n","\n","Beyond just redaction, this cell implements what privacy professionals call the \"minimum necessary\" standard. Just because you could share an entire client presentation with the AI doesn't mean you should. The cell encourages you to extract only the essential facts needed for drafting‚Äîperhaps three key sentences rather than five pages of background.\n","\n","This serves two purposes. First, it minimizes confidentiality exposure. Second, it actually improves AI output quality. When you force yourself to distill complex situations down to core facts, you clarify your own thinking and give the AI more focused instructions.\n","\n","**The demonstration:**\n","\n","The cell includes a practical demonstration using fake but realistic sensitive data‚Äîclient names, deal values, contact information. When you run this cell, you see before-and-after comparisons showing exactly what gets masked. This builds your confidence in the protection mechanisms and helps you understand what still requires manual review.\n","\n","**Consulting governance culture:**\n","\n","This cell embodies a critical mindset shift. In traditional consulting, you controlled confidentiality by controlling who saw documents‚Äîonly sharing within your firm or with authorized client personnel. With AI tools, you're potentially sending information to external systems. The cell makes explicit that you must sanitize first, verify protection, and maintain records of what was removed.\n","\n","**What gets logged:**\n","\n","Importantly, the cell tracks what it removed in each redaction pass, creating an audit trail of the protection process itself."],"metadata":{"id":"ksHvcArXMxMR"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"x7z8cMnQMx3g"}},{"cell_type":"code","source":["\n","# Cell 5\n","# Type: Code\n","# Goal: Confidentiality + Client Sensitivity Utilities\n","# Output: Demo redact() on fake sensitive string\n","\n","def redact(text):\n","    \"\"\"\n","    Redact sensitive information from text.\n","    Returns: (redacted_text, removed_fields_list)\n","    \"\"\"\n","    removed = []\n","    original = text\n","\n","    # Email addresses\n","    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n","    if re.search(email_pattern, text):\n","        text = re.sub(email_pattern, '[EMAIL_REDACTED]', text)\n","        removed.append(\"email_addresses\")\n","\n","    # Phone numbers (various formats)\n","    phone_patterns = [\n","        r'\\b\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b',\n","        r'\\b\\(\\d{3}\\)\\s*\\d{3}[-.\\s]?\\d{4}\\b',\n","        r'\\+\\d{1,3}[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,4}[-.\\s]?\\d{1,9}\\b'\n","    ]\n","    for pattern in phone_patterns:\n","        if re.search(pattern, text):\n","            text = re.sub(pattern, '[PHONE_REDACTED]', text)\n","            if \"phone_numbers\" not in removed:\n","                removed.append(\"phone_numbers\")\n","\n","    # Government IDs (SSN-like patterns)\n","    ssn_pattern = r'\\b\\d{3}-\\d{2}-\\d{4}\\b'\n","    if re.search(ssn_pattern, text):\n","        text = re.sub(ssn_pattern, '[ID_REDACTED]', text)\n","        removed.append(\"government_ids\")\n","\n","    # Currency amounts (preserve structure but flag)\n","    currency_pattern = r'\\$\\s?\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?(?:\\s?(?:million|billion|M|B|K))?'\n","    if re.search(currency_pattern, text, re.IGNORECASE):\n","        # Note: We keep amounts but flag them as potentially sensitive\n","        if \"currency_amounts\" not in removed:\n","            removed.append(\"currency_amounts_present\")\n","\n","    # Bracketed placeholders like [CLIENT], [COMPANY]\n","    bracket_pattern = r'\\[([A-Z_]+)\\]'\n","    brackets = re.findall(bracket_pattern, text)\n","    if brackets:\n","        text = re.sub(bracket_pattern, '[REDACTED]', text)\n","        removed.append(f\"bracketed_tokens ({len(brackets)})\")\n","\n","    # Warning for potential person names (simple heuristic: capitalized words)\n","    # This is imperfect but better than nothing\n","    capitalized_words = re.findall(r'\\b[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*\\b', text)\n","    if len(capitalized_words) > 3:  # Likely contains names\n","        removed.append(\"potential_person_names_detected (manual review required)\")\n","\n","    # Warning for potential company names\n","    company_indicators = ['Inc.', 'LLC', 'Ltd.', 'Corp.', 'Corporation', 'Company']\n","    for indicator in company_indicators:\n","        if indicator in text:\n","            removed.append(\"potential_company_names_detected (manual review required)\")\n","            break\n","\n","    return text, removed\n","\n","def build_minimum_necessary(raw_text):\n","    \"\"\"\n","    Extract minimum necessary facts from raw text.\n","    Returns: {sanitized_facts: [...], removed_fields: [...], redacted_preview: \"...\"}\n","    \"\"\"\n","    redacted_text, removed_fields = redact(raw_text)\n","\n","    # Split into sentences and take first 3 as \"sanitized facts\"\n","    sentences = [s.strip() for s in redacted_text.split('.') if s.strip()]\n","    sanitized_facts = sentences[:3] if sentences else [\"No specific facts provided\"]\n","\n","    # Create short preview\n","    preview = redacted_text[:200] + \"...\" if len(redacted_text) > 200 else redacted_text\n","\n","    return {\n","        \"sanitized_facts\": sanitized_facts,\n","        \"removed_fields\": removed_fields,\n","        \"redacted_preview\": preview\n","    }\n","\n","def consulting_guardrails():\n","    \"\"\"Return standard consulting governance warnings to prepend to prompts\"\"\"\n","    return \"\"\"\n","CRITICAL INSTRUCTIONS:\n","- Do NOT invent facts, statistics, benchmarks, or citations\n","- ALWAYS separate: facts provided vs assumptions made\n","- Do NOT provide recommendations or advice; draft neutral language only\n","- ALWAYS label output as \"Not verified\"\n","- If information is missing, add to open_questions\n","- Flag risks: hallucination, missing_facts, decision_laundering, scope_creep\n","\"\"\"\n","\n","# Demo redaction\n","demo_text = \"\"\"\n","Our client John Smith (john.smith@acmecorp.com, 555-123-4567) is considering\n","a $50 million acquisition of TechCo Inc. The deal involves sensitive IP\n","at 123 Main Street. Contact Sarah Johnson for details. SSN: 123-45-6789.\n","[CLIENT] approval required by [DEAL_CLOSE_DATE].\n","\"\"\"\n","\n","print(\"=\" * 70)\n","print(\"CONFIDENTIALITY UTILITIES LOADED\")\n","print(\"=\" * 70)\n","print(\"\\nüìã REDACTION DEMO\\n\")\n","print(\"BEFORE (Original Text):\")\n","print(\"-\" * 70)\n","print(demo_text)\n","print(\"-\" * 70)\n","\n","redacted_demo, removed_demo = redact(demo_text)\n","\n","print(\"\\nAFTER (Redacted Text):\")\n","print(\"-\" * 70)\n","print(redacted_demo)\n","print(\"-\" * 70)\n","print(\"\\nüîí REMOVED/FLAGGED FIELDS:\")\n","for field in removed_demo:\n","    print(f\"   ‚Ä¢ {field}\")\n","print(\"=\" * 70)\n","print(\"\\n‚ö†Ô∏è  WARNING: Always redact sensitive data BEFORE inputting to this notebook!\")\n","print(\"=\" * 70)\n"],"metadata":{"id":"_OdMQ8SwMiEp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768826060542,"user_tz":360,"elapsed":101,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"22f29673-eb3b-4fc6-ea50-e6cf41c68af4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CONFIDENTIALITY UTILITIES LOADED\n","======================================================================\n","\n","üìã REDACTION DEMO\n","\n","BEFORE (Original Text):\n","----------------------------------------------------------------------\n","\n","Our client John Smith (john.smith@acmecorp.com, 555-123-4567) is considering\n","a $50 million acquisition of TechCo Inc. The deal involves sensitive IP\n","at 123 Main Street. Contact Sarah Johnson for details. SSN: 123-45-6789.\n","[CLIENT] approval required by [DEAL_CLOSE_DATE].\n","\n","----------------------------------------------------------------------\n","\n","AFTER (Redacted Text):\n","----------------------------------------------------------------------\n","\n","Our client John Smith ([REDACTED], [REDACTED]) is considering\n","a $50 million acquisition of TechCo Inc. The deal involves sensitive IP\n","at 123 Main Street. Contact Sarah Johnson for details. SSN: [REDACTED].\n","[REDACTED] approval required by [REDACTED].\n","\n","----------------------------------------------------------------------\n","\n","üîí REMOVED/FLAGGED FIELDS:\n","   ‚Ä¢ email_addresses\n","   ‚Ä¢ phone_numbers\n","   ‚Ä¢ government_ids\n","   ‚Ä¢ currency_amounts_present\n","   ‚Ä¢ bracketed_tokens (5)\n","   ‚Ä¢ potential_person_names_detected (manual review required)\n","   ‚Ä¢ potential_company_names_detected (manual review required)\n","======================================================================\n","\n","‚ö†Ô∏è  WARNING: Always redact sensitive data BEFORE inputting to this notebook!\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##6.LLM WRAPPER"],"metadata":{"id":"uVJjvhvVM0E8"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"MyxD2F2XM1J3"}},{"cell_type":"markdown","source":["\n","\n","**What this cell does:**\n","\n","This cell creates a sophisticated quality control system that sits between you and the AI, ensuring every output meets strict professional standards before you ever see it. Think of it as a combination compliance officer, fact-checker, and quality assurance reviewer built into the workflow‚Äîautomatically validating that AI outputs are properly structured, appropriately cautious, and flagged with necessary warnings.\n","\n","**Why strict validation matters:**\n","\n","When you delegate work to a junior consultant, you expect deliverables in a consistent format with clear separation of facts from assumptions. The same principle applies to AI. This cell enforces a rigid structure on every AI response, requiring exact fields like facts provided, assumptions made, open questions, risks identified, and verification status. If the AI returns anything that deviates from this structure, the cell rejects it and demands a corrected version.\n","\n","**The parsing challenge:**\n","\n","AI models sometimes return outputs with extra formatting‚Äîmarkdown code fences, conversational preambles, or trailing commentary. For governance purposes, you need pure, parseable data. This cell implements a multi-stage extraction process. It first attempts to parse the AI response as clean structured data. If that fails, it intelligently locates the data boundaries and extracts just the core content. If that still fails, it automatically sends a correction request back to the AI, essentially saying \"please reformat properly.\" Only after two failed attempts does it raise an alert and log the parsing failure as a high-severity traceability risk.\n","\n","**Automatic risk detection:**\n","\n","Beyond format validation, this cell acts as an intelligent watchdog. It examines every draft output for concerning patterns. If the draft contains numbers or percentages that weren't in your original facts, it flags a potential hallucination risk. If the draft uses phrases like \"we analyzed\" or \"our research shows\" without supporting evidence, it flags decision laundering‚Äîthe dangerous practice of using AI to create false authority for work that wasn't actually performed. If you asked for recommendations rather than neutral drafting, it flags scope creep, reminding you that this is Level One drafting support only.\n","\n","**The verification mandate:**\n","\n","Perhaps most importantly, this cell enforces that every single output carries the label \"Not verified.\" This is not optional. Even if the AI generates perfectly reasonable-sounding text, it must be explicitly marked as requiring human review. This prevents the subtle but dangerous drift toward treating AI outputs as authoritative rather than as drafts requiring professional judgment.\n","\n","**Logging for accountability:**\n","\n","Every interaction gets logged to the governance system with cryptographic hashes of what you asked and what the AI returned. The cell redacts sensitive content before logging but preserves enough information to reconstruct the interaction for audit purposes. If someone later questions how a particular draft was generated, you have timestamped, tamper-evident records.\n","\n","**Professional standards:**\n","\n","This cell embodies the principle that increasing AI capability requires proportionally increasing control mechanisms. The more powerful the tool, the more rigorous your governance must be."],"metadata":{"id":"NbI8D2MMNp2V"}},{"cell_type":"markdown","source":["####6.1.1.EXPLAINING SOME FUNCTIONS IN MORE DETAIL"],"metadata":{"id":"s02R0QirSVvN"}},{"cell_type":"markdown","source":["**validate_schema(obj)**\n","\n","This function acts as a strict quality inspector that checks whether the AI's response contains all required fields in the correct format. It verifies that facts, assumptions, questions, and risks are properly separated into distinct categories, ensures the output is marked \"Not verified,\" and confirms that risk assessments include type, severity, and explanatory notes‚Äîrejecting any response that fails these standards.\n","\n","**log_call_event(task_name...)**\n","This function creates an auditable record of each AI interaction while protecting confidentiality. It captures what you asked and what the AI returned using cryptographic fingerprints rather than storing full text, includes redacted excerpts for context, timestamps the interaction, and logs whether the response parsed correctly‚Äîbuilding a tamper-evident audit trail without exposing sensitive client information.\n","\n","**call_claude(task_name, sanitized_facts, user_instruction, governance_context=\"\")**\n","\n","\n","**The Master Orchestrator Function**\n","\n","This is the central function that manages every interaction with Claude, acting as a sophisticated intermediary that enforces quality and governance standards throughout the process.\n","\n","When you request a draft, this function first constructs careful instructions for Claude, explicitly defining output format requirements and governance rules‚Äîdemanding structured data with facts separated from assumptions, requiring all outputs marked \"Not verified,\" and prohibiting invented statistics or recommendations.\n","\n","It then sends your sanitized facts and drafting request to Claude, receives the response, and immediately validates it against strict standards. If the response fails validation, it automatically requests a correction. If that fails too, it logs the failure as a high-severity risk and stops.\n","\n","Beyond format checking, this function acts as an intelligent quality inspector. It scans drafts for numbers not present in your original facts, flagging potential hallucinations. It detects phrases like \"we analyzed\" that falsely imply completed work you didn't perform‚Äîcatching decision laundering before it enters your deliverables. It notices when you've asked for recommendations rather than neutral drafting, flagging scope creep.\n","\n","Every interaction gets logged with cryptographic fingerprints for accountability, and all identified risks are automatically added to your governance register. This function embodies the principle that AI capability requires proportional control‚Äîthe more powerful the tool, the more rigorous your safeguards must be."],"metadata":{"id":"B3n72uCiSesH"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"HYi01MJHM25b"}},{"cell_type":"code","source":["\n","# Cell 6\n","# Type: Code\n","# Goal: LLM Call Wrapper (SUPER STRICT JSON Parsing + Traceability)\n","# Output: Print \"Wrapper ready\" and run smoke test\n","\n","EXPECTED_KEYS = [\n","    \"task\",\n","    \"facts_provided\",\n","    \"assumptions\",\n","    \"open_questions\",\n","    \"risks\",\n","    \"draft_output\",\n","    \"verification_status\",\n","    \"questions_to_verify\"\n","]\n","\n","def validate_schema(obj):\n","    \"\"\"\n","    Validate that obj matches expected schema exactly.\n","    Returns: (is_valid, error_message)\n","    \"\"\"\n","    if not isinstance(obj, dict):\n","        return False, \"Output is not a dictionary\"\n","\n","    # Check exact keys\n","    obj_keys = set(obj.keys())\n","    expected_keys = set(EXPECTED_KEYS)\n","\n","    if obj_keys != expected_keys:\n","        missing = expected_keys - obj_keys\n","        extra = obj_keys - expected_keys\n","        msg = \"\"\n","        if missing:\n","            msg += f\"Missing keys: {missing}. \"\n","        if extra:\n","            msg += f\"Extra keys: {extra}. \"\n","        return False, msg\n","\n","    # Check types\n","    if not isinstance(obj.get(\"task\"), str):\n","        return False, \"task must be string\"\n","    if not isinstance(obj.get(\"facts_provided\"), list):\n","        return False, \"facts_provided must be list\"\n","    if not isinstance(obj.get(\"assumptions\"), list):\n","        return False, \"assumptions must be list\"\n","    if not isinstance(obj.get(\"open_questions\"), list):\n","        return False, \"open_questions must be list\"\n","    if not isinstance(obj.get(\"risks\"), list):\n","        return False, \"risks must be list\"\n","    if not isinstance(obj.get(\"draft_output\"), str):\n","        return False, \"draft_output must be string\"\n","    if not isinstance(obj.get(\"verification_status\"), str):\n","        return False, \"verification_status must be string\"\n","    if not isinstance(obj.get(\"questions_to_verify\"), list):\n","        return False, \"questions_to_verify must be list\"\n","\n","    # Check verification_status\n","    if obj.get(\"verification_status\") != \"Not verified\":\n","        return False, f\"verification_status must be 'Not verified', got '{obj.get('verification_status')}'\"\n","\n","    # Check risks structure\n","    for i, risk in enumerate(obj.get(\"risks\", [])):\n","        if not isinstance(risk, dict):\n","            return False, f\"risks[{i}] must be dict\"\n","        required_risk_keys = {\"type\", \"severity\", \"note\"}\n","        if not required_risk_keys.issubset(risk.keys()):\n","            return False, f\"risks[{i}] missing required keys: {required_risk_keys - risk.keys()}\"\n","        if risk[\"severity\"] not in [\"low\", \"medium\", \"high\"]:\n","            return False, f\"risks[{i}] severity must be low/medium/high\"\n","\n","    return True, \"\"\n","\n","def extract_json_strict(text):\n","    \"\"\"\n","    Extract JSON from text with strict validation.\n","    Returns: (parsed_obj, error_message)\n","    \"\"\"\n","    # First try: parse entire string\n","    try:\n","        obj = json.loads(text)\n","        return obj, None\n","    except json.JSONDecodeError:\n","        pass\n","\n","    # Second try: extract between first { and last }\n","    try:\n","        first_brace = text.index('{')\n","        last_brace = text.rindex('}')\n","        json_substr = text[first_brace:last_brace+1]\n","\n","        # Check for extra content outside JSON\n","        before = text[:first_brace].strip()\n","        after = text[last_brace+1:].strip()\n","\n","        if before and not before.startswith('```'):\n","            return None, f\"Extra content before JSON: {before[:50]}\"\n","        if after and not after.startswith('```'):\n","            return None, f\"Extra content after JSON: {after[:50]}\"\n","\n","        obj = json.loads(json_substr)\n","        return obj, None\n","    except (ValueError, json.JSONDecodeError) as e:\n","        return None, f\"JSON parse failed: {str(e)}\"\n","\n","def log_call_event(task_name, prompt_text, response_text, model, params, parsing_status, error_msg=None):\n","    \"\"\"Log API call to prompts_log.jsonl (REDACTED)\"\"\"\n","    # Redact prompt and response\n","    prompt_redacted, _ = redact(prompt_text[:500])  # First 500 chars only\n","    response_redacted, _ = redact(response_text[:500])\n","\n","    log_entry = {\n","        \"timestamp\": now_iso(),\n","        \"task_name\": task_name,\n","        \"prompt_hash\": sha256_text(prompt_text),\n","        \"response_hash\": sha256_text(response_text),\n","        \"model\": model,\n","        \"params\": params,\n","        \"config_hash\": config_hash,\n","        \"redaction_summary\": \"First 500 chars redacted and logged\",\n","        \"parsing\": {\n","            \"status\": parsing_status,\n","            \"error\": error_msg\n","        },\n","        \"prompt_excerpt_redacted\": prompt_redacted,\n","        \"response_excerpt_redacted\": response_redacted\n","    }\n","\n","    append_jsonl(prompts_log_path, log_entry)\n","\n","def call_claude(task_name, sanitized_facts, user_instruction, governance_context=\"\"):\n","    \"\"\"\n","    Call Claude API with strict JSON parsing and governance controls.\n","\n","    Args:\n","        task_name: Name of the task (for logging)\n","        sanitized_facts: List of sanitized/redacted facts\n","        user_instruction: What to draft\n","        governance_context: Additional context about the task\n","\n","    Returns:\n","        Validated JSON output dict\n","    \"\"\"\n","    # Build system prompt\n","    system_prompt = f\"\"\"{consulting_guardrails()}\n","\n","You are a drafting assistant for management consultants. Your role is to produce DRAFT text only.\n","\n","CRITICAL OUTPUT REQUIREMENTS:\n","- Return ONLY valid JSON\n","- No markdown code fences (no ```)\n","- No prose before or after the JSON\n","- Exactly these keys: {', '.join(EXPECTED_KEYS)}\n","- verification_status must ALWAYS be \"Not verified\"\n","\n","GOVERNANCE RULES:\n","- Never invent facts, statistics, or benchmarks not provided\n","- Separate facts provided from assumptions you're making\n","- Flag ALL missing information in open_questions\n","- Flag risks: hallucination, missing_facts, decision_laundering, scope_creep, client_sensitivity\n","- Draft output should be neutral, professional consulting language\n","- No recommendations or completed analysis claims\n","\n","JSON SCHEMA:\n","{{\n","  \"task\": \"string describing what was requested\",\n","  \"facts_provided\": [\"fact1\", \"fact2\", ...],\n","  \"assumptions\": [\"assumption1\", \"assumption2\", ...],\n","  \"open_questions\": [\"question1\", \"question2\", ...],\n","  \"risks\": [\n","    {{\n","      \"type\": \"confidentiality|hallucination|missing_facts|traceability|scope_creep|decision_laundering|client_sensitivity|other\",\n","      \"severity\": \"low|medium|high\",\n","      \"note\": \"explanation\"\n","    }}\n","  ],\n","  \"draft_output\": \"the actual draft text\",\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"claim1 to verify\", \"claim2 to verify\", ...]\n","}}\n","\n","TASK CONTEXT:\n","{governance_context}\n","\"\"\"\n","\n","    # Build user prompt\n","    facts_text = \"\\n\".join(f\"- {fact}\" for fact in sanitized_facts)\n","    user_prompt = f\"\"\"\n","FACTS PROVIDED (sanitized/redacted):\n","{facts_text}\n","\n","INSTRUCTION:\n","{user_instruction}\n","\n","Remember: Return ONLY valid JSON. No markdown. No extra text.\n","\"\"\"\n","\n","    # Call API\n","    try:\n","        response = client.messages.create(\n","            model=MODEL,\n","            max_tokens=4128,\n","            temperature=0.2,\n","            system=system_prompt,\n","            messages=[{\"role\": \"user\", \"content\": user_prompt}]\n","        )\n","\n","        response_text = response.content[0].text\n","\n","        # Parse JSON strictly\n","        obj, error = extract_json_strict(response_text)\n","\n","        if error:\n","            # Retry once with correction prompt\n","            print(f\"‚ö†Ô∏è  First parse failed: {error}. Retrying with correction prompt...\")\n","\n","            correction_prompt = f\"\"\"The previous output had a format error: {error}\n","\n","Please return ONLY valid JSON with these exact keys: {', '.join(EXPECTED_KEYS)}\n","\n","No markdown code fences. No prose. Just pure JSON.\n","\n","verification_status must be \"Not verified\"\n","\n","Return the corrected JSON now:\"\"\"\n","\n","            retry_response = client.messages.create(\n","                model=MODEL,\n","                max_tokens=4128,\n","                temperature=0.2,\n","                system=system_prompt,\n","                messages=[\n","                    {\"role\": \"user\", \"content\": user_prompt},\n","                    {\"role\": \"assistant\", \"content\": response_text},\n","                    {\"role\": \"user\", \"content\": correction_prompt}\n","                ]\n","            )\n","\n","            response_text = retry_response.content[0].text\n","            obj, error = extract_json_strict(response_text)\n","\n","            if error:\n","                # Final failure\n","                log_call_event(task_name, user_prompt, response_text, MODEL,\n","                             {\"temperature\": 0.2, \"max_tokens\": 4128}, \"fail\", error)\n","\n","                # Log to risk_log\n","                risk_log = read_json(risk_log_path)\n","                risk_log[\"risks\"].append({\n","                    \"timestamp\": now_iso(),\n","                    \"task\": task_name,\n","                    \"type\": \"traceability\",\n","                    \"severity\": \"high\",\n","                    \"note\": f\"Model returned non-parseable JSON: {error}\",\n","                    \"owner\": \"unassigned\",\n","                    \"disposition\": \"open\"\n","                })\n","                write_json(risk_log_path, risk_log)\n","\n","                raise Exception(f\"Failed to parse JSON after retry: {error}\")\n","\n","            parsing_status = \"retry_ok\"\n","        else:\n","            parsing_status = \"ok\"\n","\n","        # Validate schema\n","        is_valid, validation_error = validate_schema(obj)\n","        if not is_valid:\n","            log_call_event(task_name, user_prompt, response_text, MODEL,\n","                         {\"temperature\": 0.2, \"max_tokens\": 4128}, \"fail\", validation_error)\n","\n","            # Log to risk_log\n","            risk_log = read_json(risk_log_path)\n","            risk_log[\"risks\"].append({\n","                \"timestamp\": now_iso(),\n","                \"task\": task_name,\n","                \"type\": \"traceability\",\n","                \"severity\": \"high\",\n","                \"note\": f\"Schema validation failed: {validation_error}\",\n","                \"owner\": \"unassigned\",\n","                \"disposition\": \"open\"\n","            })\n","            write_json(risk_log_path, risk_log)\n","\n","            raise Exception(f\"Schema validation failed: {validation_error}\")\n","\n","        # Auto risk detection\n","        auto_risks = []\n","\n","        # Check for empty open_questions\n","        if not obj[\"open_questions\"]:\n","            auto_risks.append({\n","                \"type\": \"missing_facts\",\n","                \"severity\": \"medium\",\n","                \"note\": \"No open questions flagged; may indicate incomplete analysis\"\n","            })\n","\n","        # Check for hallucinated numbers\n","        draft_lower = obj[\"draft_output\"].lower()\n","        facts_lower = \" \".join(sanitized_facts).lower()\n","\n","        # Look for numbers/percentages in draft\n","        number_pattern = r'\\d+(?:\\.\\d+)?%?|\\$[\\d,]+(?:\\.\\d+)?(?:\\s?(?:million|billion|thousand|[MBK]))?'\n","        draft_numbers = set(re.findall(number_pattern, obj[\"draft_output\"], re.IGNORECASE))\n","        facts_numbers = set(re.findall(number_pattern, \" \".join(sanitized_facts), re.IGNORECASE))\n","\n","        hallucinated_numbers = draft_numbers - facts_numbers\n","        if hallucinated_numbers:\n","            auto_risks.append({\n","                \"type\": \"hallucination\",\n","                \"severity\": \"high\",\n","                \"note\": f\"Draft contains numbers/percentages not in provided facts: {list(hallucinated_numbers)[:3]}\"\n","            })\n","\n","        # Check for decision laundering\n","        laundering_phrases = [\n","            \"we analyzed\", \"we validated\", \"we interviewed\", \"we confirmed\",\n","            \"our analysis shows\", \"our research indicates\", \"we found that\"\n","        ]\n","        for phrase in laundering_phrases:\n","            if phrase in draft_lower and phrase not in facts_lower:\n","                auto_risks.append({\n","                    \"type\": \"decision_laundering\",\n","                    \"severity\": \"high\",\n","                    \"note\": f\"Draft implies completed work ('{phrase}') not supported by facts\"\n","                })\n","                break\n","\n","        # Check for advice/recommendations\n","        advice_keywords = [\"recommend\", \"should\", \"must\", \"advise\", \"suggest that you\"]\n","        for keyword in advice_keywords:\n","            if keyword in user_instruction.lower():\n","                auto_risks.append({\n","                    \"type\": \"scope_creep\",\n","                    \"severity\": \"medium\",\n","                    \"note\": f\"User instruction requested advice/recommendation ('{keyword}'); maintained neutral drafting posture\"\n","                })\n","                break\n","\n","        # Merge auto-detected risks with model-generated risks\n","        obj[\"risks\"].extend(auto_risks)\n","\n","        # Update risk_log.json\n","        risk_log = read_json(risk_log_path)\n","        for risk in obj[\"risks\"]:\n","            risk_log[\"risks\"].append({\n","                \"timestamp\": now_iso(),\n","                \"task\": task_name,\n","                \"type\": risk[\"type\"],\n","                \"severity\": risk[\"severity\"],\n","                \"note\": risk[\"note\"],\n","                \"owner\": \"unassigned\",\n","                \"disposition\": \"open\"\n","            })\n","        write_json(risk_log_path, risk_log)\n","\n","        # Log successful call\n","        log_call_event(task_name, user_prompt, response_text, MODEL,\n","                     {\"temperature\": 0.2, \"max_tokens\": 4128}, parsing_status)\n","\n","        return obj\n","\n","    except Exception as e:\n","        print(f\"‚ùå API call failed: {e}\")\n","        raise\n","\n","# Smoke test\n","print(\"=\" * 70)\n","print(\"LLM WRAPPER LOADED - Running Smoke Test...\")\n","print(\"=\" * 70)\n","\n","try:\n","    test_output = call_claude(\n","        task_name=\"smoke_test\",\n","        sanitized_facts=[\"Company operates in retail sector\", \"Annual revenue is stable\"],\n","        user_instruction=\"Draft a one-sentence email opening greeting a client.\",\n","        governance_context=\"This is a smoke test to verify JSON parsing.\"\n","    )\n","\n","    print(\"‚úÖ Smoke test PASSED\")\n","    print(f\"   ‚Ä¢ Schema valid: Yes\")\n","    print(f\"   ‚Ä¢ Verification status: {test_output['verification_status']}\")\n","    print(f\"   ‚Ä¢ Open questions: {len(test_output['open_questions'])}\")\n","    print(f\"   ‚Ä¢ Risks flagged: {len(test_output['risks'])}\")\n","    print(\"=\" * 70)\n","\n","except Exception as e:\n","    print(f\"‚ùå Smoke test FAILED: {e}\")\n","    print(\"=\" * 70)\n"],"metadata":{"id":"NVWzVmXzM4V4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768826183345,"user_tz":360,"elapsed":6486,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"f71e0cdc-01a9-4f97-e5f2-a6a51b364600"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","LLM WRAPPER LOADED - Running Smoke Test...\n","======================================================================\n","‚úÖ Smoke test PASSED\n","   ‚Ä¢ Schema valid: Yes\n","   ‚Ä¢ Verification status: Not verified\n","   ‚Ä¢ Open questions: 5\n","   ‚Ä¢ Risks flagged: 2\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##7.DOCUMENT LIFECYCLE INFRASTRUCTURE"],"metadata":{"id":"Dr34h4v4M8SU"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"EnAuC2ckM_GU"}},{"cell_type":"markdown","source":["\n","**What this cell does:**\n","\n","This cell creates a set of specialized tools for managing the complete lifecycle of consulting deliverables‚Äîfrom initial intake through assumptions tracking, verification planning, approval workflows, and final presentation. Think of it as building the administrative scaffolding that surrounds every consulting engagement, ensuring proper documentation and accountability at each stage.\n","\n","**Why document governance matters:**\n","\n","In professional consulting, a deliverable is never just the final slide deck or memo. Behind every client-facing document sits a trail of intake forms, assumption logs, verification checklists, and approval signatures. These artifacts protect both you and your client by documenting what was agreed, what assumptions underpin the analysis, what still needs validation, and who reviewed the work before it went out the door.\n","\n","When AI enters the drafting process, this documentation becomes even more critical. You need explicit records showing that outputs were marked as drafts, that assumptions were flagged for human review, and that appropriate approvals were obtained before use.\n","\n","**The intake record function:**\n","\n","The first builder creates intake records‚Äîessentially a project kickoff form for each drafting task. It captures the case name, when work began, client sensitivity level, the purpose of the engagement, and critically, the scope boundary. That scope boundary explicitly states this is Level One drafting only, not strategic analysis or decision-making. This prevents scope creep and sets clear expectations about what the AI will and will not do.\n","\n","**The assumption register:**\n","\n","When Claude drafts text, it inevitably makes assumptions‚Äîabout market conditions, organizational capabilities, stakeholder priorities, or regulatory environments. The assumption register builder extracts these assumptions from Claude's output and creates formal tracking records for each one. Every assumption gets a unique identifier, an owner field marking who's responsible for validating it, a test method field describing how it should be verified, and a validation status showing it hasn't been tested yet.\n","\n","This mirrors standard consulting practice. When you build a financial model or strategic recommendation, you document your assumptions explicitly so stakeholders understand the foundation of your analysis and can challenge questionable premises.\n","\n","**The verification register:**\n","\n","Some AI outputs contain specific claims that require fact-checking before use‚Äîmarket statistics, regulatory requirements, competitor capabilities, or technical specifications. The verification register builder extracts these claims and creates tracking records showing what needs verification, how to verify it, who owns that task, and current verification status.\n","\n","This is your defense against hallucinations. Rather than hoping you'll remember to fact-check everything, you have a systematic register forcing accountability for each verifiable claim.\n","\n","**The approval workflow:**\n","\n","The approval record builder creates formal sign-off documentation showing who reviewed the work and what decision they made."],"metadata":{"id":"EKvlFydjNrmX"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"X1KSLRldNBYW"}},{"cell_type":"code","source":["\n","# Cell 7\n","# Type: Code\n","# Goal: Level 1 Consulting Draft Builders\n","# Output: Print \"Draft builders loaded\" and list function names\n","\n","def build_intake_record(case_name, client_sensitivity, purpose, scope_boundary):\n","    \"\"\"Build intake record for a consulting case\"\"\"\n","    return {\n","        \"case_name\": case_name,\n","        \"intake_timestamp\": now_iso(),\n","        \"client_sensitivity\": client_sensitivity,\n","        \"purpose\": purpose,\n","        \"scope_boundary\": scope_boundary,\n","        \"level\": \"1 - Chatbots (Drafting Only)\",\n","        \"governance_posture\": \"Human-in-the-loop; outputs are Not verified drafts\"\n","    }\n","\n","def build_assumption_register_stub(output_json):\n","    \"\"\"Extract assumptions and create register stubs\"\"\"\n","    assumptions = output_json.get(\"assumptions\", [])\n","    register = []\n","\n","    for i, assumption in enumerate(assumptions):\n","        register.append({\n","            \"assumption_id\": f\"ASMP_{i+1:03d}\",\n","            \"assumption_text\": assumption,\n","            \"owner\": \"unassigned\",\n","            \"test_method\": \"pending\",\n","            \"validation_status\": \"not_tested\",\n","            \"created\": now_iso()\n","        })\n","\n","    return register\n","\n","def build_verification_register_stub(output_json):\n","    \"\"\"Extract claims needing verification and create register stubs\"\"\"\n","    questions = output_json.get(\"questions_to_verify\", [])\n","    register = []\n","\n","    for i, question in enumerate(questions):\n","        register.append({\n","            \"verification_id\": f\"VER_{i+1:03d}\",\n","            \"claim_or_question\": question,\n","            \"how_to_verify\": \"pending\",\n","            \"owner\": \"unassigned\",\n","            \"verification_status\": \"not_verified\",\n","            \"created\": now_iso()\n","        })\n","\n","    return register\n","\n","def build_approval_record(case_name, reviewer_role, approval_state=\"pending\"):\n","    \"\"\"Build approval record stub\"\"\"\n","    return {\n","        \"case_name\": case_name,\n","        \"timestamp\": now_iso(),\n","        \"reviewer_role\": reviewer_role,\n","        \"approval_state\": approval_state,\n","        \"verification_status\": \"Not verified\",\n","        \"comments\": \"\"\n","    }\n","\n","def render_human_readable(case_name, output_json, disclaimers):\n","    \"\"\"Render output in human-readable format with disclaimers\"\"\"\n","    sections = []\n","\n","    sections.append(\"=\" * 70)\n","    sections.append(f\"CASE: {case_name}\")\n","    sections.append(\"=\" * 70)\n","    sections.append(\"\")\n","\n","    sections.append(\"‚ö†Ô∏è  DISCLAIMERS\")\n","    sections.append(\"-\" * 70)\n","    for disclaimer in disclaimers:\n","        sections.append(f\"‚Ä¢ {disclaimer}\")\n","    sections.append(\"\")\n","\n","    sections.append(\"üìã TASK\")\n","    sections.append(\"-\" * 70)\n","    sections.append(output_json.get(\"task\", \"N/A\"))\n","    sections.append(\"\")\n","\n","    sections.append(\"‚úÖ FACTS PROVIDED\")\n","    sections.append(\"-\" * 70)\n","    for fact in output_json.get(\"facts_provided\", []):\n","        sections.append(f\"‚Ä¢ {fact}\")\n","    sections.append(\"\")\n","\n","    sections.append(\"üîç ASSUMPTIONS MADE\")\n","    sections.append(\"-\" * 70)\n","    for assumption in output_json.get(\"assumptions\", []):\n","        sections.append(f\"‚Ä¢ {assumption}\")\n","    sections.append(\"\")\n","\n","    sections.append(\"‚ùì OPEN QUESTIONS\")\n","    sections.append(\"-\" * 70)\n","    for question in output_json.get(\"open_questions\", []):\n","        sections.append(f\"‚Ä¢ {question}\")\n","    sections.append(\"\")\n","\n","    sections.append(\"‚ö†Ô∏è  RISKS IDENTIFIED\")\n","    sections.append(\"-\" * 70)\n","    for risk in output_json.get(\"risks\", []):\n","        sections.append(f\"‚Ä¢ [{risk['severity'].upper()}] {risk['type']}: {risk['note']}\")\n","    sections.append(\"\")\n","\n","    sections.append(\"üìù DRAFT OUTPUT\")\n","    sections.append(\"-\" * 70)\n","    sections.append(output_json.get(\"draft_output\", \"N/A\"))\n","    sections.append(\"\")\n","\n","    sections.append(\"üîé QUESTIONS TO VERIFY\")\n","    sections.append(\"-\" * 70)\n","    for q in output_json.get(\"questions_to_verify\", []):\n","        sections.append(f\"‚Ä¢ {q}\")\n","    sections.append(\"\")\n","\n","    sections.append(\"=\" * 70)\n","    sections.append(f\"VERIFICATION STATUS: {output_json.get('verification_status', 'Unknown')}\")\n","    sections.append(\"=\" * 70)\n","\n","    return \"\\n\".join(sections)\n","\n","print(\"=\" * 70)\n","print(\"DRAFT BUILDERS LOADED\")\n","print(\"=\" * 70)\n","print(\"Available functions:\")\n","print(\"  ‚Ä¢ build_intake_record()\")\n","print(\"  ‚Ä¢ build_assumption_register_stub()\")\n","print(\"  ‚Ä¢ build_verification_register_stub()\")\n","print(\"  ‚Ä¢ build_approval_record()\")\n","print(\"  ‚Ä¢ render_human_readable()\")\n","print(\"=\" * 70)"],"metadata":{"id":"vw3KXun5NDTt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768828809508,"user_tz":360,"elapsed":26,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"30c90671-a81f-4254-d129-f88413912a8d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","DRAFT BUILDERS LOADED\n","======================================================================\n","Available functions:\n","  ‚Ä¢ build_intake_record()\n","  ‚Ä¢ build_assumption_register_stub()\n","  ‚Ä¢ build_verification_register_stub()\n","  ‚Ä¢ build_approval_record()\n","  ‚Ä¢ render_human_readable()\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##8.RUN MINI-CASES"],"metadata":{"id":"E9DiNZg2NOyv"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"Ee1sdukLNP3S"}},{"cell_type":"markdown","source":["\n","\n","**What this cell does:**\n","\n","This cell executes four realistic consulting drafting scenarios, demonstrating how AI-assisted drafting works in practice across common strategy and advisory situations. Think of it as a flight simulator for consultants‚Äîyou're experiencing realistic drafting workflows without risking actual client work, seeing both the capabilities and the critical governance controls in action.\n","\n","**Why four scenarios:**\n","\n","The cell deliberately covers diverse consulting contexts to show you how the same AI drafting infrastructure adapts across different engagement types. Market entry analysis requires different deliverables than cost transformation work, which differs from capital allocation decisions, which differs from operating model redesign. By walking through all four, you develop intuition about when and how to apply AI drafting support across your actual consulting portfolio.\n","\n","**How each scenario unfolds:**\n","\n","For every scenario, the cell follows a disciplined workflow that mirrors professional consulting practice. First, it creates an intake record documenting what you're trying to accomplish, the client sensitivity level, and the explicit scope boundary. This prevents mission creep where simple drafting expands into unauthorized strategic analysis.\n","\n","Then the cell makes multiple separate calls to Claude‚Äîone for each deliverable type needed. For market entry, that means one call drafts the client email, another call drafts the memo shell, and a third call drafts the meeting agenda. These are intentionally separate interactions, not a continuous conversation. This reflects the Level One boundary: you're using the AI as a drafting tool, not as an autonomous agent that independently manages multi-step workflows.\n","\n","After each AI call returns a draft, the cell immediately extracts governance artifacts. It pulls out the assumptions Claude made and creates tracking records for each one. It identifies claims requiring verification and logs those systematically. It creates placeholder approval records showing these drafts are pending human review.\n","\n","**The intentional incompleteness:**\n","\n","Notice that the scenarios provide deliberately sparse facts‚Äîjust three or four bullet points about each situation. This is not an oversight. The cell is demonstrating a critical governance principle: when you give the AI incomplete information, it should flag missing data rather than inventing plausible-sounding details. You'll see this reflected in the outputs‚Äîeach draft comes with substantial lists of open questions and flagged risks.\n","\n","**What gets saved:**\n","\n","Every scenario generates multiple files in your deliverables folder. The raw JSON outputs preserve the complete structured data. Human-readable text files present the drafts with clear disclaimers and governance warnings. Assumption stubs, verification stubs, and approval stubs create the paper trail showing what still needs human attention before these drafts become usable deliverables.\n","\n","**The summary table:**\n","\n","At the end, the cell prints a simple summary showing how many open questions each scenario generated and what the highest severity risk was."],"metadata":{"id":"UPGXnne7NtGW"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"BIE5Ni_wNRvq"}},{"cell_type":"code","source":["# Cell 8\n","# Type: Code\n","# Goal: Run 4 Mini-Case Demos + Save Deliverables\n","# Output: Print summary table\n","\n","mini_cases = [\n","    {\n","        \"case_name\": \"market_entry\",\n","        \"client_sensitivity\": \"medium\",\n","        \"purpose\": \"Draft market entry analysis deliverables for new geography\",\n","        \"scope_boundary\": \"Drafting only; no market research or data analysis\",\n","        \"sanitized_facts\": [\n","            \"Client is considering entering Southeast Asian market\",\n","            \"Product category is consumer electronics\",\n","            \"Target launch timeframe is 18-24 months\"\n","        ],\n","        \"tasks\": [\n","            {\n","                \"task_name\": \"client_email\",\n","                \"instruction\": \"Draft a brief client email (3-4 sentences) confirming receipt of market entry request and outlining next steps for the engagement kickoff.\"\n","            },\n","            {\n","                \"task_name\": \"memo_shell\",\n","                \"instruction\": \"Draft an executive memo shell (outline with section headers and 1-2 sentence descriptions per section) for a market entry feasibility analysis. Include sections for: Market Overview, Competitive Landscape, Regulatory Considerations, Financial Projections, and Recommendations.\"\n","            },\n","            {\n","                \"task_name\": \"meeting_agenda\",\n","                \"instruction\": \"Draft a meeting agenda for the market entry kickoff meeting with the client team. Include: objectives, attendees, topics for discussion, and a follow-up action items template.\"\n","            }\n","        ]\n","    },\n","    {\n","        \"case_name\": \"cost_transformation\",\n","        \"client_sensitivity\": \"high\",\n","        \"purpose\": \"Draft cost transformation program deliverables\",\n","        \"scope_boundary\": \"Drafting only; no financial analysis or implementation planning\",\n","        \"sanitized_facts\": [\n","            \"Client is a mid-size manufacturing company\",\n","            \"Objective is 15-20% cost reduction over 2 years\",\n","            \"Focus areas include procurement, operations, and overhead\"\n","        ],\n","        \"tasks\": [\n","            {\n","                \"task_name\": \"workplan_narrative\",\n","                \"instruction\": \"Draft a workplan narrative (5-6 sentences) describing the phases of a cost transformation engagement: diagnostic, opportunity identification, initiative design, and implementation support.\"\n","            },\n","            {\n","                \"task_name\": \"data_request_list\",\n","                \"instruction\": \"Draft a data request list for the cost diagnostic phase. Include 5-7 categories of data needed (e.g., expense data, headcount, vendor contracts) with brief descriptions of what's needed for each category.\"\n","            },\n","            {\n","                \"task_name\": \"stakeholder_update\",\n","                \"instruction\": \"Draft a stakeholder update email (4-5 sentences) for the client CFO summarizing progress in the diagnostic phase and highlighting 2-3 early observations (generic, no specific numbers).\"\n","            }\n","        ]\n","    },\n","    {\n","        \"case_name\": \"capital_allocation\",\n","        \"client_sensitivity\": \"high\",\n","        \"purpose\": \"Draft investment committee materials\",\n","        \"scope_boundary\": \"Drafting only; no financial modeling or valuation\",\n","        \"sanitized_facts\": [\n","            \"Client is evaluating acquisition target in adjacent market\",\n","            \"Deal size is in the mid-market range\",\n","            \"Investment committee meeting scheduled in 3 weeks\"\n","        ],\n","        \"tasks\": [\n","            {\n","                \"task_name\": \"ic_preread_shell\",\n","                \"instruction\": \"Draft an investment committee pre-read shell (outline with section headers and 2-3 sentence descriptions) covering: Transaction Overview, Strategic Rationale, Financial Summary, Key Risks, and Next Steps.\"\n","            },\n","            {\n","                \"task_name\": \"assumptions_memo\",\n","                \"instruction\": \"Draft a brief memo section (4-5 sentences) explicitly listing key assumptions underlying the investment case (e.g., market growth, synergies, integration complexity) and noting what would need to be validated.\"\n","            },\n","            {\n","                \"task_name\": \"meeting_prep_email\",\n","                \"instruction\": \"Draft an internal team email (3-4 sentences) preparing team members for the investment committee presentation, outlining anticipated questions and discussion topics.\"\n","            }\n","        ]\n","    },\n","    {\n","        \"case_name\": \"operating_model\",\n","        \"client_sensitivity\": \"medium\",\n","        \"purpose\": \"Draft operating model redesign deliverables\",\n","        \"scope_boundary\": \"Drafting only; no organizational design or change management\",\n","        \"sanitized_facts\": [\n","            \"Client is restructuring post-merger integration\",\n","            \"Focus is on corporate functions and shared services\",\n","            \"Target is streamlined decision-making and reduced duplication\"\n","        ],\n","        \"tasks\": [\n","            {\n","                \"task_name\": \"raci_narrative\",\n","                \"instruction\": \"Draft a narrative section (5-6 sentences) explaining the purpose of a RACI framework for the operating model redesign and how it will clarify decision rights and accountabilities across functions.\"\n","            },\n","            {\n","                \"task_name\": \"workshop_agenda\",\n","                \"instruction\": \"Draft a workshop agenda for an operating model design session with client leadership. Include: session objectives, activities (e.g., current state review, future state brainstorming, decision rights mapping), and time allocations.\"\n","            },\n","            {\n","                \"task_name\": \"followup_email\",\n","                \"instruction\": \"Draft a post-workshop follow-up email (4-5 sentences) thanking participants, summarizing key decisions made, and outlining next steps with action owners.\"\n","            }\n","        ]\n","    }\n","]\n","\n","# Run all mini-cases\n","results = []\n","\n","for case in mini_cases:\n","    print(\"=\" * 70)\n","    print(f\"RUNNING MINI-CASE: {case['case_name'].upper()}\")\n","    print(\"=\" * 70)\n","\n","    # Create intake record\n","    intake = build_intake_record(\n","        case[\"case_name\"],\n","        case[\"client_sensitivity\"],\n","        case[\"purpose\"],\n","        case[\"scope_boundary\"]\n","    )\n","    intake_path = deliverables_dir / f\"{case['case_name']}_intake.json\"\n","    write_json(intake_path, intake)\n","\n","    # Run tasks\n","    outputs = {}\n","    all_open_questions = []\n","    all_risks = []\n","\n","    for task in case[\"tasks\"]:\n","        print(f\"\\n‚ñ∂ Task: {task['task_name']}\")\n","\n","        output = call_claude(\n","            task_name=f\"{case['case_name']}_{task['task_name']}\",\n","            sanitized_facts=case[\"sanitized_facts\"],\n","            user_instruction=task[\"instruction\"],\n","            governance_context=f\"Case: {case['case_name']} | Client sensitivity: {case['client_sensitivity']}\"\n","        )\n","\n","        outputs[task['task_name']] = output\n","        all_open_questions.extend(output.get(\"open_questions\", []))\n","        all_risks.extend(output.get(\"risks\", []))\n","\n","        # Save individual output\n","        output_path = deliverables_dir / f\"{case['case_name']}_{task['task_name']}.json\"\n","        write_json(output_path, output)\n","\n","        print(f\"  ‚úÖ Saved: {output_path.name}\")\n","\n","    # Create verification and assumption registers\n","    # Use first output for demonstration\n","    first_output = outputs[case['tasks'][0]['task_name']]\n","\n","    assumptions_stub = build_assumption_register_stub(first_output)\n","    assumptions_path = deliverables_dir / f\"{case['case_name']}_assumptions_stub.json\"\n","    write_json(assumptions_path, assumptions_stub)\n","\n","    verification_stub = build_verification_register_stub(first_output)\n","    verification_path = deliverables_dir / f\"{case['case_name']}_verification_stub.json\"\n","    write_json(verification_path, verification_stub)\n","\n","    # Update global verification register\n","    ver_register = read_json(verification_register_path)\n","    ver_register[\"items\"].extend(verification_stub)\n","    write_json(verification_register_path, ver_register)\n","\n","    # Create approval record\n","    approval = build_approval_record(case[\"case_name\"], \"Engagement Manager\", \"pending\")\n","    approval_path = deliverables_dir / f\"{case['case_name']}_approval_stub.json\"\n","    write_json(approval_path, approval)\n","\n","    # Update global approvals log\n","    approvals = read_json(approvals_log_path)\n","    approvals[\"approvals\"].append(approval)\n","    write_json(approvals_log_path, approvals)\n","\n","    # Create human-readable summary\n","    disclaimers = [\n","        \"DRAFT ONLY - Not verified\",\n","        \"Human review required before use\",\n","        \"No factual claims guaranteed\",\n","        f\"Client sensitivity: {case['client_sensitivity']}\"\n","    ]\n","\n","    human_readable = render_human_readable(\n","        case[\"case_name\"],\n","        first_output,\n","        disclaimers\n","    )\n","\n","    readable_path = deliverables_dir / f\"{case['case_name']}_human_readable.txt\"\n","    readable_path.write_text(human_readable, encoding='utf-8')\n","\n","    # Track results\n","    highest_severity = \"low\"\n","    for risk in all_risks:\n","        if risk[\"severity\"] == \"high\":\n","            highest_severity = \"high\"\n","            break\n","        elif risk[\"severity\"] == \"medium\" and highest_severity == \"low\":\n","            highest_severity = \"medium\"\n","\n","    results.append({\n","        \"case_name\": case[\"case_name\"],\n","        \"open_questions\": len(set(all_open_questions)),\n","        \"highest_risk\": highest_severity,\n","        \"artifacts\": len(list(deliverables_dir.glob(f\"{case['case_name']}_*\")))\n","    })\n","\n","    print(f\"\\n‚úÖ {case['case_name']} complete: {results[-1]['artifacts']} artifacts saved\")\n","\n","# Print summary table\n","print(\"\\n\" + \"=\" * 70)\n","print(\"MINI-CASES SUMMARY\")\n","print(\"=\" * 70)\n","print(f\"{'Case Name':<25} {'Open Qs':<10} {'Max Risk':<12} {'Artifacts':<10}\")\n","print(\"-\" * 70)\n","\n","for result in results:\n","    print(f\"{result['case_name']:<25} {result['open_questions']:<10} {result['highest_risk']:<12} {result['artifacts']:<10}\")\n","\n","print(\"=\" * 70)"],"metadata":{"id":"GF7UbU5xNTWW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768829224203,"user_tz":360,"elapsed":229950,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"5704ecad-4b95-40ba-e23b-7247a5a88aeb"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","RUNNING MINI-CASE: MARKET_ENTRY\n","======================================================================\n","\n","‚ñ∂ Task: client_email\n","  ‚úÖ Saved: market_entry_client_email.json\n","\n","‚ñ∂ Task: memo_shell\n","  ‚úÖ Saved: market_entry_memo_shell.json\n","\n","‚ñ∂ Task: meeting_agenda\n","  ‚úÖ Saved: market_entry_meeting_agenda.json\n","\n","‚úÖ market_entry complete: 8 artifacts saved\n","======================================================================\n","RUNNING MINI-CASE: COST_TRANSFORMATION\n","======================================================================\n","\n","‚ñ∂ Task: workplan_narrative\n","  ‚úÖ Saved: cost_transformation_workplan_narrative.json\n","\n","‚ñ∂ Task: data_request_list\n","  ‚úÖ Saved: cost_transformation_data_request_list.json\n","\n","‚ñ∂ Task: stakeholder_update\n","  ‚úÖ Saved: cost_transformation_stakeholder_update.json\n","\n","‚úÖ cost_transformation complete: 8 artifacts saved\n","======================================================================\n","RUNNING MINI-CASE: CAPITAL_ALLOCATION\n","======================================================================\n","\n","‚ñ∂ Task: ic_preread_shell\n","  ‚úÖ Saved: capital_allocation_ic_preread_shell.json\n","\n","‚ñ∂ Task: assumptions_memo\n","  ‚úÖ Saved: capital_allocation_assumptions_memo.json\n","\n","‚ñ∂ Task: meeting_prep_email\n","  ‚úÖ Saved: capital_allocation_meeting_prep_email.json\n","\n","‚úÖ capital_allocation complete: 8 artifacts saved\n","======================================================================\n","RUNNING MINI-CASE: OPERATING_MODEL\n","======================================================================\n","\n","‚ñ∂ Task: raci_narrative\n","  ‚úÖ Saved: operating_model_raci_narrative.json\n","\n","‚ñ∂ Task: workshop_agenda\n","  ‚úÖ Saved: operating_model_workshop_agenda.json\n","\n","‚ñ∂ Task: followup_email\n","  ‚úÖ Saved: operating_model_followup_email.json\n","\n","‚úÖ operating_model complete: 8 artifacts saved\n","\n","======================================================================\n","MINI-CASES SUMMARY\n","======================================================================\n","Case Name                 Open Qs    Max Risk     Artifacts \n","----------------------------------------------------------------------\n","market_entry              25         high         8         \n","cost_transformation       20         high         8         \n","capital_allocation        27         high         8         \n","operating_model           26         high         8         \n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##9.USER'S APPLICATION"],"metadata":{"id":"3juVsof2NUJC"}},{"cell_type":"markdown","source":["###9.1.OVERVIEW"],"metadata":{"id":"0A7X8eAeNVjp"}},{"cell_type":"markdown","source":["####9.1.1.GENERAL DESCRIPTION"],"metadata":{"id":"98g_0Gk2eigT"}},{"cell_type":"markdown","source":["\n","\n","**What this cell does:**\n","\n","This cell shifts from demonstration to participation‚Äîyou become the consultant using AI drafting support for your own scenario. It prompts you to describe a consulting situation, automatically protects confidential information, calls Claude to generate your requested deliverable, and produces the complete governance package showing exactly what assumptions were made, what risks were flagged, and what still needs human verification.\n","\n","**Why hands-on practice matters:**\n","\n","Watching four pre-built scenarios run is instructive, but actually using the tool yourself reveals the practical realities. You experience how much context you need to provide, how the redaction warnings make you think twice about what you're sharing, how the AI interprets vague instructions, and most importantly, how the governance artifacts force you to confront gaps in your own thinking. This is learning by doing.\n","\n","**The interactive flow:**\n","\n","The cell begins by asking you two simple questions. First, what type of deliverable do you need‚Äîa client email, an internal memo shell, or a meeting agenda. Second, describe the situation you're working with. This mirrors real consulting work where you often start with incomplete information and need to draft something quickly to move a workstream forward.\n","\n","**Confidentiality protection in action:**\n","\n","Before your situation description ever reaches Claude, the cell runs it through the redaction function you saw demonstrated in Cell Five. It automatically strips out email addresses, phone numbers, government IDs, and other sensitive patterns. More importantly, it shows you a detailed summary of what was removed or flagged. If it detected potential person names or company identifiers, it warns you explicitly that manual review is required. This builds the muscle memory of checking what's being shared before it leaves your control.\n","\n","The cell then applies the minimum necessary principle, extracting only two or three core facts from your description rather than sending the entire context. This serves dual purposes‚Äîconfidentiality protection and better AI performance. When you force yourself to distill situations down to essentials, you clarify your own thinking.\n","\n","**What gets created:**\n","\n","Just like the mini-cases in Cell Eight, your exercise generates a complete governance package. An intake record documents what you asked for and when. The AI output gets saved with full structured data showing facts provided, assumptions made, open questions, and risks. Assumption stubs and verification stubs create tracking records for what needs human attention. An approval placeholder reminds you this is pending review. The human-readable text file presents everything with clear disclaimers.\n","\n","**The learning moment:**\n","\n","Pay close attention to the removed fields summary that prints after redaction. Even if you thought you were careful, you'll often see flags for currency amounts, capitalized words that might be names, or company indicators. This demonstrates that confidentiality hygiene requires both automated tools and human judgment‚Äîneither alone is sufficient.\n","\n","Also notice the open questions and risks that Claude flags in your output. If you provided sparse context, Claude should identify what's missing rather than inventing plausible details. If your instruction accidentally requested recommendations rather than neutral drafting, you'll see a scope creep risk flagged. These governance controls work regardless of whether you're running pre-built scenarios or your own ad-hoc requests.\n","\n","**Professional habit formation:**\n","\n","This exercise builds the workflow you should follow in real consulting work. Before using AI, redact sensitive data and review what was removed. After receiving AI output, immediately check the assumptions, open questions, and risks before using any of the draft text. Save the governance artifacts alongside the deliverable so you have an audit trail. Mark everything as not verified until human review is complete.\n","\n","**The meta-lesson:**\n","\n","By the time you finish Cell Nine, you've experienced both sides of AI-assisted consulting. You've seen carefully constructed scenarios with known governance outcomes, and you've tried your own messy real-world situation where the boundaries are less clear. This combination develops both technical competence and professional judgment about when and how to use these tools responsibly."],"metadata":{"id":"7SgqchOZNupJ"}},{"cell_type":"markdown","source":["####9.1.2.IDEAS FOR EXAMPLES"],"metadata":{"id":"qtV2M6H9eqN-"}},{"cell_type":"markdown","source":["**Example 1: Client Email (Market Entry)**\n","\n","**Deliverable Type:**\n","client email\n","\n","**Situation:**\n","Our client, a mid-sized European consumer goods manufacturer, is exploring entry into the Mexican market. They currently generate 500M EUR in annual revenue across Germany, France, and Spain. The CEO wants to understand regulatory requirements, distribution channel options, and competitive landscape before committing resources. We have an initial discovery call scheduled next week with their executive team.\n","\n","**Example 2: Internal Memo Shell (Cost Optimization)**\n","\n","**Deliverable Type:**\n","internal memo shell\n","\n","**Situation:**\n","A global logistics company is facing margin pressure due to rising fuel costs and labor inflation. They operate 200 distribution centers across North America and employ 15,000 workers. The CFO has tasked our team with identifying 100-150M USD in cost savings over 18 months without compromising service levels. We need to structure our diagnostic approach covering procurement, network optimization, and operational efficiency.\n","\n","**Example 3: Meeting Agenda (Digital Transformation)**\n","\n","**Deliverable Type:**\n","meeting agenda\n","\n","**Situation:**\n","A traditional retail bank with 800 branches wants to modernize its technology stack and improve customer digital experience. Current online banking adoption is 45 percent compared to industry average of 70 percent. The CIO and Chief Customer Officer are sponsoring this initiative. We are facilitating a two-day workshop next month with 20 senior leaders to align on transformation priorities and governance model.\n","\n","**Example 4: Stakeholder Update Email (Post-Merger Integration)**\n","\n","**Deliverable Type:**\n","client email\n","\n","**Situation:**\n","Two healthcare providers merged six months ago. Integration workstreams cover IT systems, clinical protocols, supply chain consolidation, and organizational design. The Steering Committee meets monthly. We need to send an update to the Committee Chair summarizing progress in the last 30 days, highlighting three critical path items requiring executive decisions, and confirming next meeting date.\n","\n","**Tips for Creating Your Own Prompt**\n","\n","**Good prompts include:**\n","- Industry context (e.g., \"manufacturing company,\" \"financial services firm\")\n","- Scale indicators (e.g., \"500M revenue,\" \"15,000 employees,\" \"200 locations\")\n","- Specific business challenge (e.g., \"margin pressure,\" \"market entry,\" \"integration\")\n","- Key stakeholders (e.g., \"CEO,\" \"CFO,\" \"Steering Committee\")\n","- Timeframe or milestone (e.g., \"next week,\" \"18 months,\" \"Q2 deadline\")\n","\n","**Avoid including:**\n","- Real client names or identifying details\n","- Specific deal values that could identify transactions\n","- Proprietary strategy details\n","- Confidential financial metrics\n","\n","**Remember:** The redaction function will automatically mask emails, phone numbers, and other sensitive patterns, but it's best practice to avoid entering real confidential data in the first place.\n","\n","**What to Expect**\n","\n","After entering your prompt, Cell 9 will:\n","\n","1. Show you what sensitive information was redacted or flagged\n","2. Extract 2-3 core facts from your situation\n","3. Call Claude to draft your requested deliverable\n","4. Generate governance artifacts (assumptions, verification items, risks)\n","5. Save everything to the deliverables folder with \"Not verified\" labels\n","\n","The output will intentionally flag missing information and assumptions - this demonstrates the governance-first approach where AI helps you identify gaps rather than papering over them."],"metadata":{"id":"CbdzbO8EeuXW"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"q65FZs56NXZp"}},{"cell_type":"code","source":["\n","# Cell 9\n","# Type: Code\n","# Goal: User Exercise (Draft Your Own Deliverable Safely)\n","# Output: Print removed_fields summary + file paths saved\n","\n","print(\"=\" * 70)\n","print(\"USER EXERCISE: DRAFT YOUR CONSULTING DELIVERABLE\")\n","print(\"=\" * 70)\n","print(\"\\n‚ö†Ô∏è  CRITICAL: Do not paste confidential client information!\")\n","print(\"Redact all sensitive data before entering.\")\n","print(\"\\n\")\n","\n","# Get user input\n","deliverable_type = input(\"Deliverable type (client email / internal memo shell / meeting agenda): \").strip()\n","\n","print(\"\\nDescribe the situation (we will automatically redact sensitive info):\")\n","print(\"Example: 'Our client is considering expanding into renewable energy sector...\")\n","situation = input(\"\\nSituation: \").strip()\n","\n","if not situation:\n","    print(\"\\n‚ùå No situation provided. Skipping user exercise.\")\n","else:\n","    print(\"\\nüîí REDACTING SENSITIVE INFORMATION...\")\n","\n","    # Build minimum necessary\n","    min_necessary = build_minimum_necessary(situation)\n","\n","    print(\"\\n\" + \"-\" * 70)\n","    print(\"REDACTION SUMMARY:\")\n","    print(\"-\" * 70)\n","    if min_necessary[\"removed_fields\"]:\n","        print(\"Removed/flagged:\")\n","        for field in min_necessary[\"removed_fields\"]:\n","            print(f\"  ‚Ä¢ {field}\")\n","    else:\n","        print(\"  ‚Ä¢ No sensitive patterns detected (manual review still recommended)\")\n","    print(\"-\" * 70)\n","\n","    print(\"\\nSanitized facts extracted:\")\n","    for i, fact in enumerate(min_necessary[\"sanitized_facts\"], 1):\n","        print(f\"  {i}. {fact}\")\n","\n","    # Create intake\n","    user_intake = build_intake_record(\n","        case_name=\"user_exercise\",\n","        client_sensitivity=\"user_specified\",\n","        purpose=f\"User-requested {deliverable_type}\",\n","        scope_boundary=\"Level 1 drafting only\"\n","    )\n","    user_intake_path = deliverables_dir / \"user_intake.json\"\n","    write_json(user_intake_path, user_intake)\n","\n","    # Determine instruction based on deliverable type\n","    if \"email\" in deliverable_type.lower():\n","        instruction = \"Draft a brief professional email (3-5 sentences) based on the situation provided.\"\n","    elif \"memo\" in deliverable_type.lower():\n","        instruction = \"Draft an executive memo shell (outline with section headers and brief descriptions) based on the situation provided.\"\n","    elif \"agenda\" in deliverable_type.lower():\n","        instruction = \"Draft a meeting agenda with objectives, topics, and action items template based on the situation provided.\"\n","    else:\n","        instruction = f\"Draft a professional {deliverable_type} based on the situation provided.\"\n","\n","    print(\"\\n‚ñ∂ Calling Claude to draft your deliverable...\")\n","\n","    # Call Claude\n","    user_output = call_claude(\n","        task_name=\"user_exercise\",\n","        sanitized_facts=min_necessary[\"sanitized_facts\"],\n","        user_instruction=instruction,\n","        governance_context=\"User-provided exercise with redacted input\"\n","    )\n","\n","    # Save output\n","    user_output_path = deliverables_dir / \"user_output.json\"\n","    write_json(user_output_path, user_output)\n","\n","    # Create stubs\n","    user_assumptions = build_assumption_register_stub(user_output)\n","    user_assumptions_path = deliverables_dir / \"user_assumptions_stub.json\"\n","    write_json(user_assumptions_path, user_assumptions)\n","\n","    user_verification = build_verification_register_stub(user_output)\n","    user_verification_path = deliverables_dir / \"user_verification_stub.json\"\n","    write_json(user_verification_path, user_verification)\n","\n","    # Human readable\n","    user_disclaimers = [\n","        \"DRAFT ONLY - Not verified\",\n","        \"Human review REQUIRED\",\n","        \"User-provided scenario (redacted)\",\n","        \"No factual claims guaranteed\"\n","    ]\n","\n","    user_readable = render_human_readable(\n","        \"user_exercise\",\n","        user_output,\n","        user_disclaimers\n","    )\n","    user_readable_path = deliverables_dir / \"user_human_readable.txt\"\n","    user_readable_path.write_text(user_readable, encoding='utf-8')\n","\n","    # Update approvals log\n","    user_approval = build_approval_record(\"user_exercise\", \"User (self-review)\", \"pending\")\n","    approvals = read_json(approvals_log_path)\n","    approvals[\"approvals\"].append(user_approval)\n","    write_json(approvals_log_path, approvals)\n","\n","    print(\"\\n‚úÖ USER EXERCISE COMPLETE\")\n","    print(\"=\" * 70)\n","    print(\"Files saved:\")\n","    print(f\"  ‚Ä¢ {user_intake_path.name}\")\n","    print(f\"  ‚Ä¢ {user_output_path.name}\")\n","    print(f\"  ‚Ä¢ {user_assumptions_path.name}\")\n","    print(f\"  ‚Ä¢ {user_verification_path.name}\")\n","    print(f\"  ‚Ä¢ {user_readable_path.name}\")\n","    print(\"=\" * 70)\n","    print(f\"\\nüìù Draft output preview:\")\n","    print(\"-\" * 70)\n","    print(user_output['draft_output'][:300] + \"...\" if len(user_output['draft_output']) > 300 else user_output['draft_output'])\n","    print(\"-\" * 70)\n","    print(f\"\\n‚ö†Ô∏è  Verification status: {user_output['verification_status']}\")\n","    print(f\"‚ö†Ô∏è  Open questions: {len(user_output['open_questions'])}\")\n","    print(f\"‚ö†Ô∏è  Risks flagged: {len(user_output['risks'])}\")\n","    print(\"=\" * 70)\n"],"metadata":{"id":"h8-UJrsrNZmu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768830098064,"user_tz":360,"elapsed":61298,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"2d6682ea-ad45-4415-8a7b-d9a2a41411c9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","USER EXERCISE: DRAFT YOUR CONSULTING DELIVERABLE\n","======================================================================\n","\n","‚ö†Ô∏è  CRITICAL: Do not paste confidential client information!\n","Redact all sensitive data before entering.\n","\n","\n","Deliverable type (client email / internal memo shell / meeting agenda): **Deliverable Type:** meeting agenda  **Situation:** A traditional retail bank with 800 branches wants to modernize its technology stack and improve customer digital experience. Current online banking adoption is 45 percent compared to industry average of 70 percent. The CIO and Chief Customer Officer are sponsoring this initiative. We are facilitating a two-day workshop next month with 20 senior leaders to align on transformation priorities and governance model.\n","\n","Describe the situation (we will automatically redact sensitive info):\n","Example: 'Our client is considering expanding into renewable energy sector...\n","\n","Situation: A traditional retail bank with 800 branches wants to modernize its technology stack and improve customer digital experience. Current online banking adoption is 45 percent compared to industry average of 70 percent. The CIO and Chief Customer Officer are sponsoring this initiative. We are facilitating a two-day workshop next month with 20 senior leaders to align on transformation priorities and governance model.\n","\n","üîí REDACTING SENSITIVE INFORMATION...\n","\n","----------------------------------------------------------------------\n","REDACTION SUMMARY:\n","----------------------------------------------------------------------\n","Removed/flagged:\n","  ‚Ä¢ potential_person_names_detected (manual review required)\n","----------------------------------------------------------------------\n","\n","Sanitized facts extracted:\n","  1. A traditional retail bank with 800 branches wants to modernize its technology stack and improve customer digital experience\n","  2. Current online banking adoption is 45 percent compared to industry average of 70 percent\n","  3. The CIO and Chief Customer Officer are sponsoring this initiative\n","\n","‚ñ∂ Calling Claude to draft your deliverable...\n","\n","‚úÖ USER EXERCISE COMPLETE\n","======================================================================\n","Files saved:\n","  ‚Ä¢ user_intake.json\n","  ‚Ä¢ user_output.json\n","  ‚Ä¢ user_assumptions_stub.json\n","  ‚Ä¢ user_verification_stub.json\n","  ‚Ä¢ user_human_readable.txt\n","======================================================================\n","\n","üìù Draft output preview:\n","----------------------------------------------------------------------\n","MEETING AGENDA: Digital Modernization Initiative\n","\n","DATE: [To be scheduled]\n","DURATION: [To be determined]\n","LOCATION: [To be determined]\n","SPONSORS: Chief Information Officer, Chief Customer Officer\n","\n","I. MEETING OBJECTIVES\n","   ‚Ä¢ Align stakeholders on initiative scope and strategic priorities\n","   ‚Ä¢ Review curr...\n","----------------------------------------------------------------------\n","\n","‚ö†Ô∏è  Verification status: Not verified\n","‚ö†Ô∏è  Open questions: 10\n","‚ö†Ô∏è  Risks flagged: 4\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##10.AUDIT BUNDLE"],"metadata":{"id":"deALRI7DNc11"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"hspK-tF8Nd9D"}},{"cell_type":"markdown","source":["\n","\n","**What this cell does:**\n","\n","This final cell transforms your entire notebook session into a permanent, auditable record by creating comprehensive documentation and bundling everything into a single downloadable archive. Think of it as closing the books on a consulting engagement‚Äîyou're not just walking away with draft deliverables, you're creating a complete governance package that proves how the work was done, what controls were applied, and what still requires human attention before use.\n","\n","**Why the audit package matters:**\n","\n","In consulting and corporate strategy work, you're often asked months or years later to explain how you arrived at a recommendation, what information you relied on, or whether proper procedures were followed. When AI tools enter your workflow, these accountability questions become more complex. The audit package provides definitive answers. It shows which AI model was used, what parameters were set, what prompts were sent, what governance controls were active, and what risks were flagged‚Äîall in a format designed for review by compliance officers, regulators, clients, or internal quality assurance teams.\n","\n","**The AUDIT README file:**\n","\n","Before zipping everything, the cell creates a comprehensive README document that serves as your guide to the entire package. This isn't technical documentation for engineers‚Äîit's written for non-technical stakeholders who need to understand what happened during your AI-assisted drafting session.\n","\n","The README explains the purpose of the notebook, clearly stating this was Level One chatbot drafting with human oversight at every step. It describes each governance artifact and what it contains. Critically, it explains how to safely review the prompts log, emphasizing that full confidential content was never stored‚Äîonly cryptographic hashes and redacted excerpts. This protects you from creating a liability while maintaining accountability.\n","\n","The README also documents reproducibility information. It lists the exact AI model version, the parameters used, and the configuration hash. If someone needs to understand why outputs might differ in a future run or wants to verify your setup matched approved standards, they have everything needed. The README even points to the pip freeze file showing your complete Python environment, though this level of technical detail matters more for advanced users.\n","\n","**Multiple reminder layers:**\n","\n","Throughout the README, you'll see repeated warnings that all outputs are marked not verified and require human review. This repetition is intentional. The document assumes it might be read months later by someone unfamiliar with the session, possibly in a high-pressure situation where there's temptation to treat AI drafts as authoritative. The multiple reminders make it nearly impossible to claim you weren't warned.\n","\n","**The ZIP archive:**\n","\n","After creating the README, the cell bundles your entire run directory into a single compressed file. This includes the manifest, all governance logs, every deliverable from the four mini-cases, your user exercise outputs, the environment snapshot, and the README itself. Everything is timestamped and uniquely identified by the run ID generated way back in Cell Two.\n","\n","The cell uses Python's built-in archiving tools to create this ZIP file reliably in the Colab environment. It then verifies the archive was created successfully and provides you with the exact file path so you can download it before your Colab session ends.\n","\n","**The contents inventory:**\n","\n","Before finishing, the cell walks through every file in your run directory and prints a detailed inventory. You see each filename, its location within the folder structure, and its size. This serves two purposes. First, it's a final verification that everything you expected to create actually exists. Second, it helps you understand the scope of what you're preserving‚Äîyou're not just saving one draft email, you're documenting an entire governance-controlled workflow.\n","\n","**The final checklist:**\n","\n","The cell concludes with a simple checklist showing whether each major governance artifact was successfully created. Run manifest‚Äîcheck. Prompts log‚Äîcheck. Risk log‚Äîcheck. You get visual confirmation with checkmarks or warnings if anything is missing. This prevents you from discovering weeks later that a critical audit file wasn't saved.\n","\n","**Download instructions:**\n","\n","Because Colab sessions are temporary and files disappear when you close the browser, the cell provides explicit guidance on downloading your archive. It reminds you to click the folder icon in the left sidebar and save the ZIP file to your local system or cloud storage before ending the session.\n","\n","**The governance culture message:**\n","\n","This final cell embodies a critical principle for AI adoption in professional services: tools that increase capability must be accompanied by proportionally stronger accountability mechanisms. You're not just learning how to draft faster with AI‚Äîyou're learning how to do it in a way that withstands scrutiny, protects confidentiality, and maintains professional standards. The audit package proves you took governance seriously from start to finish."],"metadata":{"id":"QktoO36gNwPN"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"-qPlPvQYNhIv"}},{"cell_type":"code","source":["\n","\n","# Cell 10\n","# Type: Code\n","# Goal: Bundle + AUDIT_README + Zip\n","# Output: Print zip filepath and artifact checklist\n","\n","print(\"=\" * 70)\n","print(\"CREATING AUDIT BUNDLE\")\n","print(\"=\" * 70)\n","\n","# Create AUDIT_README\n","audit_readme_content = f\"\"\"\n","{'=' * 70}\n","AI CONSULTING CHAPTER 1 - LEVEL 1 (CHATBOTS) AUDIT PACKAGE\n","{'=' * 70}\n","\n","Run ID: {run_id}\n","Generated: {now_iso()}\n","Model: {MODEL}\n","Parameters: temperature=0.2, max_tokens=4128\n","Config Hash: {config_hash}\n","\n","{'=' * 70}\n","PURPOSE\n","{'=' * 70}\n","\n","This notebook demonstrates Level 1 AI capabilities for management consulting:\n","- DRAFTING SUPPORT ONLY (emails, memos, agendas, workplans)\n","- Human-in-the-loop for every output\n","- Governance-first approach with full traceability\n","- NO autonomous agents, NO multi-step tool use, NO web access\n","\n","All outputs are marked \"Not verified\" and require human review before use.\n","\n","{'=' * 70}\n","GOVERNANCE ARTIFACTS\n","{'=' * 70}\n","\n","This package contains the following governance artifacts:\n","\n","1. run_manifest.json\n","   - Run metadata (timestamp, model, parameters, environment)\n","   - Config hash for reproducibility\n","\n","2. prompts_log.jsonl\n","   - REDACTED log of all API calls (stores hashes only)\n","   - Prompt and response excerpts are redacted\n","   - Includes parsing status and error handling\n","   - Format: One JSON object per line (JSONL)\n","\n","3. risk_log.json\n","   - Aggregated risk register\n","   - Risk types: hallucination, missing_facts, decision_laundering,\n","     scope_creep, client_sensitivity, traceability\n","   - Severity levels: low, medium, high\n","\n","4. verification_register.json\n","   - Claims and questions requiring human verification\n","   - Verification status tracking\n","\n","5. change_log.json\n","   - Document version control (stub)\n","\n","6. approvals_log.json\n","   - Approval workflow records\n","   - All marked as \"pending\" (Not verified)\n","\n","7. deliverables/\n","   - All draft outputs (JSON + human-readable text)\n","   - Per-case artifacts (intake, assumptions, verification stubs)\n","\n","8. pip_freeze.txt\n","   - Python environment snapshot\n","\n","{'=' * 70}\n","HOW TO REVIEW PROMPTS_LOG SAFELY\n","{'=' * 70}\n","\n","The prompts_log.jsonl file contains REDACTED excerpts only:\n","- Full prompts/responses are NOT stored (confidentiality protection)\n","- Only SHA256 hashes are stored for traceability\n","- Redacted excerpts (first 500 chars) are provided for context\n","- Parsing status indicates if JSON validation succeeded\n","\n","To review:\n","1. Open prompts_log.jsonl in a text editor\n","2. Each line is a separate JSON object (one API call)\n","3. Check \"parsing.status\" field: ok / retry_ok / fail\n","4. Review \"redaction_summary\" for what was removed\n","5. Use hashes to verify prompt/response integrity if needed\n","\n","{'=' * 70}\n","REPRODUCIBILITY\n","{'=' * 70}\n","\n","To reproduce this run:\n","1. Use same model: {MODEL}\n","2. Use same parameters: temperature=0.2, max_tokens=4128\n","3. Verify config_hash matches: {config_hash}\n","4. Install dependencies from pip_freeze.txt\n","5. Re-run notebook with same inputs\n","\n","Note: LLM outputs are non-deterministic even with low temperature.\n","Hashes will differ, but content should be similar.\n","\n","{'=' * 70}\n","CRITICAL REMINDERS\n","{'=' * 70}\n","\n","‚ö†Ô∏è  ALL OUTPUTS ARE \"NOT VERIFIED\" DRAFTS\n","\n","‚ö†Ô∏è  HUMAN REVIEW REQUIRED BEFORE USE\n","\n","‚ö†Ô∏è  NO FACTUAL CLAIMS GUARANTEED\n","\n","‚ö†Ô∏è  CONFIDENTIALITY RISKS - Do not share raw client data\n","\n","‚ö†Ô∏è  THIS IS LEVEL 1 ONLY - No autonomous decision-making\n","\n","{'=' * 70}\n","QUESTIONS OR ISSUES?\n","{'=' * 70}\n","\n","This notebook is for educational/demonstration purposes.\n","Review all governance artifacts before using outputs in client work.\n","\n","Author: Alejandro Reynoso\n","Chief Scientist, DEFI CAPITAL RESEARCH\n","External Lecturer, Judge Business School Cambridge\n","\n","{'=' * 70}\n","\"\"\"\n","\n","audit_readme_path = run_dir / \"AUDIT_README.txt\"\n","audit_readme_path.write_text(audit_readme_content, encoding='utf-8')\n","\n","print(f\"‚úÖ Created: AUDIT_README.txt\")\n","\n","# Create zip archive\n","zip_filename = f\"{run_id}.zip\"\n","zip_path = base_dir / zip_filename\n","\n","print(f\"\\nüì¶ Creating ZIP archive...\")\n","print(f\"   Source: {run_dir}\")\n","print(f\"   Target: {zip_path}\")\n","\n","# Use subprocess to create zip (more reliable in Colab)\n","import shutil\n","shutil.make_archive(\n","    str(base_dir / run_id),\n","    'zip',\n","    str(run_dir.parent),\n","    str(run_dir.name)\n",")\n","\n","print(f\"\\n‚úÖ ZIP ARCHIVE CREATED\")\n","print(\"=\" * 70)\n","\n","# List contents\n","print(\"\\nüìã AUDIT PACKAGE CONTENTS:\")\n","print(\"-\" * 70)\n","\n","all_files = sorted(run_dir.rglob(\"*\"))\n","file_count = 0\n","\n","for file_path in all_files:\n","    if file_path.is_file():\n","        rel_path = file_path.relative_to(run_dir)\n","        size = file_path.stat().st_size\n","        size_kb = size / 1024\n","        print(f\"  ‚Ä¢ {rel_path} ({size_kb:.1f} KB)\")\n","        file_count += 1\n","\n","print(\"-\" * 70)\n","print(f\"Total files: {file_count}\")\n","print(\"=\" * 70)\n","\n","# Final checklist\n","print(\"\\n‚úÖ FINAL CHECKLIST:\")\n","print(\"-\" * 70)\n","checklist_items = [\n","    (\"Run manifest\", (run_dir / \"run_manifest.json\").exists()),\n","    (\"Prompts log (REDACTED)\", (run_dir / \"prompts_log.jsonl\").exists()),\n","    (\"Risk log\", (run_dir / \"risk_log.json\").exists()),\n","    (\"Verification register\", (run_dir / \"verification_register.json\").exists()),\n","    (\"Change log\", (run_dir / \"change_log.json\").exists()),\n","    (\"Approvals log\", (run_dir / \"approvals_log.json\").exists()),\n","    (\"Deliverables folder\", deliverables_dir.exists() and any(deliverables_dir.iterdir())),\n","    (\"AUDIT_README\", audit_readme_path.exists()),\n","    (\"ZIP archive\", zip_path.exists()),\n","]\n","\n","for item, status in checklist_items:\n","    status_icon = \"‚úÖ\" if status else \"‚ùå\"\n","    print(f\"  {status_icon} {item}\")\n","\n","print(\"-\" * 70)\n","print(\"\\nüì¶ DOWNLOAD YOUR AUDIT PACKAGE:\")\n","print(f\"   {zip_path}\")\n","print(\"\\nüí° TIP: Click the folder icon in the left sidebar to download files\")\n","print(\"=\" * 70)\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"NOTEBOOK EXECUTION COMPLETE\")\n","print(\"=\" * 70)\n","print(f\"Run ID: {run_id}\")\n","print(f\"Total deliverables created: {len(list(deliverables_dir.glob('*')))}\")\n","print(f\"Total risks logged: {len(read_json(risk_log_path)['risks'])}\")\n","print(f\"ZIP archive: {zip_path}\")\n","print(\"\\n‚ö†Ô∏è  REMEMBER: All outputs are 'Not verified' and require human review\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_i4UQnpY9yLK","executionInfo":{"status":"ok","timestamp":1768830323044,"user_tz":360,"elapsed":35,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"19c1bb67-0867-4085-c6cc-75b3f0bf2771"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CREATING AUDIT BUNDLE\n","======================================================================\n","‚úÖ Created: AUDIT_README.txt\n","\n","üì¶ Creating ZIP archive...\n","   Source: /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781\n","   Target: /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781.zip\n","\n","‚úÖ ZIP ARCHIVE CREATED\n","======================================================================\n","\n","üìã AUDIT PACKAGE CONTENTS:\n","----------------------------------------------------------------------\n","  ‚Ä¢ AUDIT_README.txt (4.3 KB)\n","  ‚Ä¢ approvals_log.json (1.3 KB)\n","  ‚Ä¢ change_log.json (0.0 KB)\n","  ‚Ä¢ deliverables/capital_allocation_approval_stub.json (0.2 KB)\n","  ‚Ä¢ deliverables/capital_allocation_assumptions_memo.json (2.8 KB)\n","  ‚Ä¢ deliverables/capital_allocation_assumptions_stub.json (1.2 KB)\n","  ‚Ä¢ deliverables/capital_allocation_human_readable.txt (5.8 KB)\n","  ‚Ä¢ deliverables/capital_allocation_ic_preread_shell.json (5.2 KB)\n","  ‚Ä¢ deliverables/capital_allocation_intake.json (0.4 KB)\n","  ‚Ä¢ deliverables/capital_allocation_meeting_prep_email.json (2.6 KB)\n","  ‚Ä¢ deliverables/capital_allocation_verification_stub.json (1.6 KB)\n","  ‚Ä¢ deliverables/cost_transformation_approval_stub.json (0.2 KB)\n","  ‚Ä¢ deliverables/cost_transformation_assumptions_stub.json (1.3 KB)\n","  ‚Ä¢ deliverables/cost_transformation_data_request_list.json (4.7 KB)\n","  ‚Ä¢ deliverables/cost_transformation_human_readable.txt (4.1 KB)\n","  ‚Ä¢ deliverables/cost_transformation_intake.json (0.4 KB)\n","  ‚Ä¢ deliverables/cost_transformation_stakeholder_update.json (3.0 KB)\n","  ‚Ä¢ deliverables/cost_transformation_verification_stub.json (1.5 KB)\n","  ‚Ä¢ deliverables/cost_transformation_workplan_narrative.json (3.4 KB)\n","  ‚Ä¢ deliverables/market_entry_approval_stub.json (0.2 KB)\n","  ‚Ä¢ deliverables/market_entry_assumptions_stub.json (1.0 KB)\n","  ‚Ä¢ deliverables/market_entry_client_email.json (2.5 KB)\n","  ‚Ä¢ deliverables/market_entry_human_readable.txt (3.2 KB)\n","  ‚Ä¢ deliverables/market_entry_intake.json (0.4 KB)\n","  ‚Ä¢ deliverables/market_entry_meeting_agenda.json (5.9 KB)\n","  ‚Ä¢ deliverables/market_entry_memo_shell.json (4.7 KB)\n","  ‚Ä¢ deliverables/market_entry_verification_stub.json (1.4 KB)\n","  ‚Ä¢ deliverables/operating_model_approval_stub.json (0.2 KB)\n","  ‚Ä¢ deliverables/operating_model_assumptions_stub.json (1.3 KB)\n","  ‚Ä¢ deliverables/operating_model_followup_email.json (3.2 KB)\n","  ‚Ä¢ deliverables/operating_model_human_readable.txt (4.1 KB)\n","  ‚Ä¢ deliverables/operating_model_intake.json (0.4 KB)\n","  ‚Ä¢ deliverables/operating_model_raci_narrative.json (3.4 KB)\n","  ‚Ä¢ deliverables/operating_model_verification_stub.json (1.2 KB)\n","  ‚Ä¢ deliverables/operating_model_workshop_agenda.json (6.4 KB)\n","  ‚Ä¢ deliverables/user_assumptions_stub.json (1.4 KB)\n","  ‚Ä¢ deliverables/user_human_readable.txt (5.4 KB)\n","  ‚Ä¢ deliverables/user_intake.json (0.8 KB)\n","  ‚Ä¢ deliverables/user_output.json (4.8 KB)\n","  ‚Ä¢ deliverables/user_verification_stub.json (1.7 KB)\n","  ‚Ä¢ pip_freeze.txt (12.6 KB)\n","  ‚Ä¢ prompts_log.jsonl (21.8 KB)\n","  ‚Ä¢ risk_log.json (19.4 KB)\n","  ‚Ä¢ run_manifest.json (0.6 KB)\n","  ‚Ä¢ verification_register.json (5.9 KB)\n","----------------------------------------------------------------------\n","Total files: 45\n","======================================================================\n","\n","‚úÖ FINAL CHECKLIST:\n","----------------------------------------------------------------------\n","  ‚úÖ Run manifest\n","  ‚úÖ Prompts log (REDACTED)\n","  ‚úÖ Risk log\n","  ‚úÖ Verification register\n","  ‚úÖ Change log\n","  ‚úÖ Approvals log\n","  ‚úÖ Deliverables folder\n","  ‚úÖ AUDIT_README\n","  ‚úÖ ZIP archive\n","----------------------------------------------------------------------\n","\n","üì¶ DOWNLOAD YOUR AUDIT PACKAGE:\n","   /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781.zip\n","\n","üí° TIP: Click the folder icon in the left sidebar to download files\n","======================================================================\n","\n","======================================================================\n","NOTEBOOK EXECUTION COMPLETE\n","======================================================================\n","Run ID: run_20260119_121343_14b2e781\n","Total deliverables created: 37\n","Total risks logged: 56\n","ZIP archive: /content/ai_consulting_ch1_runs/run_20260119_121343_14b2e781.zip\n","\n","‚ö†Ô∏è  REMEMBER: All outputs are 'Not verified' and require human review\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSIONS"],"metadata":{"id":"7X2_AKt3NkAR"}},{"cell_type":"markdown","source":["**Concluding Remarks: Building Professional Judgment in the Age of AI**\n","\n","**What You've Accomplished**\n","\n","You've just completed a comprehensive exploration of governance-first AI deployment for professional consulting work. Over ten carefully structured cells, you've moved from foundational concepts through practical demonstrations to hands-on application. More importantly, you've internalized a framework for thinking about AI tools that will serve you regardless of how rapidly the technology evolves or which specific models become dominant in your field.\n","\n","You now understand that professional use of AI differs fundamentally from casual chatbot interactions. You've seen confidentiality protection implemented through systematic redaction rather than relying on memory and good intentions. You've experienced quality control wrappers that validate outputs against strict schemas and automatically flag risks like hallucinations, decision laundering, and scope creep. You've worked with governance artifacts‚Äîmanifests, prompt logs, risk registers, verification registers, and approval workflows‚Äîthat create accountability and traceability for every AI interaction.\n","\n","Perhaps most valuably, you've developed intuition about the boundary between appropriate and inappropriate AI delegation. You understand that Level One means drafting support with human review at every step, not autonomous analysis or decision-making. You recognize that \"Not verified\" isn't a formality but a critical reminder that professional judgment cannot be outsourced to algorithms, no matter how impressive their outputs appear.\n","\n","**The Governance Mindset**\n","\n","The technical skills you've acquired‚Äîcalling APIs, validating JSON schemas, logging interactions, bundling audit packages‚Äîmatter less than the governance mindset underlying them. This mindset rests on several core principles that should guide your AI adoption journey beyond this notebook.\n","\n","First, capability and control must advance together. As AI systems become more powerful, producing longer documents, handling more complex instructions, and generating increasingly sophisticated analysis, your governance mechanisms must strengthen proportionally. The temptation will be to relax controls as AI becomes more reliable, but this inverts the correct relationship. Greater capability means greater potential for harm when things go wrong, requiring more robust safeguards, not fewer.\n","\n","Second, transparency trumps convenience. It would be simpler to accept whatever the AI returns without demanding structured outputs, explicit assumption lists, and risk flagging. The structured approach requires more upfront design work and creates more artifacts to review. But this transparency protects you when questions arise months or years later about how deliverables were created. The inconvenience of documentation today becomes your shield against accountability gaps tomorrow.\n","\n","Third, verification is mandatory, not optional. Every number, statistic, benchmark, regulatory claim, or factual assertion that appears in AI-generated drafts must be traced to reliable sources or explicitly flagged for human fact-checking. The verification register you've learned to maintain isn't bureaucratic overhead‚Äîit's the mechanism preventing hallucinated content from entering client work and undermining your credibility. Professional reputation takes years to build and moments to destroy through preventable errors.\n","\n","Fourth, confidentiality is structural, not behavioral. Hoping people will remember to redact sensitive information before using AI tools is insufficient. You need automated detection, forced review of flagged content, logging of what was removed, and technical barriers preventing raw confidential data from reaching external systems. The redaction utilities in this notebook represent minimum viable protection‚Äîyour organization may need stronger controls depending on your regulatory environment and client obligations.\n","\n","Fifth, human judgment remains sovereign. AI drafts email openings, structures memo sections, and suggests meeting agenda items, but it doesn't decide strategy, assess risk, or make recommendations. The decision laundering detection you've seen‚Äîflagging phrases like \"we analyzed\" or \"our research indicates\" when no such work occurred‚Äîprotects against the insidious drift where AI outputs become mistaken for completed professional analysis. You must remain the expert, with AI serving as a productivity tool, not a substitute for your judgment.\n","\n","**The Road Ahead: Levels Two and Three**\n","\n","This notebook focused exclusively on Level One capabilities‚Äîsingle-turn drafting interactions with explicit human review. But AI deployment in consulting will evolve through progressively more autonomous levels, and you should understand what's coming even if you're not ready to implement it yet.\n","\n","Level Two introduces multi-step workflows where AI systems can chain together related tasks with periodic human checkpoints rather than continuous oversight. An example might be an AI agent that drafts a memo, identifies missing data, queries internal databases to fill gaps, revises the draft, and presents a refined version for review‚Äîall within guardrails you've defined. This requires more sophisticated governance including workflow audit trails, checkpoint validation, and rollback mechanisms when agents veer off track.\n","\n","Level Three encompasses AI systems that conduct substantial analysis, synthesize information across multiple sources, and develop strategic recommendations that humans then evaluate and refine. This might involve market research synthesis, competitive analysis, scenario modeling, or risk assessment where AI processes large datasets and complex frameworks beyond practical human analysis scope. The governance requirements here become extensive‚Äîyou need methodology validation, assumption testing, sensitivity analysis, competing hypothesis exploration, and rigorous verification of every substantive claim.\n","\n","Each level multiplies both capability and risk. The governance principles you've learned in Level One‚Äîconfidentiality protection, output validation, audit trails, verification requirements, human sovereignty‚Äîapply with increasing importance as autonomy increases. Organizations that master Level One governance before advancing to Level Two, and master Level Two before attempting Level Three, will deploy AI safely and effectively. Those that leap ahead without adequate controls will experience breaches, errors, and accountability failures that damage client relationships and professional reputation.\n","\n","**Integrating This Into Your Practice**\n","\n","The immediate question becomes: how do you actually use what you've learned in your day-to-day consulting work? Several pathways exist depending on your role and organizational context.\n","\n","If you're an individual consultant or corporate strategist working independently, you can begin using modified versions of this notebook immediately for appropriate drafting tasks. Start with low-stakes deliverables‚Äîinternal team emails, meeting prep notes, first-draft workplan narratives‚Äîwhere errors have limited consequences. Build confidence with the governance workflows before expanding to client-facing materials. Maintain your audit packages systematically even when no one is asking for them, establishing good habits before they become mandatory.\n","\n","If you're part of a consulting firm or corporate strategy function, socialize this governance-first approach with leadership and peers. Many organizations are simultaneously excited about AI productivity gains and anxious about risks they don't fully understand. You can bridge this gap by demonstrating that responsible AI adoption is achievable with appropriate controls. Propose pilot programs applying these governance principles to specific engagement types or internal processes, measuring both productivity benefits and control effectiveness.\n","\n","If you're in a risk, compliance, or quality assurance role, use this notebook as a reference architecture for what good AI governance looks like in professional services. The artifacts generated‚Äîmanifests, prompt logs, risk registers, verification registers, approval workflows‚Äîprovide concrete examples you can adapt into enterprise policies and standards. The principles of confidentiality protection, output validation, and audit trails translate across different AI tools and use cases.\n","\n","Regardless of your role, recognize that AI governance is not a solved problem handed down by authorities but an evolving practice where early adopters are still figuring out what works. Your experiences applying these principles in real consulting situations will teach you nuances that no notebook can anticipate. Document what works, what fails, and what needs modification. Share lessons learned with your professional community. The collective learning happening now across consulting, finance, law, and other professional services will shape how these tools are used for decades to come.\n","\n","**Final Reflection**\n","\n","The introduction of AI into professional consulting represents neither utopia nor catastrophe but rather a choice point. Organizations and individuals can deploy these tools recklessly, chasing productivity gains while ignoring governance gaps, and experience the predictable consequences‚Äîconfidentiality breaches, factual errors, accountability failures, and erosion of professional standards. Or they can adopt the governance-first approach you've learned here, building capability and control together, maintaining transparency and human judgment, and demonstrating that powerful AI tools can be integrated responsibly into high-stakes work.\n","\n","Your mastery of this notebook positions you to be part of the solution rather than the problem. You understand that using AI professionally means more than typing prompts and copying outputs‚Äîit means systematic confidentiality protection, rigorous output validation, comprehensive audit trails, mandatory verification of factual claims, and unwavering human sovereignty over judgment and decision-making.\n","\n","As you close this notebook and return to your consulting practice, carry forward not just the technical procedures but the underlying mindset. Question capability without control. Insist on transparency. Demand verification. Protect confidentiality structurally. Preserve human judgment. These principles will serve you well as AI capabilities continue their exponential growth and the professional services industry navigates the complex transition ahead.\n","\n","The future of AI-assisted consulting belongs to those who take governance seriously from day one. Welcome to that future."],"metadata":{"id":"cD-yzw1ag6k6"}},{"cell_type":"markdown","source":["##12.DEPENDENCY MAP"],"metadata":{"id":"A1GG2BmedrSI"}},{"cell_type":"markdown","source":["\n","\n","**CELL 2: Setup**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| `Path.mkdir()` | Timestamp + UUID (hardcoded) | Creates `run_dir/` and `deliverables_dir/` folders. Used by ALL cells for file storage |\n","\n","\n","**CELL 3: API Initialization**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| `userdata.get()` | Google Colab Secrets (user configured) | `ANTHROPIC_API_KEY` variable |\n","| `anthropic.Anthropic()` | `ANTHROPIC_API_KEY` | `client` object (global). Used by `call_claude()` in Cell 6 |\n","\n","\n","\n","**CELL 4: Governance Utilities**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| `now_iso()` | System clock | Timestamps for ALL governance records. Used by Cells 6, 7, 8, 9 |\n","| `sha256_text()` | Text strings | Hashes stored in `prompts_log.jsonl` and `run_manifest.json`. Used by `log_call_event()` and `stable_config_hash()` |\n","| `write_json()` | File path + Python dict/list | Saves ALL `.json` files to disk. Used by Cells 4, 6, 7, 8, 9, 10 |\n","| `read_json()` | File path | Returns dict/list from `.json` file. Used by `call_claude()` (Cell 6) and Cells 8, 9, 10 |\n","| `append_jsonl()` | File path + record dict | Appends line to `prompts_log.jsonl`. Used by `log_call_event()` (Cell 6) |\n","| `get_env_fingerprint()` | System environment (subprocess pip freeze) | `env_fingerprint` dict saved in `run_manifest.json` |\n","| `stable_config_hash()` | Config dict | `config_hash` string saved in `run_manifest.json` and all log entries |\n","\n","\n","\n","**CELL 5: Confidentiality Utilities**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| `redact()` | Text string (potentially sensitive) | Redacted text + list of `removed_fields`. Used by `build_minimum_necessary()` and `log_call_event()` |\n","| `build_minimum_necessary()` | Raw text string | Dict with `sanitized_facts`, `removed_fields`, `redacted_preview`. Used by Cell 9 |\n","| `consulting_guardrails()` | None (returns hardcoded text) | Governance rules string prepended to system prompt. Used by `call_claude()` (Cell 6) |\n","\n","\n","**CELL 6: LLM Wrapper**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| `validate_schema()` | Python dict (AI response) | `(is_valid, error_message)` tuple. Used internally by `call_claude()` |\n","| `extract_json_strict()` | Response text from AI | `(parsed_obj, error)` tuple. Used internally by `call_claude()` |\n","| `log_call_event()` | `task_name`, `prompt_text`, `response_text`, `model`, `params`, `parsing_status` | Appends record to `prompts_log.jsonl`. Called by `call_claude()` |\n","| `call_claude()` | `task_name`, `sanitized_facts` (list), `user_instruction` (string), `governance_context` (string) | Returns validated `output_json` dict. Updates `risk_log.json`. Used by Cells 6 (smoke test), 8 (mini-cases), 9 (user exercise) |\n","\n","\n","**CELL 7: Draft Builders**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| `build_intake_record()` | `case_name`, `client_sensitivity`, `purpose`, `scope_boundary` (from case definitions) | Intake dict saved as `case_intake.json`. Used by Cells 8, 9 |\n","| `build_assumption_register_stub()` | `output_json` from `call_claude()` (specifically the `assumptions` field) | List of assumption records saved as `case_assumptions_stub.json`. Used by Cells 8, 9 |\n","| `build_verification_register_stub()` | `output_json` from `call_claude()` (specifically the `questions_to_verify` field) | List of verification records saved as `case_verification_stub.json` and appended to global `verification_register.json`. Used by Cells 8, 9 |\n","| `build_approval_record()` | `case_name`, `reviewer_role`, `approval_state` | Approval dict saved as `case_approval_stub.json` and appended to global `approvals_log.json`. Used by Cells 8, 9 |\n","| `render_human_readable()` | `case_name`, `output_json` from `call_claude()`, `disclaimers` list | Formatted text string saved as `case_human_readable.txt`. Used by Cells 8, 9 |\n","\n","\n","**CELL 8: Mini-Cases Execution**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| **Hardcoded case definitions** | Defined at top of Cell 8 in `mini_cases` list | Provides `case_name`, `sanitized_facts`, `tasks`, `client_sensitivity`, `purpose`, `scope_boundary` |\n","| `build_intake_record()` | Case definition fields | `case_intake.json` file |\n","| `call_claude()` | `sanitized_facts` + `instruction` from case definition | `output_json` dict saved as `case_task.json` |\n","| `build_assumption_register_stub()` | `output_json` from `call_claude()` | `case_assumptions_stub.json` file |\n","| `build_verification_register_stub()` | `output_json` from `call_claude()` | `case_verification_stub.json` + updates global `verification_register.json` |\n","| `build_approval_record()` | `case_name` from case definition | `case_approval_stub.json` + updates global `approvals_log.json` |\n","| `render_human_readable()` | `case_name` + `output_json` + constructed disclaimers | `case_human_readable.txt` file |\n","\n","**Flow Summary for Cell 8:**\n","```\n","Case Definition ‚Üí build_intake_record() ‚Üí intake.json\n","                ‚Üí call_claude() ‚Üí output_json\n","                                ‚Üí build_assumption_register_stub() ‚Üí assumptions.json\n","                                ‚Üí build_verification_register_stub() ‚Üí verification.json\n","                                ‚Üí render_human_readable() ‚Üí human_readable.txt\n","                                ‚Üí Saved directly as task.json\n","                ‚Üí build_approval_record() ‚Üí approval.json\n","```\n","\n","\n","**CELL 9: User Exercise**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| `input()` | **USER KEYBOARD INPUT** (deliverable type + situation description) | Raw text strings |\n","| `build_minimum_necessary()` | User's situation text | `sanitized_facts`, `removed_fields`, `redacted_preview` |\n","| `build_intake_record()` | User's inputs | `user_intake.json` file |\n","| `call_claude()` | `sanitized_facts` from `build_minimum_necessary()` + constructed instruction | `output_json` dict saved as `user_output.json` |\n","| `build_assumption_register_stub()` | `output_json` from `call_claude()` | `user_assumptions_stub.json` file |\n","| `build_verification_register_stub()` | `output_json` from `call_claude()` | `user_verification_stub.json` file |\n","| `build_approval_record()` | Hardcoded \"user_exercise\" case name | Updates global `approvals_log.json` |\n","| `render_human_readable()` | `output_json` + constructed disclaimers | `user_human_readable.txt` file |\n","\n","**Flow Summary for Cell 9:**\n","```\n","USER INPUT ‚Üí build_minimum_necessary() ‚Üí sanitized_facts\n","                                       ‚Üí build_intake_record() ‚Üí user_intake.json\n","                                       ‚Üí call_claude() ‚Üí output_json\n","                                                       ‚Üí build_assumption_register_stub() ‚Üí user_assumptions.json\n","                                                       ‚Üí build_verification_register_stub() ‚Üí user_verification.json\n","                                                       ‚Üí render_human_readable() ‚Üí user_human_readable.txt\n","                                                       ‚Üí Saved as user_output.json\n","                                       ‚Üí build_approval_record() ‚Üí updates approvals_log.json\n","```\n","\n","\n","**CELL 10: Bundle and Zip**\n","\n","| Function | Input Source | Output Destination |\n","|----------|-------------|-------------------|\n","| `Path.write_text()` | Constructed `AUDIT_README` content string | `AUDIT_README.txt` file in `run_dir/` |\n","| `shutil.make_archive()` | `run_dir/` path (entire directory) | ZIP file containing all governance artifacts and deliverables |\n","| `Path.rglob()` | `run_dir/` path | List of all files for inventory printout |\n","\n","\n","\n","**KEY INSIGHTS**\n","\n","**Central Hub Functions (Used by Multiple Cells):**\n","\n","- `call_claude()` - Used by Cells 6, 8, 9\n","- `write_json()` - Used by Cells 4, 6, 7, 8, 9, 10\n","- `read_json()` - Used by Cells 6, 8, 9, 10\n","- `now_iso()` - Used by Cells 4, 6, 7, 8, 9\n","\n","**One-Way Flow:**\n","\n","Most functions transform data and save to files. Files are **END POINTS** - they don't feed back into other functions (except global registers like `risk_log.json`, `verification_register.json`, `approvals_log.json` which accumulate records).\n","\n","**Data Origins:**\n","\n","- **Cell 8**: Data comes from hardcoded case definitions\n","- **Cell 9**: Data comes from user keyboard input\n","- **All Cells**: Governance metadata (timestamps, hashes, config) comes from system state"],"metadata":{"id":"-iaJHJc8dvwi"}}]}