{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNfUFiEAk7yhknR5rOswR/w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**AI CONSULTING CHAPTER 5: ORGANIZATIONS**\n","\n","---"],"metadata":{"id":"cnQK8yTVMAhC"}},{"cell_type":"markdown","source":["##0.REFERENCE"],"metadata":{"id":"tw2-7uYoMGHg"}},{"cell_type":"markdown","source":[],"metadata":{"id":"axSMA0YpNnYX"}},{"cell_type":"markdown","source":["##1.CONTEXT"],"metadata":{"id":"4LFo5LtiMIff"}},{"cell_type":"markdown","source":[],"metadata":{"id":"6n-x0MLbMKUs"}},{"cell_type":"markdown","source":["##2.LIBRARIES AND ENVIRONMENT"],"metadata":{"id":"HzSSYRQ0MKs8"}},{"cell_type":"code","source":["# Cell 2: Install + Imports + Run Directory\n","\n","# Install Anthropic SDK\n","!pip install -q anthropic\n","\n","# Imports\n","import json\n","import os\n","import re\n","import datetime\n","import hashlib\n","import platform\n","import textwrap\n","import subprocess\n","import uuid\n","from pathlib import Path\n","\n","# Create base run directory with timestamp and short ID\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","short_id = str(uuid.uuid4())[:8]\n","run_name = f\"run_{timestamp}_{short_id}\"\n","\n","base_dir = Path(\"/content/ai_consulting_ch5_runs\")\n","run_dir = base_dir / run_name\n","\n","# Create directory structure\n","run_dir.mkdir(parents=True, exist_ok=True)\n","(run_dir / \"deliverables\").mkdir(exist_ok=True)\n","(run_dir / \"stage_outputs\").mkdir(exist_ok=True)\n","(run_dir / \"asset_bundles\").mkdir(exist_ok=True)\n","(run_dir / \"logs\").mkdir(exist_ok=True)\n","\n","print(\"=\" * 70)\n","print(\"LEVEL 5 (ORGANIZATIONS) â€” RUN DIRECTORY INITIALIZED\")\n","print(\"=\" * 70)\n","print(f\"\\nðŸ“ Run Directory: {run_dir}\")\n","print(f\"   Run Name: {run_name}\")\n","print(f\"\\nðŸ“‚ Subdirectories created:\")\n","print(f\"   â”œâ”€â”€ deliverables/\")\n","print(f\"   â”œâ”€â”€ stage_outputs/\")\n","print(f\"   â”œâ”€â”€ asset_bundles/\")\n","print(f\"   â””â”€â”€ logs/\")\n","print(f\"\\nâœ“ Ready for governance artifacts initialization (Cell 4)\")\n","print(\"=\" * 70)"],"metadata":{"id":"TOYUwL9vMKKC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768927364808,"user_tz":360,"elapsed":4829,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"a590ea19-1e2c-4919-8aea-1e4a16cfabc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","LEVEL 5 (ORGANIZATIONS) â€” RUN DIRECTORY INITIALIZED\n","======================================================================\n","\n","ðŸ“ Run Directory: /content/ai_consulting_ch5_runs/run_20260120_164244_582e182e\n","   Run Name: run_20260120_164244_582e182e\n","\n","ðŸ“‚ Subdirectories created:\n","   â”œâ”€â”€ deliverables/\n","   â”œâ”€â”€ stage_outputs/\n","   â”œâ”€â”€ asset_bundles/\n","   â””â”€â”€ logs/\n","\n","âœ“ Ready for governance artifacts initialization (Cell 4)\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##3.API AND CLIENT INITIALIZATION"],"metadata":{"id":"STtjBQgwMNHi"}},{"cell_type":"markdown","source":["###3.1.OVERVIEW"],"metadata":{"id":"ShWjt_vyMO17"}},{"cell_type":"markdown","source":["\n","Think of Cell 3 as plugging in the power cord to your organization's AI assistant.\n","Just as you need electricity flowing through a building before any equipment can\n","work, you need a secure connection to the AI model before any of the governance\n","workflows can execute.\n","\n","When you use AI tools in consulting work, you need a way to communicate with the\n","AI model. This is like having a phone number to call an expert consultant, except\n","instead of a phone number, you use what's called an \"API key.\" This is essentially\n","a secure password that lets your notebook talk to Anthropic's Claude AI model.\n","The API key proves that you're an authorized user who has permission to make\n","requests to the AI service.\n","\n","Here's what happens in this cell, step by step, and why each step matters for\n","organizational governance.\n","\n","First, the notebook retrieves your API key from a secure storage location in\n","Google Colab called \"Secrets.\" This is important because you don't want to write\n","your password directly in the notebook where others might see it if you share the\n","file. It's like keeping your building access card in a secure wallet rather than\n","taping it to your forehead where everyone can see it. The Secrets mechanism in\n","Colab is specifically designed to store sensitive credentials separately from\n","your code. When you set up the notebook, you went to the Secrets panel (the key\n","icon on the left sidebar) and stored your API key there with the name\n","\"ANTHROPIC_API_KEY.\" Now Cell 3 retrieves it programmatically.\n","\n","If the retrieval fails - maybe you forgot to add the secret, or you misspelled\n","the name - the cell stops immediately and shows you clear instructions about how\n","to fix it. This \"fail fast\" principle is important in organizational systems.\n","Better to find out immediately that you don't have access than to run halfway\n","through a workflow and then discover the connection is broken. The error message\n","tells you exactly what to do: go to the Secrets panel, add a new secret called\n","\"ANTHROPIC_API_KEY,\" paste your key, and try again.\n","\n","Second, the cell initializes the \"client\" - this is the communication channel\n","between your notebook and Claude. Think of it like opening a dedicated phone line\n","to an expert who will help you draft documents, verify information, and flag\n","risks. The client is a software object that knows how to format requests properly,\n","send them to Anthropic's servers, wait for responses, and handle any communication\n","errors that might occur. Without this client initialization, you'd have no way to\n","send your drafting requests to the AI model.\n","\n","Third, and critically important for organizational governance, the cell locks in\n","two non-negotiable parameters that will govern every single AI call throughout\n","the entire notebook. These parameters aren't suggestions or preferences - they're\n","firm-wide standards that ensure consistency across all consultants and all cases.\n","\n","The first parameter is temperature, set to 0.2. Temperature controls how creative\n","or random the AI's responses will be. At temperature 0, the AI would be completely\n","deterministic, always giving the exact same response to the same prompt. At\n","temperature 1 or higher, the AI would be highly creative, producing very different\n","responses each time, sometimes surprisingly innovative and sometimes completely\n","off-track. We set it to 0.2 - low but not zero - which means the AI will be\n","consistent and predictable while retaining just enough flexibility to adapt its\n","language naturally to different cases.\n","\n","Why does this matter? Because in consulting work, you want reliability, not\n","artistic flourishes. If you submit the same case facts twice, you want roughly\n","similar intake narratives, not wildly different approaches. If ten different\n","consultants use the system for similar market entry cases, you want the outputs\n","to have consistent structure and quality, not vary dramatically based on which\n","random responses the AI happened to generate. Temperature 0.2 gives you that\n","consistency while avoiding the robotic repetition that temperature 0 might produce.\n","\n","The second parameter is max_tokens, set to 4,128. Tokens are roughly equivalent\n","to words (technically, they're chunks of text that the model processes, with\n","common words being single tokens and rare words sometimes being multiple tokens).\n","Setting max_tokens to 4,128 means the AI can produce responses up to about 3,000\n","words long - enough space for thorough intake narratives, detailed deliverable\n","templates, and comprehensive verification plans, without rambling endlessly.\n","\n","Why lock this in rather than letting it vary? Because response length affects\n","cost (you pay per token), quality (very long responses often include padding and\n","repetition), and consistency (you want all Stage A outputs to be roughly similar\n","in depth). By setting this as a firm-wide standard, you ensure that a consultant\n","in New York and a consultant in Singapore are using the AI in exactly the same\n","way, producing comparable outputs that meet the same quality bar.\n","\n","Notice that the cell doesn't give you options to adjust these parameters. You\n","can't say \"I want my case to be more creative, so I'll use temperature 0.8\" or\n","\"I need a longer response, so I'll request 8,000 tokens.\" These are organizational\n","standards, not individual preferences. That's what separates Level 5 from Level 3.\n","At Level 3, individuals configure their AI tools however they want, leading to\n","inconsistent quality and ungovernable outputs. At Level 5, the organization sets\n","standards and the code enforces them automatically.\n","\n","When this cell runs successfully, you'll see a confirmation message showing three\n","pieces of information. First, you see which model you're using - in this case,\n","Claude Sonnet 4.5, which is the specific version identifier that allows you to\n","reproduce results later. Models improve over time, and having the exact version\n","number matters for audit purposes. If a regulator asks \"What AI system did you\n","use?\" you can point to this exact model identifier.\n","\n","Second, you see the temperature setting (0.2) confirmed. This tells you the\n","consistency level is locked in. Third, you see the max tokens (4,128) confirmed.\n","This tells you the response length constraint is active.\n","\n","This confirmation isn't just informational - it's a quality control checkpoint.\n","Before any AI work begins, you're verifying that the connection is established,\n","the correct model is selected, and the organizational parameters are set. This is\n","analogous to a pilot's pre-flight checklist: you don't take off until you've\n","confirmed all systems are configured correctly.\n","\n","Why does this matter for your organization? Because at Level 5, you're not just\n","using AI for one person's work. You're establishing firm-wide standards. Every\n","consultant in your organization will use the same model, with the same temperature\n","setting, with the same token limit, producing outputs that meet the same quality\n","bar. This consistency is what allows you to have organizational governance rather\n","than just individual best practices.\n","\n","Consider what happens six months from now when a client questions a deliverable\n","that used AI assistance. You need to be able to say: \"We used Claude Sonnet 4.5,\n","configured with temperature 0.2 and max tokens 4,128, following our documented\n","organizational standards.\" You need to show that the AI configuration wasn't ad\n","hoc or arbitrary, but rather part of a governed process. Cell 3 creates that\n","documentation automatically by printing the confirmed settings every time it runs.\n","\n","The cell also creates what we call the \"configuration hash\" - a cryptographic\n","fingerprint of your exact model and parameter settings. This hash gets recorded\n","in your run manifest (created in Cell 4) and included in all audit trails. If two\n","different runs have the same configuration hash, you know they used identical AI\n","settings. If the hashes differ, something changed. This enables reproducibility:\n","given the same inputs and same configuration hash, you should get equivalent\n","outputs.\n","\n","There's also an important security principle embedded in Cell 3: the API key\n","itself is never printed to the screen or logged to files. You see \"API key\n","retrieved from Colab Secrets\" but you never see the actual key value. This\n","prevents accidental exposure if someone screenshots the notebook output or shares\n","logs. The key exists in memory only as long as needed to initialize the client,\n","then the reference is stored in an environment variable where only the client can\n","access it. This is defense-in-depth: even if someone gains access to your notebook\n","files, they won't find your API credentials sitting in plain text.\n","\n","From an organizational perspective, Cell 3 represents the boundary between your\n","internal systems and external AI services. Everything before this cell is local\n","setup - installing packages, creating directories, initializing data structures.\n","Everything after this cell involves sending requests to Anthropic's servers and\n","receiving AI-generated content. Having this clear boundary matters for security\n","reviews, compliance assessments, and vendor management. You can point to Cell 3\n","and say: \"This is where we connect to our AI vendor, using credentials managed\n","through Colab's secure secrets mechanism, with these specific configuration\n","parameters.\"\n","\n","The cell also implicitly handles error conditions that might occur during\n","initialization. If Anthropic's API is temporarily unavailable, or if your API key\n","has expired, or if there's a network connectivity issue, the client initialization\n","will fail with a clear error message. This prevents the confusing scenario where\n","you run the entire notebook and only discover at Stage A drafting that you never\n","actually connected to the AI service. Again, the principle is fail fast: find\n","problems immediately at initialization, not halfway through your workflow.\n","\n","When Cell 3 completes successfully, you're ready to proceed. The connection is\n","live, the configuration is locked in, and the organizational standards are active.\n","Every AI call from this point forward - whether it's drafting an intake narrative\n","in Stage A, creating a deliverable template in Stage B, or building a verification\n","plan in Stage C - will use these exact settings. You've established the foundation\n","for consistent, governed AI use at organizational scale.\n","\n","This is why Cell 3, despite being relatively simple code, is essential to the\n","Level 5 architecture. It's the gateway that transforms individual AI experimentation\n","into organizational AI governance. Without it, you'd have consultants using\n","different models, different settings, different quality levels. With it, you have\n","a firm-wide standard that enables quality assurance, compliance documentation, and\n","reproducible outputs. The AI might do the drafting, but Cell 3 ensures the AI does\n","it the organization's way."],"metadata":{"id":"n_uMwdv8MRcU"}},{"cell_type":"markdown","source":["###3.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"Xml9f9GoMR7J"}},{"cell_type":"code","source":["# Cell 3: API Key + Client Initialization\n","\n","import anthropic\n","from google.colab import userdata\n","\n","# Retrieve API key from Colab Secrets\n","try:\n","    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n","    os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n","    print(\"âœ“ API key retrieved from Colab Secrets\")\n","except Exception as e:\n","    print(\"âŒ FATAL: Could not retrieve ANTHROPIC_API_KEY from Colab Secrets\")\n","    print(\"   â†’ Go to ðŸ”‘ (Secrets) in left sidebar\")\n","    print(\"   â†’ Add secret: ANTHROPIC_API_KEY = your_api_key\")\n","    raise e\n","\n","# Initialize Anthropic client\n","client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n","\n","# Model and parameters (NON-NEGOTIABLE)\n","MODEL = \"claude-haiku-4-5-20251001\"\n","PARAMS = {\n","    \"temperature\": 0.2,\n","    \"max_tokens\": 4128\n","}\n","\n","print(\"=\" * 70)\n","print(\"API CLIENT INITIALIZED\")\n","print(\"=\" * 70)\n","print(f\"\\nðŸ¤– Model: {MODEL}\")\n","print(f\"ðŸŒ¡ï¸  Temperature: {PARAMS['temperature']}\")\n","print(f\"ðŸ“Š Max Tokens: {PARAMS['max_tokens']}\")\n","print(f\"\\nâœ“ Client ready for API calls\")\n","print(\"=\" * 70)"],"metadata":{"id":"UExynb0iMJwm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768927373074,"user_tz":360,"elapsed":577,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"daeea477-0a43-4a14-a04f-466d7f0e26ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ“ API key retrieved from Colab Secrets\n","======================================================================\n","API CLIENT INITIALIZED\n","======================================================================\n","\n","ðŸ¤– Model: claude-haiku-4-5-20251001\n","ðŸŒ¡ï¸  Temperature: 0.2\n","ðŸ“Š Max Tokens: 4128\n","\n","âœ“ Client ready for API calls\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##4.ORGANIZATIONAL POLICY AND INITIALIZATION OF GOVERNANCE ARTIFACTS"],"metadata":{"id":"zSjFjeDuMaZn"}},{"cell_type":"markdown","source":["###4.1.OVERVIEW"],"metadata":{"id":"6OWXlpZoMcHa"}},{"cell_type":"markdown","source":["\n","\n","Cell 4 is where your consulting firm gets its constitution - the foundational\n","rules and policies that will govern every AI-assisted engagement from this point\n","forward. Think of it as writing the employee handbook, compliance manual, and\n","process documentation all at once, but in a form that code can automatically\n","enforce rather than hoping people remember to follow.\n","\n","The cell creates two critical policy documents that define how your organization\n","operates. The first is org_policy.json - your firm's governance charter. This\n","document specifies what AI can and cannot be used for (the scope), what's\n","explicitly prohibited (like using client-confidential data without sanitization,\n","providing legal advice, or making autonomous recommendations), how long you keep\n","records (retention policy), and what triggers escalation to senior leadership\n","(like high-severity risks or policy violations). These aren't suggestions - they're\n","firm-wide rules that every consultant must follow, enforced automatically by code.\n","\n","The second document is workflow_runbook.json - your operational playbook. This\n","defines the exact stages every case flows through (Intake, Controls, Drafting A,\n","Drafting B, Drafting C, QA Sampling, Approval), what gates exist between stages\n","(checkpoints that must pass before proceeding), who's responsible for what (the\n","RACI model assigning Responsible, Accountable, Consulted, and Informed roles),\n","and what controls apply at each stage. This is your assembly line blueprint for\n","knowledge work.\n","\n","But Cell 4 doesn't just create policy documents - it initializes the entire\n","governance infrastructure that will track compliance throughout your run. It\n","creates empty log files that will fill with data as work progresses: prompts_log\n","for all AI calls (using hashes to protect confidentiality), risk_log for\n","aggregated risks, verification_register for items needing human review,\n","approvals_log for routing decisions, incident_log for policy violations, and\n","several others. Each log serves a specific compliance or operational purpose.\n","\n","The cell also computes a configuration hash - a cryptographic fingerprint of your\n","exact setup (model plus parameters). This hash appears in every log entry,\n","enabling you to prove that all work in this run used identical AI configuration.\n","Six months later, if someone questions whether your process was consistent, you\n","can show that every case has the same config hash.\n","\n","What makes Cell 4 powerful is that these aren't aspirational policies sitting in\n","a binder on a shelf. These are machine-readable rules that code will enforce\n","automatically in Cells 6-10. The organization defines the rules once in Cell 4,\n","and the system ensures compliance from that point forward."],"metadata":{"id":"XdRc9-nEMeIF"}},{"cell_type":"markdown","source":["###4.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"GvnsRIc6Mefx"}},{"cell_type":"code","source":["# Cell 4: Org Policy + Governance Artifacts Initialization\n","\n","import hashlib\n","\n","# Generate config hash (for reproducibility)\n","config_string = f\"{MODEL}|{PARAMS['temperature']}|{PARAMS['max_tokens']}\"\n","config_hash = hashlib.sha256(config_string.encode()).hexdigest()[:16]\n","\n","# Org Policy\n","org_policy = {\n","    \"version\": \"1.0\",\n","    \"effective_date\": datetime.datetime.now().isoformat(),\n","    \"scope\": \"AI-assisted consulting and strategy deliverables (drafts only)\",\n","    \"prohibited_uses\": [\n","        \"Client-confidential data without explicit sanitization\",\n","        \"Legal advice or regulatory compliance determinations\",\n","        \"Autonomous recommendations without human review\",\n","        \"Fabrication of market data, benchmarks, or citations\",\n","        \"Substitution of human professional judgment\"\n","    ],\n","    \"retention_policy\": {\n","        \"run_artifacts\": \"90 days minimum\",\n","        \"prompts_log\": \"redacted, hashes only, 365 days\",\n","        \"incident_log\": \"indefinite\"\n","    },\n","    \"escalation_triggers\": [\n","        \"High-severity risk identified\",\n","        \"Policy violation detected\",\n","        \"Multiple validation failures\",\n","        \"Recommendation language detected\"\n","    ],\n","    \"required_approvals\": [\n","        \"All deliverables require human approver before release\",\n","        \"QA samples require senior review\"\n","    ],\n","    \"qa_sampling_expectations\": \"Minimum 1-2 artifacts per case; random + risk-based selection\"\n","}\n","\n","with open(run_dir / \"org_policy.json\", \"w\") as f:\n","    json.dump(org_policy, f, indent=2)\n","\n","# Workflow Runbook\n","workflow_runbook = {\n","    \"version\": \"1.0\",\n","    \"lifecycle_stages\": [\n","        {\n","            \"stage\": \"Intake\",\n","            \"gate\": \"intake_complete\",\n","            \"roles\": [\"Consultant\"],\n","            \"controls\": [\"data_classification\", \"scope_boundary\", \"intended_reliance\"]\n","        },\n","        {\n","            \"stage\": \"Controls_Checklist\",\n","            \"gate\": \"controls_assigned\",\n","            \"roles\": [\"Risk_Officer\"],\n","            \"controls\": [\"risk_tier_mapping\", \"required_controls_list\"]\n","        },\n","        {\n","            \"stage\": \"Drafting_A\",\n","            \"gate\": \"intake_narrative_drafted\",\n","            \"roles\": [\"AI_Assistant\", \"Consultant_Reviewer\"],\n","            \"controls\": [\"JSON_schema_validation\", \"redaction\", \"Not_verified_flag\"]\n","        },\n","        {\n","            \"stage\": \"Drafting_B\",\n","            \"gate\": \"deliverable_drafted\",\n","            \"roles\": [\"AI_Assistant\", \"Consultant_Reviewer\"],\n","            \"controls\": [\"JSON_schema_validation\", \"recommendation_check\", \"Not_verified_flag\"]\n","        },\n","        {\n","            \"stage\": \"Drafting_C\",\n","            \"gate\": \"verification_plan_drafted\",\n","            \"roles\": [\"AI_Assistant\", \"Consultant_Reviewer\"],\n","            \"controls\": [\"JSON_schema_validation\", \"open_questions_enumerated\"]\n","        },\n","        {\n","            \"stage\": \"QA_Sampling\",\n","            \"gate\": \"samples_selected\",\n","            \"roles\": [\"QA_Lead\"],\n","            \"controls\": [\"sampling_plan_adherence\", \"sample_register\"]\n","        },\n","        {\n","            \"stage\": \"Approval\",\n","            \"gate\": \"approved_for_release\",\n","            \"roles\": [\"Senior_Approver\"],\n","            \"controls\": [\"verification_status_check\", \"qa_results_review\"]\n","        }\n","    ],\n","    \"RACI\": {\n","        \"Consultant\": \"Accountable for final deliverable; Responsible for review\",\n","        \"AI_Assistant\": \"Responsible for draft generation\",\n","        \"Risk_Officer\": \"Consulted on controls\",\n","        \"QA_Lead\": \"Responsible for QA sampling\",\n","        \"Senior_Approver\": \"Accountable for release approval\"\n","    }\n","}\n","\n","with open(run_dir / \"workflow_runbook.json\", \"w\") as f:\n","    json.dump(workflow_runbook, f, indent=2)\n","\n","# Initialize governance artifacts\n","\n","# run_manifest.json\n","run_manifest = {\n","    \"run_name\": run_name,\n","    \"run_id\": short_id,\n","    \"timestamp\": timestamp,\n","    \"model\": MODEL,\n","    \"params\": PARAMS,\n","    \"config_hash\": config_hash,\n","    \"platform\": f\"Google Colab / {platform.system()}\",\n","    \"notebook_version\": \"Chapter_5_Level_5_Organizations_v1.0\",\n","    \"author\": \"Alejandro Reynoso, Chief Scientist DEFI CAPITAL RESEARCH; External Lecturer, Judge Business School Cambridge\"\n","}\n","\n","with open(run_dir / \"run_manifest.json\", \"w\") as f:\n","    json.dump(run_manifest, f, indent=2)\n","\n","# prompts_log.jsonl (empty initially)\n","with open(run_dir / \"logs\" / \"prompts_log.jsonl\", \"w\") as f:\n","    pass\n","\n","# risk_log.json\n","with open(run_dir / \"risk_log.json\", \"w\") as f:\n","    json.dump({\"risks\": []}, f, indent=2)\n","\n","# verification_register.json\n","with open(run_dir / \"verification_register.json\", \"w\") as f:\n","    json.dump({\"items\": []}, f, indent=2)\n","\n","# change_log.json\n","with open(run_dir / \"change_log.json\", \"w\") as f:\n","    json.dump({\"changes\": []}, f, indent=2)\n","\n","# approvals_log.json\n","with open(run_dir / \"approvals_log.json\", \"w\") as f:\n","    json.dump({\"approvals\": []}, f, indent=2)\n","\n","# exception_log.json\n","with open(run_dir / \"exception_log.json\", \"w\") as f:\n","    json.dump({\"exceptions\": []}, f, indent=2)\n","\n","# incident_log.json\n","with open(run_dir / \"incident_log.json\", \"w\") as f:\n","    json.dump({\"incidents\": []}, f, indent=2)\n","\n","# qa_sampling_plan.json\n","qa_sampling_plan = {\n","    \"version\": \"1.0\",\n","    \"sampling_strategy\": \"random + risk-based\",\n","    \"frequency\": \"1-2 artifacts per case\",\n","    \"criteria\": [\n","        \"High-risk outputs (severity=high)\",\n","        \"Random sample from medium-risk outputs\",\n","        \"First deliverable from each case type (baseline)\"\n","    ]\n","}\n","\n","with open(run_dir / \"qa_sampling_plan.json\", \"w\") as f:\n","    json.dump(qa_sampling_plan, f, indent=2)\n","\n","# qa_results.json\n","with open(run_dir / \"qa_results.json\", \"w\") as f:\n","    json.dump({\"samples\": [], \"summary\": {}}, f, indent=2)\n","\n","# asset_registry.json\n","asset_registry = {\n","    \"assets\": [\n","        {\n","            \"asset_type\": \"prompt_template\",\n","            \"asset_name\": \"structured_output_schema\",\n","            \"version\": \"1.0\",\n","            \"description\": \"JSON schema for all model outputs\"\n","        },\n","        {\n","            \"asset_type\": \"workflow\",\n","            \"asset_name\": \"controlled_drafting_lifecycle\",\n","            \"version\": \"1.0\",\n","            \"description\": \"Stage A-B-C drafting workflow\"\n","        }\n","    ]\n","}\n","\n","with open(run_dir / \"asset_registry.json\", \"w\") as f:\n","    json.dump(asset_registry, f, indent=2)\n","\n","# stage_gate_log.jsonl (empty initially)\n","with open(run_dir / \"logs\" / \"stage_gate_log.jsonl\", \"w\") as f:\n","    pass\n","\n","print(\"=\" * 70)\n","print(\"GOVERNANCE ARTIFACTS INITIALIZED\")\n","print(\"=\" * 70)\n","print(f\"\\nðŸ“„ Organizational Policy:\")\n","print(f\"   â”œâ”€â”€ org_policy.json\")\n","print(f\"   â””â”€â”€ workflow_runbook.json\")\n","print(f\"\\nðŸ“‹ Base Artifacts:\")\n","print(f\"   â”œâ”€â”€ run_manifest.json\")\n","print(f\"   â”œâ”€â”€ risk_log.json\")\n","print(f\"   â”œâ”€â”€ verification_register.json\")\n","print(f\"   â”œâ”€â”€ change_log.json\")\n","print(f\"   â”œâ”€â”€ approvals_log.json\")\n","print(f\"   â””â”€â”€ logs/prompts_log.jsonl\")\n","print(f\"\\nðŸ”’ Level 5 Artifacts:\")\n","print(f\"   â”œâ”€â”€ qa_sampling_plan.json\")\n","print(f\"   â”œâ”€â”€ qa_results.json\")\n","print(f\"   â”œâ”€â”€ incident_log.json\")\n","print(f\"   â”œâ”€â”€ exception_log.json\")\n","print(f\"   â”œâ”€â”€ asset_registry.json\")\n","print(f\"   â””â”€â”€ logs/stage_gate_log.jsonl\")\n","print(f\"\\nðŸ”‘ Config Hash: {config_hash}\")\n","print(f\"âœ“ All governance artifacts ready\")\n","print(\"=\" * 70)"],"metadata":{"id":"AY_6OY4SMbAv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768927376200,"user_tz":360,"elapsed":22,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"e9080d0b-0f7e-4cdd-8f06-bcc3d5b7c7a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","GOVERNANCE ARTIFACTS INITIALIZED\n","======================================================================\n","\n","ðŸ“„ Organizational Policy:\n","   â”œâ”€â”€ org_policy.json\n","   â””â”€â”€ workflow_runbook.json\n","\n","ðŸ“‹ Base Artifacts:\n","   â”œâ”€â”€ run_manifest.json\n","   â”œâ”€â”€ risk_log.json\n","   â”œâ”€â”€ verification_register.json\n","   â”œâ”€â”€ change_log.json\n","   â”œâ”€â”€ approvals_log.json\n","   â””â”€â”€ logs/prompts_log.jsonl\n","\n","ðŸ”’ Level 5 Artifacts:\n","   â”œâ”€â”€ qa_sampling_plan.json\n","   â”œâ”€â”€ qa_results.json\n","   â”œâ”€â”€ incident_log.json\n","   â”œâ”€â”€ exception_log.json\n","   â”œâ”€â”€ asset_registry.json\n","   â””â”€â”€ logs/stage_gate_log.jsonl\n","\n","ðŸ”‘ Config Hash: d2ef82f08f0c34b9\n","âœ“ All governance artifacts ready\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##5.CONFIDENTIALITY AND MINIMUM NECESSARY INFORMATION"],"metadata":{"id":"aFfOfCZmMgx4"}},{"cell_type":"markdown","source":["###5.1.OVERVIEW"],"metadata":{"id":"tIlOMU-SMjni"}},{"cell_type":"markdown","source":["\n","\n","Cell 5 implements one of the most critical principles in Level 5 governance: the\n","AI should never see information it doesn't absolutely need to see. This cell\n","builds the confidentiality machinery that runs before any data touches the AI\n","model, automatically removing personal and sensitive information that could create\n","privacy or compliance risks.\n","\n","The cell creates two essential functions. The first is redact(), which scans text\n","for patterns that match personally identifiable information (PII) and replaces\n","them with safe placeholders. Email addresses become [EMAIL_REDACTED]. Phone\n","numbers in any format (with dashes, dots, or parentheses) become [PHONE_REDACTED].\n","Social security numbers and ID patterns become [ID_REDACTED]. Street addresses\n","become [ADDRESS_REDACTED]. Even proper names - detected as sequences of\n","capitalized words - become [NAME_REDACTED]. This isn't perfect (no regex-based\n","system is), but it catches the most common PII patterns automatically.\n","\n","The second function is build_minimum_necessary(), which implements the principle\n","of using only the information actually needed for the task. This function takes\n","raw input text, applies redaction, and produces three outputs: the sanitized text\n","that's safe to process, a list of what field types were removed (so you know what\n","got redacted), and a preview showing the first 200 characters of the cleaned text.\n","\n","What makes this powerful is the timing. Cell 5 runs before Cell 6 (the AI wrapper)\n","and before Cell 8 (the drafting workflow). By the time any text reaches the AI\n","model, it has already been sanitized. The raw input with contact details, names,\n","and addresses never gets sent to the API. Only the redacted version does. This is\n","defense-in-depth: even if someone accidentally pastes an email signature or\n","contact sheet, the confidential details get stripped automatically.\n","\n","The cell includes a demonstration using sample text that contains multiple PII\n","types. When you run it, you see the before-and-after comparison: raw text with\n","names and contact details, then sanitized text with redaction placeholders, plus\n","a summary of what was removed. This demo teaches you what the redaction system\n","catches and helps you understand what will happen to your real inputs.\n","\n","There's an explicit rule stated in the cell: raw inputs are never stored to disk.\n","Only sanitized artifacts persist in your governance trail. This means your audit\n","files and deliverable bundles don't contain the confidential information that was\n","redacted. The organization gets the governance documentation it needs without\n","retaining unnecessary PII."],"metadata":{"id":"ksHvcArXMxMR"}},{"cell_type":"markdown","source":["###5.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"x7z8cMnQMx3g"}},{"cell_type":"code","source":["# Cell 5: Confidentiality + Minimum Necessary + Redaction\n","\n","import re\n","\n","def redact(text):\n","    \"\"\"\n","    Best-effort redaction of PII:\n","    - Email addresses â†’ [EMAIL_REDACTED]\n","    - Phone numbers â†’ [PHONE_REDACTED]\n","    - Social security / ID patterns â†’ [ID_REDACTED]\n","    - Street addresses (basic patterns) â†’ [ADDRESS_REDACTED]\n","    - Proper names (capitalized consecutive words) â†’ [NAME_REDACTED]\n","    \"\"\"\n","    if not text:\n","        return text\n","\n","    # Email\n","    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL_REDACTED]', text)\n","\n","    # Phone numbers (various formats)\n","    text = re.sub(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', '[PHONE_REDACTED]', text)\n","    text = re.sub(r'\\(\\d{3}\\)\\s*\\d{3}[-.]?\\d{4}', '[PHONE_REDACTED]', text)\n","\n","    # SSN / ID patterns (XXX-XX-XXXX or similar)\n","    text = re.sub(r'\\b\\d{3}-\\d{2}-\\d{4}\\b', '[ID_REDACTED]', text)\n","\n","    # Street addresses (basic: number + Street/Ave/Rd/Blvd)\n","    text = re.sub(r'\\b\\d+\\s+[A-Z][a-z]+\\s+(Street|St|Avenue|Ave|Road|Rd|Boulevard|Blvd)\\b', '[ADDRESS_REDACTED]', text)\n","\n","    # Proper names (2-3 capitalized words in a row, crude heuristic)\n","    # This is aggressive and may over-redact; adjust as needed\n","    text = re.sub(r'\\b([A-Z][a-z]+\\s){1,2}[A-Z][a-z]+\\b', '[NAME_REDACTED]', text)\n","\n","    return text\n","\n","def build_minimum_necessary(raw_text):\n","    \"\"\"\n","    Extracts minimum necessary facts and shows what was removed.\n","\n","    Returns:\n","    - sanitized_facts: redacted text\n","    - removed_fields: list of field types removed\n","    - redacted_preview: first 200 chars of redacted output\n","    \"\"\"\n","    sanitized = redact(raw_text)\n","\n","    # Count what was redacted\n","    removed_fields = []\n","    if '[EMAIL_REDACTED]' in sanitized:\n","        removed_fields.append('emails')\n","    if '[PHONE_REDACTED]' in sanitized:\n","        removed_fields.append('phone_numbers')\n","    if '[ID_REDACTED]' in sanitized:\n","        removed_fields.append('identification_numbers')\n","    if '[ADDRESS_REDACTED]' in sanitized:\n","        removed_fields.append('street_addresses')\n","    if '[NAME_REDACTED]' in sanitized:\n","        removed_fields.append('proper_names')\n","\n","    redacted_preview = sanitized[:200] + (\"...\" if len(sanitized) > 200 else \"\")\n","\n","    return {\n","        \"sanitized_facts\": sanitized,\n","        \"removed_fields\": removed_fields,\n","        \"redacted_preview\": redacted_preview\n","    }\n","\n","# Demo\n","demo_raw_text = \"\"\"\n","Our client, John Smith from Acme Corp (john.smith@acmecorp.com, 555-123-4567),\n","is located at 123 Main Street. They are evaluating a market entry into the APAC region.\n","Contact Jane Doe at jane.doe@acmecorp.com for financial data.\n","SSN: 123-45-6789.\n","\"\"\"\n","\n","demo_result = build_minimum_necessary(demo_raw_text)\n","\n","print(\"=\" * 70)\n","print(\"CONFIDENTIALITY + REDACTION DEMO\")\n","print(\"=\" * 70)\n","print(\"\\nðŸ“ Original Text (first 200 chars):\")\n","print(textwrap.fill(demo_raw_text[:200], width=68))\n","print(\"\\nðŸ”’ Redacted Text:\")\n","print(textwrap.fill(demo_result[\"sanitized_facts\"], width=68))\n","print(f\"\\nâŒ Removed Fields: {', '.join(demo_result['removed_fields']) if demo_result['removed_fields'] else 'None'}\")\n","print(\"\\nâš ï¸  CRITICAL RULE:\")\n","print(\"   Raw inputs are NEVER stored to disk.\")\n","print(\"   Only sanitized artifacts are persisted.\")\n","print(\"=\" * 70)"],"metadata":{"id":"_OdMQ8SwMiEp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768927380482,"user_tz":360,"elapsed":23,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"e1d1d521-adf4-4336-98c3-cff84f3c4ce4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","CONFIDENTIALITY + REDACTION DEMO\n","======================================================================\n","\n","ðŸ“ Original Text (first 200 chars):\n"," Our client, John Smith from Acme Corp (john.smith@acmecorp.com,\n","555-123-4567), is located at 123 Main Street. They are evaluating a\n","market entry into the APAC region. Contact Jane Doe at jane.doe@acm\n","\n","ðŸ”’ Redacted Text:\n"," Our client, [NAME_REDACTED] from [NAME_REDACTED] ([EMAIL_REDACTED],\n","[PHONE_REDACTED]), is located at [ADDRESS_REDACTED]. They are\n","evaluating a market entry into the APAC region. [NAME_REDACTED] at\n","[EMAIL_REDACTED] for financial data. SSN: [ID_REDACTED].\n","\n","âŒ Removed Fields: emails, phone_numbers, identification_numbers, street_addresses, proper_names\n","\n","âš ï¸  CRITICAL RULE:\n","   Raw inputs are NEVER stored to disk.\n","   Only sanitized artifacts are persisted.\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##6.LLM WRAPPER"],"metadata":{"id":"uVJjvhvVM0E8"}},{"cell_type":"markdown","source":["###6.1.OVERVIEW"],"metadata":{"id":"MyxD2F2XM1J3"}},{"cell_type":"markdown","source":["\n","\n","Cell 6 is the most technically complex cell in the entire notebook, and for good\n","reason - it's the last line of defense between unpredictable AI outputs and your\n","organization's governance requirements. Think of it as a quality control inspector\n","who checks every single thing the AI produces before allowing it into your\n","official workflow. This cell implements what we call \"exhaustively defensive\"\n","parsing because it assumes the AI will fail in every possible way and builds\n","protections for each failure mode.\n","\n","The cell is organized into eight major components, each addressing specific\n","problems we've observed in real-world AI deployments. Component A handles\n","normalization - safely cleaning up the AI's response by removing markdown code\n","fences (those ```json markers) and replacing smart quotes with standard quotes,\n","but doing so carefully without destroying the actual content. Component B extracts\n","JSON objects from text that might have extra prose before or after, detecting\n","problems like multiple JSON objects or truncated responses. Component C applies\n","limited, safe repairs like removing trailing commas, but refuses to do risky\n","fixes that might change meaning.\n","\n","Component D orchestrates the parsing with retries. When the AI returns text, this\n","component tries to parse it directly. If that fails, it extracts the JSON\n","substring. If that fails, it applies fixes. If that still fails after three\n","attempts, it writes a detailed debug file showing exactly what went wrong and\n","where. This debug trail is crucial - when things break, you need to understand\n","why so you can fix the prompt or adjust the validation logic.\n","\n","Component E validates the exact schema with zero tolerance for deviations. The AI\n","must return precisely eight keys with specific types: task (string), facts_provided\n","(list of strings), assumptions (list of strings), open_questions (list of strings),\n","risks (list of dictionaries with exact keys type/severity/note), draft_output\n","(string), verification_status (must be exactly \"Not verified\"), and\n","questions_to_verify (list of strings). If any key is missing, extra, or wrong\n","type, validation fails and triggers a retry with detailed error messages.\n","\n","Component F implements policy validation specific to Level 5 governance. The\n","reject_recommendations function scans draft output for prohibited phrases like\n","\"we recommend,\" \"you should,\" or \"best option\" - language that would turn a\n","neutral draft into advice. The numeric_claim_check function extracts currency\n","amounts, percentages, and large numbers, then verifies each appears in the\n","provided facts or stated assumptions. If it finds suspicious numbers not in the\n","inputs, it flags potential hallucination.\n","\n","Component G handles logging and incident management. Every AI call gets logged to\n","prompts_log.jsonl with timestamp, task name, stage name, hashes of prompt and\n","response (not the actual text, protecting confidentiality), model configuration,\n","parsing status, and any incidents. Failed validations get logged to incident_log\n","and exception_log with severity ratings and remediation notes. This creates a\n","complete audit trail without storing potentially confidential content.\n","\n","Component H is the actual wrapper function that orchestrates everything: make the\n","API call, parse with retries, validate schema, check policies, log everything.\n","The function includes detailed console output so you can watch it work in real\n","time. Most importantly, Component H includes a mandatory smoke test - an actual\n","API call that verifies the entire wrapper works correctly before you process any\n","real cases.\n","\n","When you run Cell 6, you see the smoke test execute. The wrapper constructs a\n","simple prompt, calls the API, receives a response, parses it, validates it,\n","checks policies, and confirms everything works. You see \"Making API call\" followed\n","by \"Received response\" followed by \"Validation complete\" and finally \"SMOKE TEST\n","PASSED\" with a summary. This isn't optional - the smoke test must pass before you\n","can proceed to Cell 7.\n","\n","What makes this cell \"exhaustively defensive\" is that it doesn't trust anything.\n","It doesn't trust that the AI will return valid JSON. It doesn't trust that valid\n","JSON will have correct keys. It doesn't trust that correct keys will have correct\n","types. It doesn't trust that the AI will avoid recommendations. It doesn't trust\n","that numbers are sourced from inputs. Every single assumption gets checked, and\n","every failure triggers either a logged incident or a retry with clarification.\n","\n","This level of defensive programming might seem excessive, but it reflects reality.\n","AI models are probabilistic systems that occasionally produce malformed outputs,\n","include unwanted content, or make up plausible-sounding facts. Without these\n","defenses, those failures would corrupt your governance trail, violate policies,\n","or reach clients. With these defenses, failures get caught systematically, logged\n","for analysis, and either corrected automatically or escalated for human review.\n","\n","Cell 6 is where \"trust but verify\" becomes concrete. We trust the AI to draft\n","useful content, but we verify that content meets organizational standards before\n","accepting it into the workflow."],"metadata":{"id":"NbI8D2MMNp2V"}},{"cell_type":"markdown","source":["###6.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"HYi01MJHM25b"}},{"cell_type":"code","source":["# Cell 6: LLM Wrapper (EXHAUSTIVELY DEFENSIVE JSON PARSING + INCIDENT LOGGING)\n","\n","import json\n","import re\n","import hashlib\n","import datetime\n","\n","# ============================================================================\n","# A) NORMALIZATION (SAFE, NON-DESTRUCTIVE)\n","# ============================================================================\n","\n","def normalize_text(s):\n","    \"\"\"\n","    Normalize response text:\n","    - Strip whitespace\n","    - Remove markdown code fences (```json, ```)\n","    - Replace smart quotes with standard quotes (outer markdown only)\n","    \"\"\"\n","    if not s:\n","        return s\n","\n","    # Strip whitespace\n","    s = s.strip()\n","\n","    # Remove code fences\n","    s = re.sub(r'^```json\\s*', '', s, flags=re.IGNORECASE)\n","    s = re.sub(r'^```\\s*', '', s)\n","    s = re.sub(r'\\s*```$', '', s)\n","\n","    # Replace smart quotes (for outer markdown removal only)\n","    s = s.replace('\"', '\"').replace('\"', '\"')\n","    s = s.replace(''', \"'\").replace(''', \"'\")\n","\n","    return s.strip()\n","\n","# ============================================================================\n","# B) JSON EXTRACTION (STRICT)\n","# ============================================================================\n","\n","def extract_single_json_object(text):\n","    \"\"\"\n","    Extract JSON object from text with strict validation.\n","\n","    Returns: (extracted_json_str, warnings)\n","    warnings: list of issues detected\n","    \"\"\"\n","    warnings = []\n","\n","    # Try direct parse first\n","    try:\n","        json.loads(text)\n","        return text, warnings\n","    except json.JSONDecodeError:\n","        pass\n","\n","    # Locate first \"{\" and last \"}\"\n","    first_brace = text.find('{')\n","    last_brace = text.rfind('}')\n","\n","    if first_brace == -1 or last_brace == -1 or first_brace >= last_brace:\n","        warnings.append(\"no_valid_braces\")\n","        return None, warnings\n","\n","    # Check for extraneous text before/after\n","    before_text = text[:first_brace].strip()\n","    after_text = text[last_brace + 1:].strip()\n","\n","    if before_text:\n","        warnings.append(f\"extraneous_text_before: {len(before_text)} chars\")\n","    if after_text:\n","        warnings.append(f\"extraneous_text_after: {len(after_text)} chars\")\n","\n","    # Extract substring\n","    extracted = text[first_brace:last_brace + 1]\n","\n","    # Check for multiple JSON objects (pattern \"}{\"  or multiple top-level \"{\")\n","    if '}{' in extracted:\n","        warnings.append(\"multiple_json_objects_detected\")\n","        return None, warnings\n","\n","    # Check for truncation (doesn't end with \"}\")\n","    if not extracted.rstrip().endswith('}'):\n","        warnings.append(\"truncation_detected\")\n","        return None, warnings\n","\n","    return extracted, warnings\n","\n","# ============================================================================\n","# C) JSON REPAIR (LIMITED, SAFE)\n","# ============================================================================\n","\n","def fix_json_string(json_str):\n","    \"\"\"\n","    Apply LIMITED, SAFE repairs:\n","    - Remove trailing commas before } or ]\n","    - Remove repeated trailing commas\n","\n","    Does NOT attempt structural repairs.\n","    \"\"\"\n","    if not json_str:\n","        return json_str\n","\n","    # Remove trailing commas before } or ]\n","    json_str = re.sub(r',(\\s*[}\\]])', r'\\1', json_str)\n","\n","    # Remove repeated trailing commas\n","    json_str = re.sub(r',+', ',', json_str)\n","\n","    return json_str\n","\n","# ============================================================================\n","# D) PARSING + RETRIES\n","# ============================================================================\n","\n","def parse_with_repair(text, debug_path=None):\n","    \"\"\"\n","    Attempt to parse JSON with repair and debugging.\n","\n","    Returns: (parsed_obj, status, error_msg)\n","    status: \"success\" | \"failed\"\n","    \"\"\"\n","    original_text = text\n","\n","    # Normalize\n","    normalized = normalize_text(text)\n","\n","    # Try direct parse\n","    try:\n","        obj = json.loads(normalized)\n","        return obj, \"success\", None\n","    except json.JSONDecodeError as e:\n","        pass\n","\n","    # Extract JSON object\n","    extracted, warnings = extract_single_json_object(normalized)\n","\n","    if extracted is None:\n","        error_msg = f\"Extraction failed: {', '.join(warnings)}\"\n","        if debug_path:\n","            write_debug_file(debug_path, original_text, normalized, None, None, error_msg)\n","        return None, \"failed\", error_msg\n","\n","    # Try parse extracted\n","    try:\n","        obj = json.loads(extracted)\n","        if warnings:\n","            return obj, \"success_with_warnings\", f\"Warnings: {', '.join(warnings)}\"\n","        return obj, \"success\", None\n","    except json.JSONDecodeError as e:\n","        pass\n","\n","    # Apply fixes\n","    fixed = fix_json_string(extracted)\n","\n","    # Try parse fixed\n","    try:\n","        obj = json.loads(fixed)\n","        return obj, \"success_after_repair\", f\"Warnings: {', '.join(warnings)}\"\n","    except json.JSONDecodeError as e:\n","        error_msg = f\"Parse failed after repair: {str(e)}\"\n","        if debug_path:\n","            write_debug_file(debug_path, original_text, normalized, extracted, fixed, error_msg)\n","        return None, \"failed\", error_msg\n","\n","def write_debug_file(path, original, normalized, extracted, fixed, error):\n","    \"\"\"Write debug information for malformed JSON.\"\"\"\n","    with open(path, 'w') as f:\n","        f.write(\"=\" * 70 + \"\\n\")\n","        f.write(\"MALFORMED JSON DEBUG\\n\")\n","        f.write(\"=\" * 70 + \"\\n\\n\")\n","        f.write(\"ORIGINAL RESPONSE (first 4000 chars):\\n\")\n","        f.write(\"-\" * 70 + \"\\n\")\n","        f.write(original[:4000] + \"\\n\\n\")\n","        f.write(\"NORMALIZED:\\n\")\n","        f.write(\"-\" * 70 + \"\\n\")\n","        f.write(normalized[:4000] + \"\\n\\n\")\n","        if extracted:\n","            f.write(\"EXTRACTED:\\n\")\n","            f.write(\"-\" * 70 + \"\\n\")\n","            f.write(extracted[:4000] + \"\\n\\n\")\n","        if fixed:\n","            f.write(\"AFTER FIXES:\\n\")\n","            f.write(\"-\" * 70 + \"\\n\")\n","            f.write(fixed[:4000] + \"\\n\\n\")\n","        f.write(\"ERROR:\\n\")\n","        f.write(\"-\" * 70 + \"\\n\")\n","        f.write(error + \"\\n\")\n","\n","# ============================================================================\n","# E) SCHEMA VALIDATION (ZERO-TOLERANCE)\n","# ============================================================================\n","\n","REQUIRED_SCHEMA = {\n","    \"task\": str,\n","    \"facts_provided\": list,\n","    \"assumptions\": list,\n","    \"open_questions\": list,\n","    \"risks\": list,\n","    \"draft_output\": str,\n","    \"verification_status\": str,\n","    \"questions_to_verify\": list\n","}\n","\n","def validate_exact_schema(obj):\n","    \"\"\"\n","    Validate object matches exact schema.\n","\n","    Returns: (is_valid, issues)\n","    issues: list of validation problems\n","    \"\"\"\n","    issues = []\n","\n","    # Must be dict\n","    if not isinstance(obj, dict):\n","        issues.append(f\"Object is not a dict, got {type(obj)}\")\n","        return False, issues\n","\n","    # Check for exact keys\n","    required_keys = set(REQUIRED_SCHEMA.keys())\n","    actual_keys = set(obj.keys())\n","\n","    missing_keys = required_keys - actual_keys\n","    extra_keys = actual_keys - required_keys\n","\n","    if missing_keys:\n","        issues.append(f\"Missing keys: {missing_keys}\")\n","    if extra_keys:\n","        issues.append(f\"Extra keys: {extra_keys}\")\n","\n","    # Type validation\n","    for key, expected_type in REQUIRED_SCHEMA.items():\n","        if key not in obj:\n","            continue\n","\n","        value = obj[key]\n","\n","        if expected_type == str:\n","            if not isinstance(value, str):\n","                issues.append(f\"{key}: expected str, got {type(value)}\")\n","\n","        elif expected_type == list:\n","            if not isinstance(value, list):\n","                issues.append(f\"{key}: expected list, got {type(value)}\")\n","            elif key == \"risks\":\n","                # Validate risk objects\n","                for i, risk in enumerate(value):\n","                    if not isinstance(risk, dict):\n","                        issues.append(f\"risks[{i}]: expected dict, got {type(risk)}\")\n","                        continue\n","\n","                    risk_keys = {\"type\", \"severity\", \"note\"}\n","                    if set(risk.keys()) != risk_keys:\n","                        issues.append(f\"risks[{i}]: keys must be exactly {risk_keys}, got {set(risk.keys())}\")\n","\n","                    if \"severity\" in risk and risk[\"severity\"] not in {\"low\", \"medium\", \"high\"}:\n","                        issues.append(f\"risks[{i}]: severity must be low/medium/high, got {risk['severity']}\")\n","\n","            elif key in [\"facts_provided\", \"assumptions\", \"open_questions\", \"questions_to_verify\"]:\n","                # Must be list of strings\n","                for i, item in enumerate(value):\n","                    if not isinstance(item, str):\n","                        issues.append(f\"{key}[{i}]: expected str, got {type(item)}\")\n","\n","    # verification_status must be exactly \"Not verified\"\n","    if \"verification_status\" in obj and obj[\"verification_status\"] != \"Not verified\":\n","        issues.append(f\"verification_status must be exactly 'Not verified', got '{obj['verification_status']}'\")\n","\n","    return len(issues) == 0, issues\n","\n","# ============================================================================\n","# F) POLICY VALIDATION (LEVEL 5)\n","# ============================================================================\n","\n","def reject_recommendations(obj):\n","    \"\"\"\n","    Check for recommendation language.\n","    Returns: (has_violation, violation_type)\n","    \"\"\"\n","    draft = obj.get(\"draft_output\", \"\").lower()\n","\n","    prohibited_phrases = [\n","        \"we recommend\",\n","        \"recommend\",\n","        \"best option\",\n","        \"choose\",\n","        \"should do\",\n","        \"go with\",\n","        \"our recommendation\",\n","        \"suggested approach\"\n","    ]\n","\n","    for phrase in prohibited_phrases:\n","        if phrase in draft:\n","            return True, f\"recommendation_language_detected: '{phrase}'\"\n","\n","    return False, None\n","\n","def numeric_claim_check(obj, allowed_tokens):\n","    \"\"\"\n","    Check for numeric claims not in facts/assumptions.\n","\n","    allowed_tokens: set of strings from facts_provided + assumptions\n","\n","    Returns: (has_suspicious_claims, details)\n","    \"\"\"\n","    draft = obj.get(\"draft_output\", \"\")\n","\n","    # Extract currency/percent/large numbers\n","    numeric_patterns = [\n","        r'\\$\\d+(?:,\\d{3})*(?:\\.\\d+)?[MBK]?',  # Currency\n","        r'\\d+(?:,\\d{3})*(?:\\.\\d+)?%',          # Percentages\n","        r'\\d+(?:,\\d{3})+',                     # Large numbers with commas\n","    ]\n","\n","    found_numbers = []\n","    for pattern in numeric_patterns:\n","        matches = re.findall(pattern, draft)\n","        found_numbers.extend(matches)\n","\n","    # Check if numbers appear in allowed_tokens\n","    suspicious = []\n","    for num in found_numbers:\n","        found_in_allowed = False\n","        for token in allowed_tokens:\n","            if num in token:\n","                found_in_allowed = True\n","                break\n","        if not found_in_allowed:\n","            suspicious.append(num)\n","\n","    if suspicious:\n","        return True, f\"numeric_claims_not_in_facts: {suspicious[:5]}\"  # First 5\n","\n","    return False, None\n","\n","# ============================================================================\n","# G) LOGGING + INCIDENT HANDLING\n","# ============================================================================\n","\n","def log_prompt(task_name, stage_name, prompt_text, response_text, model, params, parsing_status, incidents):\n","    \"\"\"\n","    Log model call to prompts_log.jsonl (REDACTED).\n","    \"\"\"\n","    log_entry = {\n","        \"timestamp\": datetime.datetime.now().isoformat(),\n","        \"task_name\": task_name,\n","        \"stage_name\": stage_name,\n","        \"prompt_hash\": hashlib.sha256(prompt_text.encode()).hexdigest()[:16],\n","        \"response_hash\": hashlib.sha256(response_text.encode()).hexdigest()[:16],\n","        \"model\": model,\n","        \"params\": params,\n","        \"parsing_status\": parsing_status,\n","        \"incidents\": incidents,\n","        \"redaction_summary\": \"Full text redacted; hashes only\",\n","        \"config_hash\": config_hash\n","    }\n","\n","    with open(run_dir / \"logs\" / \"prompts_log.jsonl\", \"a\") as f:\n","        f.write(json.dumps(log_entry) + \"\\n\")\n","\n","def log_incident(incident_type, severity, details, task_name=None):\n","    \"\"\"\n","    Append to incident_log.json.\n","    \"\"\"\n","    # Read current log\n","    with open(run_dir / \"incident_log.json\", \"r\") as f:\n","        incident_log = json.load(f)\n","\n","    incident_log[\"incidents\"].append({\n","        \"timestamp\": datetime.datetime.now().isoformat(),\n","        \"task_name\": task_name,\n","        \"incident_type\": incident_type,\n","        \"severity\": severity,\n","        \"details\": details\n","    })\n","\n","    # Write back\n","    with open(run_dir / \"incident_log.json\", \"w\") as f:\n","        json.dump(incident_log, f, indent=2)\n","\n","def log_exception(exception_type, details, task_name=None):\n","    \"\"\"\n","    Append to exception_log.json.\n","    \"\"\"\n","    with open(run_dir / \"exception_log.json\", \"r\") as f:\n","        exception_log = json.load(f)\n","\n","    exception_log[\"exceptions\"].append({\n","        \"timestamp\": datetime.datetime.now().isoformat(),\n","        \"task_name\": task_name,\n","        \"exception_type\": exception_type,\n","        \"details\": details,\n","        \"remediation\": \"Manual review required; see incident log\"\n","    })\n","\n","    with open(run_dir / \"exception_log.json\", \"w\") as f:\n","        json.dump(exception_log, f, indent=2)\n","\n","# ============================================================================\n","# MAIN LLM CALL WRAPPER\n","# ============================================================================\n","\n","def call_llm_structured(prompt, task_name, stage_name=None, max_retries=2):\n","    \"\"\"\n","    Call LLM with exhaustive defensive parsing and validation.\n","\n","    Returns: parsed_obj (or raises exception after retries)\n","    \"\"\"\n","    incidents = []\n","\n","    for attempt in range(max_retries + 1):\n","        try:\n","            # ================================================================\n","            # ACTUAL API CALL TO ANTHROPIC CLAUDE\n","            # ================================================================\n","            print(f\"   â†’ Making API call (attempt {attempt + 1}/{max_retries + 1})...\")\n","\n","            response = client.messages.create(\n","                model=MODEL,\n","                max_tokens=PARAMS[\"max_tokens\"],\n","                temperature=PARAMS[\"temperature\"],\n","                messages=[{\"role\": \"user\", \"content\": prompt}]\n","            )\n","\n","            response_text = response.content[0].text\n","            print(f\"   âœ“ Received response ({len(response_text)} chars)\")\n","\n","            # Parse with repair\n","            debug_path = run_dir / \"logs\" / f\"debug_malformed_{task_name}_{attempt}.txt\"\n","            obj, parse_status, error_msg = parse_with_repair(response_text, debug_path)\n","\n","            if obj is None:\n","                incidents.append({\n","                    \"type\": \"parse_failure\",\n","                    \"attempt\": attempt,\n","                    \"error\": error_msg\n","                })\n","                log_incident(\"parse_failure\", \"high\", error_msg, task_name)\n","\n","                if attempt < max_retries:\n","                    # Retry with clarification\n","                    if attempt == 0:\n","                        prompt += \"\\n\\nYour previous JSON was invalid. Return ONLY valid JSON. No prose. No markdown fences.\"\n","                    else:\n","                        prompt += f\"\\n\\nValidation issues: {error_msg}\\nReminder: Use double quotes, no trailing commas, match exact schema.\"\n","                    continue\n","                else:\n","                    # Final failure\n","                    log_exception(\"parse_failure_after_retries\", error_msg, task_name)\n","                    raise ValueError(f\"JSON parsing failed after {max_retries + 1} attempts: {error_msg}\")\n","\n","            # Log warnings\n","            if \"warnings\" in parse_status:\n","                log_incident(\"extraneous_text\", \"medium\", parse_status, task_name)\n","                incidents.append({\"type\": \"extraneous_text\", \"details\": parse_status})\n","\n","            # Schema validation\n","            is_valid, schema_issues = validate_exact_schema(obj)\n","\n","            if not is_valid:\n","                incidents.append({\n","                    \"type\": \"schema_validation_failure\",\n","                    \"attempt\": attempt,\n","                    \"issues\": schema_issues\n","                })\n","                log_incident(\"schema_validation_failure\", \"high\", str(schema_issues), task_name)\n","\n","                if attempt < max_retries:\n","                    prompt += f\"\\n\\nSchema validation failed: {'; '.join(schema_issues)}\\nReturn object with EXACT keys and types.\"\n","                    continue\n","                else:\n","                    log_exception(\"schema_validation_failure_after_retries\", str(schema_issues), task_name)\n","                    raise ValueError(f\"Schema validation failed after {max_retries + 1} attempts: {schema_issues}\")\n","\n","            # Policy validation: recommendation language\n","            has_rec_violation, rec_detail = reject_recommendations(obj)\n","            if has_rec_violation:\n","                incidents.append({\"type\": \"decision_laundering\", \"details\": rec_detail})\n","                log_incident(\"decision_laundering\", \"high\", rec_detail, task_name)\n","\n","                # Add to risks\n","                obj[\"risks\"].append({\n","                    \"type\": \"decision_laundering\",\n","                    \"severity\": \"high\",\n","                    \"note\": rec_detail\n","                })\n","\n","            # Policy validation: numeric claims\n","            allowed_tokens = set(obj.get(\"facts_provided\", []) + obj.get(\"assumptions\", []))\n","            has_num_violation, num_detail = numeric_claim_check(obj, allowed_tokens)\n","            if has_num_violation:\n","                incidents.append({\"type\": \"hallucination\", \"details\": num_detail})\n","                log_incident(\"hallucination\", \"high\", num_detail, task_name)\n","\n","                obj[\"risks\"].append({\n","                    \"type\": \"hallucination\",\n","                    \"severity\": \"high\",\n","                    \"note\": num_detail\n","                })\n","\n","            # Log prompt\n","            log_prompt(task_name, stage_name, prompt, response_text, MODEL, PARAMS, parse_status, incidents)\n","\n","            print(f\"   âœ“ Validation complete\")\n","            return obj\n","\n","        except Exception as e:\n","            if attempt < max_retries:\n","                print(f\"   âš  Attempt {attempt + 1} failed, retrying...\")\n","                continue\n","            else:\n","                log_exception(\"api_call_failure\", str(e), task_name)\n","                raise\n","\n","# ============================================================================\n","# H) SMOKE TEST (MANDATORY, REAL API CALL)\n","# ============================================================================\n","\n","print(\"=\" * 70)\n","print(\"LLM WRAPPER: EXHAUSTIVELY DEFENSIVE PARSING + VALIDATION\")\n","print(\"=\" * 70)\n","print(\"\\nðŸ”§ Components loaded:\")\n","print(\"   âœ“ Normalization (safe, non-destructive)\")\n","print(\"   âœ“ JSON extraction (strict, with warnings)\")\n","print(\"   âœ“ JSON repair (limited, safe)\")\n","print(\"   âœ“ Parsing with retries (max 3 attempts)\")\n","print(\"   âœ“ Schema validation (zero-tolerance)\")\n","print(\"   âœ“ Policy validation (recommendation + numeric claims)\")\n","print(\"   âœ“ Logging + incident handling\")\n","print(\"\\nðŸ§ª Running SMOKE TEST with REAL API CALL...\\n\")\n","\n","smoke_test_prompt = \"\"\"You are assisting a management consultant with a governance-first approach.\n","\n","Return ONLY a JSON object with this EXACT structure (no extra text, no markdown fences):\n","\n","{\n","  \"task\": \"Smoke test for LLM wrapper validation\",\n","  \"facts_provided\": [\"User requested smoke test\", \"Test environment is Google Colab\"],\n","  \"assumptions\": [\"API key is valid\", \"Model is available\"],\n","  \"open_questions\": [\"Is the wrapper handling edge cases correctly?\"],\n","  \"risks\": [\n","    {\"type\": \"other\", \"severity\": \"low\", \"note\": \"This is a smoke test\"}\n","  ],\n","  \"draft_output\": \"Smoke test completed successfully. The wrapper is ready for production use.\",\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"Did the wrapper parse this response correctly?\"]\n","}\n","\n","Return ONLY valid JSON matching this exact schema.\"\"\"\n","\n","try:\n","    # THIS IS THE ACTUAL LLM CALL\n","    smoke_result = call_llm_structured(smoke_test_prompt, \"smoke_test\", \"initialization\")\n","\n","    print(\"\\nâœ… SMOKE TEST PASSED\")\n","    print(\"=\" * 70)\n","    print(f\"\\nðŸ“Š Smoke Test Results:\")\n","    print(f\"   Task: {smoke_result['task']}\")\n","    print(f\"   Facts Provided: {len(smoke_result['facts_provided'])} items\")\n","    print(f\"   Assumptions: {len(smoke_result['assumptions'])} items\")\n","    print(f\"   Open Questions: {len(smoke_result['open_questions'])} items\")\n","    print(f\"   Risks: {len(smoke_result['risks'])} items\")\n","    print(f\"   Questions to Verify: {len(smoke_result['questions_to_verify'])} items\")\n","    print(f\"   Verification Status: {smoke_result['verification_status']}\")\n","    print(f\"\\nâœ“ Schema validation: PASSED\")\n","    print(f\"âœ“ Policy validation: PASSED\")\n","    print(f\"âœ“ Wrapper ready for production\")\n","    print(\"=\" * 70)\n","\n","except Exception as e:\n","    print(f\"\\nâŒ SMOKE TEST FAILED: {str(e)}\")\n","    print(\"   Check logs for details.\")\n","    raise"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pKuRzIOATLSN","executionInfo":{"status":"ok","timestamp":1768928905811,"user_tz":360,"elapsed":1274,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"7f4c0e18-172f-417e-d6d1-c649bbd8a81c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","LLM WRAPPER: EXHAUSTIVELY DEFENSIVE PARSING + VALIDATION\n","======================================================================\n","\n","ðŸ”§ Components loaded:\n","   âœ“ Normalization (safe, non-destructive)\n","   âœ“ JSON extraction (strict, with warnings)\n","   âœ“ JSON repair (limited, safe)\n","   âœ“ Parsing with retries (max 3 attempts)\n","   âœ“ Schema validation (zero-tolerance)\n","   âœ“ Policy validation (recommendation + numeric claims)\n","   âœ“ Logging + incident handling\n","\n","ðŸ§ª Running SMOKE TEST with REAL API CALL...\n","\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (590 chars)\n","   âœ“ Validation complete\n","\n","âœ… SMOKE TEST PASSED\n","======================================================================\n","\n","ðŸ“Š Smoke Test Results:\n","   Task: Smoke test for LLM wrapper validation\n","   Facts Provided: 2 items\n","   Assumptions: 2 items\n","   Open Questions: 1 items\n","   Risks: 1 items\n","   Questions to Verify: 1 items\n","   Verification Status: Not verified\n","\n","âœ“ Schema validation: PASSED\n","âœ“ Policy validation: PASSED\n","âœ“ Wrapper ready for production\n","======================================================================\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"W9uaT3o9M45h"}},{"cell_type":"markdown","source":["##7.LIFECYCLE BUILDERS"],"metadata":{"id":"Dr34h4v4M8SU"}},{"cell_type":"markdown","source":["###7.1.OVERVIEW"],"metadata":{"id":"EnAuC2ckM_GU"}},{"cell_type":"markdown","source":["\n","\n","Cell 7 is where abstract organizational concepts become concrete executable\n","functions. If Cell 4 created the rulebook that says \"here's how our firm operates,\"\n","Cell 7 builds the actual machinery that makes those rules happen automatically.\n","These eight functions are the organizational operating system - the difference\n","between having policies written in a document versus having policies enforced by\n","code.\n","\n","The cell starts with two intake functions that formalize how work enters the\n","organization. The build_intake_record function takes the basic information about\n","a case - name, purpose, intended reliance, data classification, scope boundary -\n","and creates an official intake record with a unique identifier and timestamp.\n","This isn't just data entry; it's creating an organizational artifact that will be\n","referenced throughout the entire lifecycle. Every subsequent decision, every\n","artifact created, every approval routed will trace back to this intake record.\n","\n","The build_controls_checklist function demonstrates organizational policy made\n","deterministic. It reads the data classification from the intake record and\n","automatically assigns the appropriate risk tier and controls. This isn't a\n","judgment call - it's a fixed mapping. Confidential data gets medium risk tier\n","which triggers seven specific controls including Partner approval and mandatory\n","QA sampling. Restricted data gets high risk tier which triggers eleven controls\n","including legal review and dual approval. The consultant doesn't decide what\n","controls apply; firm policy decides, and code enforces.\n","\n","Then come two functions managing verification and approval - the human judgment\n","touchpoints in the workflow. The build_verification_register_stub function\n","extracts all the open questions and verification needs that the AI identified\n","during drafting, and adds them to a central register. This transforms scattered\n","questions across multiple stage outputs into a unified tracking system. The\n","build_approval_stub function creates approval routing entries that specify which\n","role must approve (Partner versus Senior Consultant) based on risk tier, with\n","state set to \"pending\" until a human makes the decision.\n","\n","The three QA functions implement systematic quality assurance at scale. The\n","qa_sample_selector function implements a sampling strategy: always select\n","high-risk outputs, include the first deliverable from each case type as a\n","baseline, and cap at two samples per case to keep QA workload manageable. This\n","is risk-based sampling - focusing human review where it matters most rather than\n","trying to review everything or reviewing randomly. The qa_reviewer_checklist\n","function generates a standardized six-item checklist for human reviewers: verify\n","status is \"Not verified,\" check if questions are substantive, confirm no\n","recommendation language, verify numeric claims are sourced, assess coherence,\n","and validate risk identification. The update_qa_results function records all QA\n","samples and maintains summary statistics.\n","\n","The final function, log_stage_gate, creates the append-only audit trail that\n","records every transition in the workflow. When Stage A completes, it logs\n","\"intake_narrative_drafted = passed.\" When Stage B completes, it logs\n","\"deliverable_drafted = passed.\" These entries go into stage_gate_log.jsonl which\n","never gets modified, only appended to, creating a tamper-evident timeline of\n","exactly what happened and when.\n","\n","What's crucial to understand is that none of these functions call the AI. They're\n","pure organizational infrastructure - data manipulation, file management, business\n","rule execution. The build_controls_checklist function doesn't ask AI what controls\n","to apply; it applies firm policy through if-then logic. The qa_sample_selector\n","doesn't ask AI what to review; it applies sampling rules deterministically. These\n","functions represent what traditional code does best: execute organizational rules\n","consistently at scale without variation or interpretation.\n","\n","When Cell 7 finishes loading, you see a summary listing all eight functions under\n","categories: Intake & Controls, Verification & Approval, QA Sampling, and Stage\n","Gates. This isn't just informational - it's showing you the organizational\n","capabilities now available. These functions are the building blocks that Cell 8\n","will orchestrate into complete workflows, and Cell 9 will use for your custom\n","case.\n","\n","The beauty of separating these functions into their own cell is clarity and\n","reusability. Each function has a single clear purpose. Each can be tested\n","independently. Each can be modified to reflect changed firm policy without\n","touching the AI wrapper or workflow orchestration. If your firm decides that\n","medium-risk cases should require dual approval instead of single Partner approval,\n","you modify build_controls_checklist in one place and the change affects every\n","case processed from that point forward.\n","\n","Cell 7 represents organizational design made executable. Instead of hoping\n","consultants remember to check controls, route approvals correctly, and log\n","decisions, the code does it automatically and consistently. This is the\n","organizational skeleton - the structure that supports everything else and ensures\n","the firm operates as a system rather than a collection of individuals doing their\n","own thing."],"metadata":{"id":"HuBP5-TijDA1"}},{"cell_type":"markdown","source":["####7.1.1.THE CONNECTION OF CELL 4 AND CELL 7"],"metadata":{"id":"vidssCyMcnPN"}},{"cell_type":"markdown","source":["\n","\n","**CELL 4 = The Organizational Anatomy (Structure)**\n","\n","Cell 4 defines the skeleton and organs of the organization:\n","\n","- org_policy.json = The organization's DNA/rules\n","  (what we're allowed to do, what's prohibited)\n","\n","- workflow_runbook.json = The circulatory system map\n","  (blood flows from heart â†’ arteries â†’ organs â†’ veins)\n","  \n","  - Lists the stages:\n","    Intake â†’ Controls â†’ Drafting A â†’ Drafting B â†’ Drafting C â†’ QA â†’ Approval\n","  \n","  - Defines the gates between stages:\n","    \"intake_complete\", \"controls_assigned\", etc.\n","  \n","  - Assigns roles (RACI):\n","    who is Responsible, Accountable, Consulted, Informed\n","\n","**Cell 4 is the blueprint.**\n","It says: \"Here's how work SHOULD flow through our organization.\"\n","\n","\n","**CELL 7 = The Organizational Physiology (Functions)**\n","\n","Cell 7 defines the biological functions that make the body work:\n","\n","- **build_intake_record()**\n","  = The mouth/digestive system (takes in raw work)\n","\n","- **build_controls_checklist()**\n","  = The immune system (checks: is this safe to process?)\n","\n","- **build_verification_register_stub()**\n","  = The quality control sensors (what needs human verification?)\n","\n","- **build_approval_stub()**\n","  = The executive brain (who must approve before release?)\n","\n","- **qa_sample_selector()**\n","  = The internal auditor (random health checks)\n","\n","- **log_stage_gate()**\n","  = The nervous system (records that we passed from one stage to the next)\n","\n","*Cell 7 is the machinery.\n","It says: \"Here's HOW we execute each step of the workflow.\"*\n","\n","---\n","**The Conceptual Bridge: Workflow â†’ Lifecycle**\n","\n","Concept: Workflow\n","  What it means: The sequence of stages work goes through (like a factory assembly line)\n","  Where it lives: Cell 4 - workflow_runbook.json\n","\n","Concept: Lifecycle\n","  What it means: The complete journey of a single piece of work from birth to archive\n","                 (like a product going from raw materials â†’ manufacturing â†’ QA â†’ shipping)\n","  Where it lives: Happens when Cell 7 functions are executed in Cell 8\n","\n","\n","---\n","**Why \"Lifecycle\"?**\n","\n","Because every consulting deliverable has a life:\n","\n","1. Birth (Intake): A request comes in\n","2. Growth (Drafting): The work gets developed through stages\n","3. Maturity (QA + Approval): The work gets checked and approved\n","4. Archive (Recordkeeping): The work is stored with full audit trail\n","\n","The workflow (Cell 4) defines the stages.  \n","The lifecycle builders (Cell 7) are the functions that shepherd each piece\n","of work through those stages.\n","\n","---\n","**What Happens in the Workflow? (Cell 7 Functions Explained)**\n","\n","Think of a consulting case flowing through the organization:\n","\n","\n","**1. Intake Stage**\n","\n","- Function: build_intake_record()\n","- What happens: Client asks \"Help us enter the APAC market\"\n","- Output: Creates intake_record.json with purpose, data classification, scope\n","- Gate: log_stage_gate(gate_name=\"intake_complete\")\n","\n","\n","**2. Controls Stage**\n","\n","- Function: build_controls_checklist()\n","- What happens: System checks data classification â†’ determines risk tier\n","               â†’ assigns required controls\n","- Output: Creates controls_checklist.json with required safeguards\n","- Gate: log_stage_gate(gate_name=\"controls_assigned\")\n","\n","\n","**3. Drafting Stages (A, B, C)**\n","\n","- Function: LLM call via call_llm_structured() (from Cell 6)\n","- What happens:\n","  - Stage A: Draft intake narrative\n","  - Stage B: Draft deliverable (memo, workplan, etc.)\n","  - Stage C: Draft verification plan\n","- Output: Each stage produces a JSON file with draft_output, open_questions, risks\n","- Gate: log_stage_gate(gate_name=\"deliverable_drafted\") after each stage\n","\n","\n","**4. Verification Planning**\n","\n","- Function: build_verification_register_stub()\n","- What happens: Extract all open_questions and questions_to_verify from drafts\n","- Output: Updates verification_register.json with what humans must verify\n","- Gate: log_stage_gate(gate_name=\"verification_plan_created\")\n","\n","\n","**5. QA Sampling Stage**\n","\n","- Function: qa_sample_selector() + qa_reviewer_checklist()\n","- What happens: Select 1-2 artifacts per case for human QA review\n","- Output: Creates QA checklists in qa_results.json\n","- Gate: log_stage_gate(gate_name=\"samples_selected\")\n","\n","\n","**6. Approval Stage**\n","\n","- Function: build_approval_stub()\n","- What happens: Create pending approval requests for human approvers\n","- Output: Updates approvals_log.json with pending approvals\n","- Gate: log_stage_gate(gate_name=\"approval_pending\")\n","\n","\n","**7. Archive Stage (Cell 10)**\n","\n","- Function: Create ZIP bundle with all artifacts\n","- What happens: Package everything for audit trail\n","- Output: Complete evidence bundle\n","\n","---\n","**Simple Summary**\n","\n","- Cell 4 = Organization Chart + Process Map  \n","\"Here's our workflow: Intake â†’ Controls â†’ Drafting â†’ QA â†’ Approval â†’ Archive\"\n","\n","- Cell 7 = The Functions/Tools That Execute Each Step  \n","\"Here's the intake function, here's the controls function, here's the QA\n","function, etc.\"\n","\n","- Cell 8 (coming next) = Actually Running Cases Through the Lifecycle  \n","\"Let's take 4 mini-cases and run them through all these stages using the\n","functions from Cell 7\"\n","\n","---\n","**Why This Matters for Level 5 (Organizations)**\n","\n","At Level 1-4, you might just have a smart AI that drafts good memos.\n","\n","At Level 5 (Organizations), you have:\n","\n","- Intake gates (not all work gets in)\n","- Risk-based controls (high-risk work gets extra scrutiny)\n","- Stage gates (work must pass checkpoints)\n","- QA sampling (systematic quality checks)\n","- Approval routing (humans decide what gets released)\n","- Complete audit trail (we can reconstruct everything)\n","\n","**Cell 7 functions are the organizational machinery that makes this possible.**"],"metadata":{"id":"pWdWz-GKayJx"}},{"cell_type":"markdown","source":["####7.1.2.LEVEL 3 VERSUS LEVEL 5"],"metadata":{"id":"D6WU_KZNd7U_"}},{"cell_type":"markdown","source":["**Level 5 is fundamentally different from Level 3**\n","\n","The key difference is NOT size, it's ORGANIZATIONAL DESIGN\n","\n","Let me explain:\n","\n","---\n","**LEVEL 3 (Workflows) - The Individual Consultant's Toolkit**\n","\n","At Level 3, you have:\n","- A smart workflow that helps ONE consultant do their job better\n","- Human-in-the-loop for specific decisions\n","- Maybe some logging and verification steps\n","- Focus: \"How does this help ME work smarter?\"\n","\n","**Example Level 3 scenario:**\n","- Sarah the consultant has a workflow that helps her draft client memos\n","- The workflow asks her to verify facts before finalizing\n","- She reviews, approves, sends to client\n","- Maybe she keeps a folder with her drafts\n","\n","This is about INDIVIDUAL PRODUCTIVITY with governance guardrails.\n","\n","---\n","**LEVEL 5 (Organizations) - The Firm's Operating Model**\n","\n","At Level 5, you have:\n","- A FIRM-WIDE system that manages work across MANY consultants\n","- Organizational roles (intake, QA, approver, risk officer)\n","- Systematic controls that apply to ALL work, not just one person's\n","- Audit trails for compliance, not just individual memory\n","- Focus: \"How does the FIRM ensure quality and accountability at scale?\"\n","\n","Example Level 5 scenario:\n","- 50 consultants are using AI to draft deliverables\n","- The FIRM needs to ensure:\n","  - All high-risk work gets senior review (not just when Sarah remembers)\n","  - QA samples are systematically selected (not ad-hoc)\n","  - Approvals are routed correctly (not \"Sarah emails her boss\")\n","  - Audit trail exists for client disputes or regulatory review\n","  - Policy violations are detected and escalated\n","  - The firm can prove \"we followed our process\" 6 months later\n","\n","---\n","**Key Conceptual Differences**\n","\n","\n","**1. SCALE OF COORDINATION**\n","\n","Level 3: One person's workflow\n","  - Sarah knows what she did yesterday\n","  - She can explain her decisions if asked\n","  - Her boss trusts her judgment\n","\n","Level 5: Organizational coordination across many people\n","  - 50 consultants doing similar work\n","  - Partners need visibility: \"Are our controls working?\"\n","  - Regulators ask: \"Show me your AI governance process\"\n","  - We need SYSTEMATIC evidence, not individual memory\n","\n","\n","**2. ROLE SEPARATION**\n","\n","Level 3: Same person does everything\n","  - Sarah drafts\n","  - Sarah verifies\n","  - Sarah approves\n","  - Sarah archives\n","\n","Level 5: Separation of duties\n","  - Consultant drafts\n","  - Risk officer assigns controls\n","  - QA lead samples outputs\n","  - Senior partner approves high-risk work\n","  - System logs everything automatically\n","\n","This is ORGANIZATIONAL DESIGN - you can't do this alone.\n","\n","\n","**3. CONTROLS PHILOSOPHY**\n","\n","Level 3: \"I'm careful and thoughtful\"\n","  - Relies on individual competence\n","  - Ad-hoc quality checks\n","  - \"I know I verified the numbers because I remember doing it\"\n","\n","**Level 5: \"The system enforces controls even if individuals forget\"**\n","  - Controls are AUTOMATIC and SYSTEMATIC\n","  - High-risk work MUST get senior review (system enforces)\n","  - QA sampling happens whether you remember or not\n","  - Audit trail exists whether you documented it or not\n","\n","This is the difference between \"best practices\" and \"enforced process\".\n","\n","\n","**4. ACCOUNTABILITY MODEL**\n","\n","Level 3: Individual accountability\n","  - \"Sarah made a mistake\"\n","  - Fix: \"Sarah needs more training\"\n","\n","Level 5: Organizational accountability\n","  - \"Did our QA process catch this before it went to the client?\"\n","  - \"Why did the approval gate not flag this risk?\"\n","  - \"What does our incident log say about similar cases?\"\n","  - Fix: \"We need to adjust our sampling strategy\"\n","\n","The firm is accountable for the SYSTEM, not just individual performance.\n","\n","\n","**5. TIME HORIZON**\n","\n","Level 3: Current work\n","  - \"Did I do good work on this project?\"\n","  - Documentation is for ME to remember\n","\n","Level 5: Institutional memory\n","  - \"Can we reconstruct what happened 6 months ago?\"\n","  - \"If this consultant leaves, can someone else understand the work?\"\n","  - \"If we're audited, can we prove compliance?\"\n","  - Documentation is for the ORGANIZATION to defend itself\n","\n","\n","**The \"Bigger\" Trap**\n","\n","You asked: \"Is Level 5 just Level 3 but bigger?\"\n","\n","NO - because you can't just add more people to a Level 3 system.\n","\n","Here's why:\n","\n","Level 3 scaled up = CHAOS\n","  - 50 consultants all doing their own thing\n","  - No consistent controls\n","  - No systematic QA\n","  - No audit trail\n","  - Partners have no visibility\n","  - Regulatory risk is HIGH\n","\n","Level 5 = DESIGNED organizational system\n","  - Consistent intake and controls across all consultants\n","  - Systematic QA sampling (not ad-hoc)\n","  - Centralized approval routing\n","  - Firm-wide audit trail\n","  - Partners have dashboards and reports\n","  - Regulatory compliance is DEMONSTRABLE\n","\n","\n","**Real-World Analogy**\n","\n","Level 3 = A skilled chef in their home kitchen\n","  - They know what ingredients they used\n","  - They taste and adjust as they cook\n","  - They remember what worked last time\n","  - Works great for feeding their family\n","\n","Level 5 = A restaurant chain's kitchen system\n","  - Standardized recipes (workflow_runbook.json)\n","  - Quality control checks at each station (stage gates)\n","  - Health inspector can audit (compliance trail)\n","  - Manager samples dishes randomly (QA sampling)\n","  - Head chef approves new menu items (approval routing)\n","  - Works for 100 locations serving 10,000 customers/day\n","\n","You can't run a restaurant chain by just hiring 100 great chefs and saying\n","\"do what you did at home, but more.\"\n","\n","You need ORGANIZATIONAL DESIGN.\n","\n","---\n","What Cell 4 and Cell 7 Actually Do\n","\n","**Cell 4 (org_policy.json, workflow_runbook.json):**\n","  - Defines the FIRM'S process (not one person's workflow)\n","  - Specifies roles and responsibilities (RACI)\n","  - Sets policy boundaries (prohibited uses, escalation triggers)\n","  - This is the \"operating manual\" for the firm\n","\n","Cell 7 (lifecycle builders):\n","  - Implements the FIRM'S controls programmatically\n","  - Ensures controls execute SYSTEMATICALLY (not ad-hoc)\n","  - Creates the organizational audit trail\n","  - These are the \"machinery\" of firm-wide governance\n","\n","You could NOT do this at Level 3 because:\n","  - Level 3 doesn't have organizational roles\n","  - Level 3 doesn't have firm-wide policy\n","  - Level 3 doesn't need systematic QA sampling\n","  - Level 3 doesn't need multi-party approval routing\n","\n","\n","**Bottom Line**\n","\n","Level 3 = Individual consultant + smart workflow + some verification\n","  â†’ \"I work better\"\n","\n","Level 5 = Organizational operating model + systematic controls + audit trail\n","  â†’ \"The FIRM can scale AI responsibly\"\n","\n","The difference is not SIZE.\n","The difference is ORGANIZATIONAL DESIGN.\n","\n","Level 5 answers questions that don't exist at Level 3:\n","  - \"How does the firm ensure consistent quality across 50 consultants?\"\n","  - \"How do we prove to regulators that our AI governance works?\"\n","  - \"How do we detect and escalate policy violations systematically?\"\n","  - \"How do partners get visibility into AI-assisted work quality?\"\n","  - \"How do we maintain institutional memory and auditability?\"\n","\n","These are ORGANIZATIONAL questions, not individual productivity questions."],"metadata":{"id":"TW-1ZIWkejm6"}},{"cell_type":"markdown","source":["###7.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"X1KSLRldNBYW"}},{"cell_type":"code","source":["# Cell 7: Level 5 Lifecycle Builders (Intake â†’ Controls â†’ QA â†’ Approval â†’ Archive)\n","\n","def build_intake_record(case_name, purpose, intended_reliance, data_classification, scope_boundary):\n","    \"\"\"\n","    Create intake record for a case.\n","\n","    Args:\n","        case_name: Name of the case\n","        purpose: What this work is for\n","        intended_reliance: How outputs will be used\n","        data_classification: \"public\" | \"internal\" | \"confidential\" | \"restricted\"\n","        scope_boundary: What is in/out of scope\n","\n","    Returns:\n","        intake_record dict\n","    \"\"\"\n","    intake_record = {\n","        \"case_name\": case_name,\n","        \"intake_timestamp\": datetime.datetime.now().isoformat(),\n","        \"purpose\": purpose,\n","        \"intended_reliance\": intended_reliance,\n","        \"data_classification\": data_classification,\n","        \"scope_boundary\": scope_boundary,\n","        \"intake_id\": hashlib.sha256(f\"{case_name}_{datetime.datetime.now().isoformat()}\".encode()).hexdigest()[:12]\n","    }\n","\n","    # Save to stage_outputs\n","    case_dir = run_dir / \"stage_outputs\" / case_name\n","    case_dir.mkdir(parents=True, exist_ok=True)\n","\n","    with open(case_dir / \"intake_record.json\", \"w\") as f:\n","        json.dump(intake_record, f, indent=2)\n","\n","    return intake_record\n","\n","def build_controls_checklist(intake_record):\n","    \"\"\"\n","    Generate controls checklist based on intake risk tier.\n","\n","    Risk tier determination:\n","        - \"restricted\" data â†’ high\n","        - \"confidential\" data â†’ medium\n","        - \"internal\" or \"public\" â†’ low\n","\n","    Returns:\n","        controls_checklist dict\n","    \"\"\"\n","    data_class = intake_record.get(\"data_classification\", \"internal\")\n","\n","    # Determine risk tier\n","    if data_class == \"restricted\":\n","        risk_tier = \"high\"\n","    elif data_class == \"confidential\":\n","        risk_tier = \"medium\"\n","    else:\n","        risk_tier = \"low\"\n","\n","    # Base controls (all tiers)\n","    controls = [\n","        \"Redaction of PII applied\",\n","        \"Minimum necessary principle enforced\",\n","        \"verification_status = 'Not verified' confirmed\",\n","        \"Human review required before release\"\n","    ]\n","\n","    # Medium tier additional controls\n","    if risk_tier in [\"medium\", \"high\"]:\n","        controls.extend([\n","            \"Senior approver required\",\n","            \"QA sampling mandatory\",\n","            \"Numeric claims verified against source data\"\n","        ])\n","\n","    # High tier additional controls\n","    if risk_tier == \"high\":\n","        controls.extend([\n","            \"Legal review required\",\n","            \"Dual approval (consultant + senior approver)\",\n","            \"Enhanced audit trail (video/screenshot evidence)\",\n","            \"30-day retention minimum for all artifacts\"\n","        ])\n","\n","    controls_checklist = {\n","        \"case_name\": intake_record[\"case_name\"],\n","        \"intake_id\": intake_record[\"intake_id\"],\n","        \"risk_tier\": risk_tier,\n","        \"required_controls\": controls,\n","        \"controls_timestamp\": datetime.datetime.now().isoformat(),\n","        \"verification_status\": \"Not verified\"\n","    }\n","\n","    # Save to stage_outputs\n","    case_dir = run_dir / \"stage_outputs\" / intake_record[\"case_name\"]\n","    with open(case_dir / \"controls_checklist.json\", \"w\") as f:\n","        json.dump(controls_checklist, f, indent=2)\n","\n","    return controls_checklist\n","\n","def build_verification_register_stub(case_name, stage_name, model_output):\n","    \"\"\"\n","    Create verification register entry from model output.\n","\n","    Extracts open_questions and questions_to_verify and adds to register.\n","    \"\"\"\n","    # Read current register\n","    with open(run_dir / \"verification_register.json\", \"r\") as f:\n","        register = json.load(f)\n","\n","    # Extract questions\n","    open_questions = model_output.get(\"open_questions\", [])\n","    questions_to_verify = model_output.get(\"questions_to_verify\", [])\n","\n","    # Create entry\n","    entry = {\n","        \"case_name\": case_name,\n","        \"stage_name\": stage_name,\n","        \"timestamp\": datetime.datetime.now().isoformat(),\n","        \"open_questions\": open_questions,\n","        \"questions_to_verify\": questions_to_verify,\n","        \"verification_status\": model_output.get(\"verification_status\", \"Not verified\"),\n","        \"assigned_to\": \"Human Reviewer (TBD)\",\n","        \"priority\": \"medium\"\n","    }\n","\n","    register[\"items\"].append(entry)\n","\n","    # Write back\n","    with open(run_dir / \"verification_register.json\", \"w\") as f:\n","        json.dump(register, f, indent=2)\n","\n","    return entry\n","\n","def build_approval_stub(case_name, artifact_name, approver_role, state=\"pending\"):\n","    \"\"\"\n","    Create approval routing stub.\n","\n","    Args:\n","        case_name: Name of the case\n","        artifact_name: Name of the artifact requiring approval\n","        approver_role: Role of approver (e.g., \"Senior Consultant\", \"Partner\")\n","        state: \"pending\" | \"approved\" | \"rejected\"\n","\n","    Returns:\n","        approval_entry dict\n","    \"\"\"\n","    # Read current approvals log\n","    with open(run_dir / \"approvals_log.json\", \"r\") as f:\n","        approvals_log = json.load(f)\n","\n","    approval_entry = {\n","        \"case_name\": case_name,\n","        \"artifact_name\": artifact_name,\n","        \"approver_role\": approver_role,\n","        \"state\": state,\n","        \"requested_timestamp\": datetime.datetime.now().isoformat(),\n","        \"approved_timestamp\": None,\n","        \"approval_id\": hashlib.sha256(f\"{case_name}_{artifact_name}_{datetime.datetime.now().isoformat()}\".encode()).hexdigest()[:12]\n","    }\n","\n","    approvals_log[\"approvals\"].append(approval_entry)\n","\n","    # Write back\n","    with open(run_dir / \"approvals_log.json\", \"w\") as f:\n","        json.dump(approvals_log, f, indent=2)\n","\n","    return approval_entry\n","\n","def qa_sample_selector(case_outputs, sampling_plan):\n","    \"\"\"\n","    Select QA samples based on sampling plan.\n","\n","    Args:\n","        case_outputs: list of dicts with keys: case_name, artifact_name, risk_level, stage_name\n","        sampling_plan: dict with sampling strategy\n","\n","    Returns:\n","        selected_samples: list of dicts\n","    \"\"\"\n","    selected = []\n","\n","    # Strategy: 1-2 artifacts per case\n","    # - Always include high-risk outputs\n","    # - Random sample from medium-risk\n","    # - First deliverable from each case type (baseline)\n","\n","    cases_seen = {}\n","\n","    for output in case_outputs:\n","        case_name = output[\"case_name\"]\n","        risk_level = output.get(\"risk_level\", \"medium\")\n","\n","        # Initialize case tracking\n","        if case_name not in cases_seen:\n","            cases_seen[case_name] = {\"high_sampled\": False, \"baseline_sampled\": False, \"count\": 0}\n","\n","        # High-risk: always sample\n","        if risk_level == \"high\" and not cases_seen[case_name][\"high_sampled\"]:\n","            selected.append({\n","                \"case_name\": case_name,\n","                \"artifact_name\": output[\"artifact_name\"],\n","                \"sample_reason\": \"high_risk\",\n","                \"stage_name\": output.get(\"stage_name\", \"unknown\")\n","            })\n","            cases_seen[case_name][\"high_sampled\"] = True\n","            cases_seen[case_name][\"count\"] += 1\n","\n","        # Baseline: first deliverable\n","        elif not cases_seen[case_name][\"baseline_sampled\"] and output.get(\"stage_name\") == \"stage_B\":\n","            selected.append({\n","                \"case_name\": case_name,\n","                \"artifact_name\": output[\"artifact_name\"],\n","                \"sample_reason\": \"baseline_first_deliverable\",\n","                \"stage_name\": output.get(\"stage_name\", \"unknown\")\n","            })\n","            cases_seen[case_name][\"baseline_sampled\"] = True\n","            cases_seen[case_name][\"count\"] += 1\n","\n","        # Cap at 2 per case\n","        if cases_seen[case_name][\"count\"] >= 2:\n","            continue\n","\n","    return selected\n","\n","def qa_reviewer_checklist(sample):\n","    \"\"\"\n","    Generate QA reviewer checklist for a sample.\n","\n","    This does NOT call the model - it's a human checklist.\n","\n","    Args:\n","        sample: dict with case_name, artifact_name, sample_reason, stage_name\n","\n","    Returns:\n","        checklist dict\n","    \"\"\"\n","    checklist = {\n","        \"sample_id\": hashlib.sha256(f\"{sample['case_name']}_{sample['artifact_name']}\".encode()).hexdigest()[:12],\n","        \"case_name\": sample[\"case_name\"],\n","        \"artifact_name\": sample[\"artifact_name\"],\n","        \"sample_reason\": sample[\"sample_reason\"],\n","        \"stage_name\": sample[\"stage_name\"],\n","        \"qa_timestamp\": datetime.datetime.now().isoformat(),\n","        \"reviewer\": \"Human QA Lead (TBD)\",\n","        \"checklist_items\": [\n","            {\n","                \"item\": \"verification_status is 'Not verified'\",\n","                \"status\": \"pending\",\n","                \"notes\": \"\"\n","            },\n","            {\n","                \"item\": \"open_questions are substantive and relevant\",\n","                \"status\": \"pending\",\n","                \"notes\": \"\"\n","            },\n","            {\n","                \"item\": \"No recommendation language detected\",\n","                \"status\": \"pending\",\n","                \"notes\": \"\"\n","            },\n","            {\n","                \"item\": \"Numeric claims (if any) are sourced from facts_provided or assumptions\",\n","                \"status\": \"pending\",\n","                \"notes\": \"\"\n","            },\n","            {\n","                \"item\": \"Draft output is coherent and aligned with scope_boundary\",\n","                \"status\": \"pending\",\n","                \"notes\": \"\"\n","            },\n","            {\n","                \"item\": \"Risks are appropriately identified and severity-rated\",\n","                \"status\": \"pending\",\n","                \"notes\": \"\"\n","            }\n","        ],\n","        \"overall_assessment\": \"pending\",\n","        \"escalations\": []\n","    }\n","\n","    return checklist\n","\n","def update_qa_results(samples_with_checklists):\n","    \"\"\"\n","    Update qa_results.json with selected samples and checklists.\n","\n","    Args:\n","        samples_with_checklists: list of dicts (sample + checklist)\n","    \"\"\"\n","    with open(run_dir / \"qa_results.json\", \"r\") as f:\n","        qa_results = json.load(f)\n","\n","    qa_results[\"samples\"].extend(samples_with_checklists)\n","\n","    qa_results[\"summary\"] = {\n","        \"total_samples\": len(qa_results[\"samples\"]),\n","        \"pending_review\": len([s for s in qa_results[\"samples\"] if s.get(\"overall_assessment\") == \"pending\"]),\n","        \"timestamp\": datetime.datetime.now().isoformat()\n","    }\n","\n","    with open(run_dir / \"qa_results.json\", \"w\") as f:\n","        json.dump(qa_results, f, indent=2)\n","\n","def log_stage_gate(case_name, stage_name, gate_name, gate_status, notes=\"\"):\n","    \"\"\"\n","    Log a stage gate decision to stage_gate_log.jsonl.\n","\n","    Args:\n","        case_name: Name of the case\n","        stage_name: Name of the stage (e.g., \"stage_A\", \"stage_B\")\n","        gate_name: Name of the gate (e.g., \"intake_complete\", \"deliverable_drafted\")\n","        gate_status: \"passed\" | \"failed\" | \"pending\"\n","        notes: Optional notes\n","    \"\"\"\n","    gate_entry = {\n","        \"timestamp\": datetime.datetime.now().isoformat(),\n","        \"case_name\": case_name,\n","        \"stage_name\": stage_name,\n","        \"gate_name\": gate_name,\n","        \"gate_status\": gate_status,\n","        \"notes\": notes\n","    }\n","\n","    with open(run_dir / \"logs\" / \"stage_gate_log.jsonl\", \"a\") as f:\n","        f.write(json.dumps(gate_entry) + \"\\n\")\n","\n","print(\"=\" * 70)\n","print(\"LEVEL 5 LIFECYCLE BUILDERS LOADED\")\n","print(\"=\" * 70)\n","print(\"\\nðŸ“‹ Available Functions:\")\n","print(\"\\n   Intake & Controls:\")\n","print(\"   â”œâ”€â”€ build_intake_record()\")\n","print(\"   â””â”€â”€ build_controls_checklist()\")\n","print(\"\\n   Verification & Approval:\")\n","print(\"   â”œâ”€â”€ build_verification_register_stub()\")\n","print(\"   â””â”€â”€ build_approval_stub()\")\n","print(\"\\n   QA Sampling:\")\n","print(\"   â”œâ”€â”€ qa_sample_selector()\")\n","print(\"   â”œâ”€â”€ qa_reviewer_checklist()\")\n","print(\"   â””â”€â”€ update_qa_results()\")\n","print(\"\\n   Stage Gates:\")\n","print(\"   â””â”€â”€ log_stage_gate()\")\n","print(\"\\nâœ“ All lifecycle builders ready for mini-case execution\")\n","print(\"=\" * 70)"],"metadata":{"id":"vw3KXun5NDTt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768929433181,"user_tz":360,"elapsed":55,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"848fb3ff-eb6a-4367-c20b-2bd994ea91e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","LEVEL 5 LIFECYCLE BUILDERS LOADED\n","======================================================================\n","\n","ðŸ“‹ Available Functions:\n","\n","   Intake & Controls:\n","   â”œâ”€â”€ build_intake_record()\n","   â””â”€â”€ build_controls_checklist()\n","\n","   Verification & Approval:\n","   â”œâ”€â”€ build_verification_register_stub()\n","   â””â”€â”€ build_approval_stub()\n","\n","   QA Sampling:\n","   â”œâ”€â”€ qa_sample_selector()\n","   â”œâ”€â”€ qa_reviewer_checklist()\n","   â””â”€â”€ update_qa_results()\n","\n","   Stage Gates:\n","   â””â”€â”€ log_stage_gate()\n","\n","âœ“ All lifecycle builders ready for mini-case execution\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##8.IMPLEMENTATION OF MINI CASES"],"metadata":{"id":"E9DiNZg2NOyv"}},{"cell_type":"markdown","source":["###8.1.OVERVIEW"],"metadata":{"id":"Ee1sdukLNP3S"}},{"cell_type":"markdown","source":["\n","\n","Think of Cell 8 as watching an entire consulting firm process four different\n","client engagements simultaneously, but in fast-forward. This is where everything\n","we've built - the organizational policies, the lifecycle functions, the AI\n","wrapper with all its safety checks - actually runs in practice.\n","\n","What makes this cell special is that it's not just running abstract examples.\n","It's processing four realistic consulting scenarios that represent the bread and\n","butter of strategy work: helping a company enter a new market, transforming cost\n","structures, preparing investment committee materials, and redesigning how\n","organizations operate. Each case follows the exact same governance process, but\n","produces different outputs appropriate to its type.\n","\n","Here's what happens when you run this cell. First, the system processes a market\n","entry case - imagine a company wanting to expand into Asia-Pacific. The system\n","creates an intake record documenting what the client wants and how sensitive the\n","information is. It assigns controls based on risk (if it's internal company data,\n","it gets medium-level controls; if it's public information, it gets lighter\n","oversight). Then comes the three-stage drafting process. Stage A creates an\n","intake narrative that summarizes the client request in plain language. Stage B\n","drafts the actual deliverable template - in this case, a client update memo\n","structure with sections for market analysis, competitive landscape, and next\n","steps. Stage C creates a verification plan that lists everything a human needs\n","to double-check before this goes to the client.\n","\n","What's happening behind the scenes is fascinating. At each stage, the AI model\n","gets called to draft content. But remember all those safety checks we built in\n","Cell 6? They're running automatically. Every time the AI produces text, the\n","system checks: Is this valid data? Did the AI accidentally include recommendation\n","language like \"we recommend you do X\"? Did it make up any numbers that weren't\n","in the original facts? Are all the required fields present? If anything fails\n","these checks, the system logs an incident and either retries or stops the process.\n","\n","After the AI drafts each stage, the lifecycle functions from Cell 7 spring into\n","action. They extract all the open questions the AI identified and add them to a\n","central verification register - think of this as a master to-do list of things\n","humans need to verify. They create approval routing entries that say \"This\n","bundle needs a Partner to review it before it goes to the client.\" They log every\n","gate passage to an audit trail so six months from now, you can see exactly what\n","happened and when.\n","\n","Then the system processes the second case - a cost transformation program for a\n","manufacturing client. This one is marked confidential because it involves internal\n","cost data. Watch what happens: the system automatically assigns stricter controls\n","because of the higher sensitivity. It requires a Partner approver instead of just\n","a Senior Consultant. It mandates QA sampling. The drafting process creates a\n","workplan structure with weekly update templates instead of a client memo. Same\n","process, different outputs.\n","\n","The third case involves investment committee materials - the pre-read documents\n","that executives review before making capital allocation decisions. This case\n","demonstrates something critical: the system enforces strict neutrality. The AI\n","is explicitly forbidden from making recommendations. It can frame scenarios\n","(\"Option A would prioritize growth; Option B would prioritize stability\") but\n","cannot say \"we recommend Option A.\" The policy checks we built catch any attempt\n","to sneak in recommendation language, and if they find it, they log a high-severity\n","incident and add a risk flag to the output.\n","\n","The fourth case tackles operating model redesign - creating RACI matrices (who's\n","Responsible, Accountable, Consulted, Informed) and operating cadences (when do\n","teams meet, what gets decided at each meeting). This shows how the system handles\n","change management content, which is particularly sensitive because it affects\n","people's roles and responsibilities.\n","\n","Throughout all four cases, something important is happening with quality\n","assurance. The system is collecting all the risks the AI identified at each\n","stage. Did the AI flag missing information? Did it note that certain assumptions\n","need validation? The system aggregates these risks and determines the highest\n","severity level for each case. If any case has high-severity risks, it\n","automatically gets selected for QA sampling. This isn't random - it's risk-based.\n","The cases that are most likely to have issues get human review, while\n","straightforward cases with only low-risk flags might skip the extra review.\n","\n","At the end of processing all four cases, Cell 8 produces a summary table. This\n","is your organizational dashboard. You can see at a glance: Which cases have the\n","most open questions (meaning more human verification work needed)? Which cases\n","triggered high-severity risks (meaning potential problems)? Which cases got\n","selected for QA review? How many artifacts did each case produce? This table\n","tells the story of your firm's workload and where human attention should focus.\n","\n","But here's what makes this truly organizational rather than just individual\n","productivity. Every artifact produced - and we're talking about five artifacts\n","per case, so twenty total across the four cases - has a complete governance trail.\n","There's an intake record showing who requested it and why. There's a controls\n","checklist showing what safety measures apply. There are three stage outputs\n","showing the evolution from initial intake to final deliverable. There's a bundle\n","index with cryptographic hashes proving the files haven't been tampered with.\n","There's a human-readable summary that someone can actually read without technical\n","knowledge. There's an approval entry showing whose desk this is waiting on. And\n","potentially, there's a QA checklist showing what needs review.\n","\n","The power of this cell is demonstrating that organizational governance at scale\n","is possible. This isn't one consultant carefully managing one case with AI\n","assistance. This is a system processing multiple cases simultaneously, applying\n","consistent controls, routing approvals correctly, selecting QA samples\n","systematically, and creating complete audit trails - all automatically. The\n","humans aren't eliminated; they're positioned at the control points where judgment\n","matters: approving deliverables, conducting QA reviews, and verifying facts.\n","\n","When consultants talk about \"AI transformation,\" they often imagine either AI\n","replacing people or AI just making suggestions while people do all the real work.\n","Cell 8 shows the third path: AI drafting content at scale, traditional code\n","enforcing organizational rules, and humans exercising judgment at critical gates.\n","It's not about being \"more efficient\" - it's about being organizationally\n","coherent at scale. Every case follows the same process. Every case gets the same\n","controls for its risk tier. Every case produces the same governance artifacts.\n","This consistency is what separates a Level 5 organization from a collection of\n","individual consultants who happen to use AI tools.\n","\n","By the time Cell 8 finishes running, you have a complete mini-firm operation\n","captured in data: intake records, drafts, verification lists, approval queues,\n","QA samples, and audit trails. A partner could review the summary table and\n","immediately understand the firm's workload and risk exposure. A compliance\n","officer could examine the audit trails and verify that proper process was\n","followed. A new consultant could read the human-readable summaries and understand\n","what work has been done. This is organizational memory and institutional\n","capability, not just individual work product.\n","\n","The cell ends with a clear message: the mini-cases are complete, but the\n","organizational process continues. Approvals are pending (humans need to review).\n","QA samples are selected (humans need to assess quality). Verification questions\n","are registered (humans need to find answers). The AI and automation have moved\n","the work forward systematically; now the humans need to exercise the judgment\n","that only they can provide."],"metadata":{"id":"UPGXnne7NtGW"}},{"cell_type":"markdown","source":["###8.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"BIE5Ni_wNRvq"}},{"cell_type":"code","source":["# Cell 8: Run 4 Mini-Case Demos (Mini-Firm Pipeline)\n","\n","import json\n","\n","# ============================================================================\n","# MINI-CASE DEFINITIONS\n","# ============================================================================\n","\n","mini_cases = [\n","    {\n","        \"case_name\": \"market_entry_apac\",\n","        \"purpose\": \"Standardized client update memo for APAC market entry evaluation\",\n","        \"intended_reliance\": \"Monthly steering committee updates; inform go/no-go decision\",\n","        \"data_classification\": \"internal\",\n","        \"scope_boundary\": \"In scope: market sizing, competitive landscape overview. Out of scope: detailed financial projections, legal/regulatory analysis\",\n","        \"facts_provided\": [\n","            \"Client is evaluating market entry into APAC region\",\n","            \"Three target markets under consideration: Singapore, Vietnam, Thailand\",\n","            \"Client has existing operations in Europe and North America\",\n","            \"Evaluation timeline: 6 months\"\n","        ]\n","    },\n","    {\n","        \"case_name\": \"cost_transformation_manufacturing\",\n","        \"purpose\": \"Standardized workplan and weekly update drafting for cost transformation program\",\n","        \"intended_reliance\": \"Program management office (PMO) tracking; executive dashboard\",\n","        \"data_classification\": \"confidential\",\n","        \"scope_boundary\": \"In scope: workplan structure, weekly status updates. Out of scope: specific cost reduction recommendations, workforce impact analysis\",\n","        \"facts_provided\": [\n","            \"Manufacturing client seeks 15-20% cost reduction over 18 months\",\n","            \"Four workstreams: procurement, operations, overhead, footprint optimization\",\n","            \"Weekly steering committee meetings require status updates\",\n","            \"Program involves 40+ FTEs across client and consulting team\"\n","        ]\n","    },\n","    {\n","        \"case_name\": \"capital_allocation_portfolio\",\n","        \"purpose\": \"Investment committee pre-read shell with scenario framing (strict neutrality)\",\n","        \"intended_reliance\": \"Investment committee preparatory materials; no decision authority\",\n","        \"data_classification\": \"confidential\",\n","        \"scope_boundary\": \"In scope: scenario framing, investment criteria summary, open questions. Out of scope: investment recommendations, financial projections, comparative scoring\",\n","        \"facts_provided\": [\n","            \"Investment committee evaluating three portfolio opportunities\",\n","            \"Decision criteria: strategic fit, financial returns, execution risk\",\n","            \"Committee meets monthly; requires pre-read materials 48 hours in advance\",\n","            \"Total capital available: not specified in intake\"\n","        ]\n","    },\n","    {\n","        \"case_name\": \"operating_model_redesign_finance\",\n","        \"purpose\": \"RACI matrix and operating cadence documentation for finance function redesign\",\n","        \"intended_reliance\": \"Change management toolkit; stakeholder alignment workshops\",\n","        \"data_classification\": \"internal\",\n","        \"scope_boundary\": \"In scope: RACI templates, operating cadence framework. Out of scope: specific role assignments, organizational structure recommendations, headcount implications\",\n","        \"facts_provided\": [\n","            \"Finance function redesign to support new business model\",\n","            \"Key processes: planning, reporting, analytics, controls\",\n","            \"Target state: centralized planning, distributed execution\",\n","            \"Implementation timeline: 12 months with phased rollout\"\n","        ]\n","    }\n","]\n","\n","# ============================================================================\n","# CONTROLLED DRAFTING WORKFLOW (3 STAGES PER CASE)\n","# ============================================================================\n","\n","def run_controlled_drafting(case_name, facts_provided, scope_boundary, purpose):\n","    \"\"\"\n","    Execute 3-stage controlled drafting workflow:\n","    - Stage A: Intake narrative (draft)\n","    - Stage B: Deliverable draft (memo/workplan/IC shell/RACI pack)\n","    - Stage C: Verification plan (draft)\n","\n","    Returns: dict with stage outputs and metadata\n","    \"\"\"\n","\n","    print(f\"\\n   Running controlled drafting for: {case_name}\")\n","    print(f\"   â”œâ”€â”€ Stage A: Intake narrative...\")\n","\n","    # ========================================================================\n","    # STAGE A: INTAKE NARRATIVE\n","    # ========================================================================\n","\n","    stage_a_prompt = f\"\"\"You are assisting a management consultant with intake documentation.\n","\n","Task: Draft an intake narrative that summarizes the client request and establishes scope boundaries.\n","\n","Facts provided:\n","{chr(10).join('- ' + f for f in facts_provided)}\n","\n","Scope boundary: {scope_boundary}\n","\n","Purpose: {purpose}\n","\n","Return ONLY a JSON object with this EXACT structure:\n","\n","{{\n","  \"task\": \"Draft intake narrative for {case_name}\",\n","  \"facts_provided\": {json.dumps(facts_provided)},\n","  \"assumptions\": [\"List any assumptions you're making\"],\n","  \"open_questions\": [\"List questions that need clarification\"],\n","  \"risks\": [\n","    {{\"type\": \"scope_creep|missing_facts|other\", \"severity\": \"low|medium|high\", \"note\": \"explain\"}}\n","  ],\n","  \"draft_output\": \"Your intake narrative here (2-3 paragraphs explaining the request, scope, and next steps)\",\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"What should the human verify?\"]\n","}}\n","\n","Remember:\n","- NO recommendations or \"we should do X\" language\n","- NO fabricated facts or numbers\n","- Flag gaps in facts_provided as open_questions\n","- Keep draft_output focused on intake documentation only\n","\"\"\"\n","\n","    stage_a_output = call_llm_structured(stage_a_prompt, case_name, \"stage_A\")\n","\n","    # Save Stage A output\n","    case_dir = run_dir / \"stage_outputs\" / case_name\n","    case_dir.mkdir(parents=True, exist_ok=True)\n","\n","    with open(case_dir / \"stage_A.json\", \"w\") as f:\n","        json.dump(stage_a_output, f, indent=2)\n","\n","    # Log gate\n","    log_stage_gate(case_name, \"stage_A\", \"intake_narrative_drafted\", \"passed\")\n","\n","    print(f\"   â”‚   âœ“ Stage A complete ({len(stage_a_output.get('open_questions', []))} open questions)\")\n","\n","    # ========================================================================\n","    # STAGE B: DELIVERABLE DRAFT\n","    # ========================================================================\n","\n","    print(f\"   â”œâ”€â”€ Stage B: Deliverable draft...\")\n","\n","    # Determine deliverable type based on case\n","    deliverable_type = {\n","        \"market_entry_apac\": \"client update memo shell\",\n","        \"cost_transformation_manufacturing\": \"workplan structure and weekly update template\",\n","        \"capital_allocation_portfolio\": \"investment committee pre-read shell with scenario framing\",\n","        \"operating_model_redesign_finance\": \"RACI matrix template and operating cadence framework\"\n","    }.get(case_name, \"deliverable\")\n","\n","    stage_b_prompt = f\"\"\"You are assisting a management consultant with deliverable drafting.\n","\n","Context from Stage A:\n","{stage_a_output.get('draft_output', '')}\n","\n","Task: Draft a {deliverable_type} shell/template.\n","\n","Facts provided:\n","{chr(10).join('- ' + f for f in facts_provided)}\n","\n","Scope boundary: {scope_boundary}\n","\n","Return ONLY a JSON object with this EXACT structure:\n","\n","{{\n","  \"task\": \"Draft {deliverable_type} for {case_name}\",\n","  \"facts_provided\": {json.dumps(facts_provided)},\n","  \"assumptions\": [\"List any assumptions\"],\n","  \"open_questions\": [\"What information is missing to complete this deliverable?\"],\n","  \"risks\": [\n","    {{\"type\": \"missing_facts|false_rigor|decision_laundering|other\", \"severity\": \"low|medium|high\", \"note\": \"explain\"}}\n","  ],\n","  \"draft_output\": \"Your deliverable shell/template here (structure, headers, placeholders where facts are missing)\",\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"What must the human verify before using this?\"]\n","}}\n","\n","CRITICAL:\n","- This is a SHELL/TEMPLATE, not final content\n","- Use placeholders like [TO BE VERIFIED: market size data] where facts are missing\n","- NO recommendations (\"we recommend\", \"you should\", \"best option\")\n","- NO fabricated numbers, dates, or benchmarks\n","- Flag all gaps as open_questions\n","\"\"\"\n","\n","    stage_b_output = call_llm_structured(stage_b_prompt, case_name, \"stage_B\")\n","\n","    # Save Stage B output\n","    with open(case_dir / \"stage_B.json\", \"w\") as f:\n","        json.dump(stage_b_output, f, indent=2)\n","\n","    # Log gate\n","    log_stage_gate(case_name, \"stage_B\", \"deliverable_drafted\", \"passed\")\n","\n","    print(f\"   â”‚   âœ“ Stage B complete ({len(stage_b_output.get('risks', []))} risks identified)\")\n","\n","    # ========================================================================\n","    # STAGE C: VERIFICATION PLAN\n","    # ========================================================================\n","\n","    print(f\"   â””â”€â”€ Stage C: Verification plan...\")\n","\n","    # Aggregate open questions from A and B\n","    all_open_questions = (\n","        stage_a_output.get('open_questions', []) +\n","        stage_b_output.get('open_questions', [])\n","    )\n","\n","    stage_c_prompt = f\"\"\"You are assisting a management consultant with verification planning.\n","\n","Context: We have drafted intake narrative and deliverable shell for {case_name}.\n","\n","Open questions from previous stages:\n","{chr(10).join('- ' + q for q in all_open_questions) if all_open_questions else \"- None\"}\n","\n","Task: Create a verification plan that identifies what the human consultant must verify before using these outputs.\n","\n","Return ONLY a JSON object with this EXACT structure:\n","\n","{{\n","  \"task\": \"Create verification plan for {case_name}\",\n","  \"facts_provided\": [\"Facts we used in stages A and B\"],\n","  \"assumptions\": [\"Assumptions we made\"],\n","  \"open_questions\": {json.dumps(all_open_questions)},\n","  \"risks\": [\n","    {{\"type\": \"missing_facts|traceability|other\", \"severity\": \"low|medium|high\", \"note\": \"explain\"}}\n","  ],\n","  \"draft_output\": \"Verification plan: (1) List what needs verification (2) Suggest verification sources (3) Flag high-priority verifications\",\n","  \"verification_status\": \"Not verified\",\n","  \"questions_to_verify\": [\"Meta-question: Is this verification plan complete?\"]\n","}}\n","\n","Focus on:\n","- Which facts need external verification?\n","- Which assumptions need validation?\n","- Which open questions are blockers vs nice-to-have?\n","- What sources should the human consult?\n","\"\"\"\n","\n","    stage_c_output = call_llm_structured(stage_c_prompt, case_name, \"stage_C\")\n","\n","    # Save Stage C output\n","    with open(case_dir / \"stage_C.json\", \"w\") as f:\n","        json.dump(stage_c_output, f, indent=2)\n","\n","    # Log gate\n","    log_stage_gate(case_name, \"stage_C\", \"verification_plan_drafted\", \"passed\")\n","\n","    print(f\"       âœ“ Stage C complete\")\n","\n","    # ========================================================================\n","    # UPDATE VERIFICATION REGISTER\n","    # ========================================================================\n","\n","    build_verification_register_stub(case_name, \"stage_A\", stage_a_output)\n","    build_verification_register_stub(case_name, \"stage_B\", stage_b_output)\n","    build_verification_register_stub(case_name, \"stage_C\", stage_c_output)\n","\n","    return {\n","        \"stage_A\": stage_a_output,\n","        \"stage_B\": stage_b_output,\n","        \"stage_C\": stage_c_output\n","    }\n","\n","# ============================================================================\n","# MAIN EXECUTION: RUN ALL 4 MINI-CASES\n","# ============================================================================\n","\n","print(\"=\" * 70)\n","print(\"RUNNING 4 MINI-CASE DEMOS (MINI-FIRM PIPELINE)\")\n","print(\"=\" * 70)\n","\n","case_results = []\n","case_outputs_for_qa = []\n","\n","for i, case in enumerate(mini_cases, 1):\n","    print(f\"\\n[{i}/4] Case: {case['case_name']}\")\n","    print(f\"      Purpose: {case['purpose'][:60]}...\")\n","    print(f\"      Data Classification: {case['data_classification']}\")\n","\n","    # ========================================================================\n","    # 1) INTAKE + CONTROLS\n","    # ========================================================================\n","\n","    intake_record = build_intake_record(\n","        case_name=case['case_name'],\n","        purpose=case['purpose'],\n","        intended_reliance=case['intended_reliance'],\n","        data_classification=case['data_classification'],\n","        scope_boundary=case['scope_boundary']\n","    )\n","\n","    controls_checklist = build_controls_checklist(intake_record)\n","\n","    print(f\"   âœ“ Intake + Controls (risk tier: {controls_checklist['risk_tier']})\")\n","\n","    # ========================================================================\n","    # 2) CONTROLLED DRAFTING WORKFLOW (3 STAGES)\n","    # ========================================================================\n","\n","    stage_outputs = run_controlled_drafting(\n","        case_name=case['case_name'],\n","        facts_provided=case['facts_provided'],\n","        scope_boundary=case['scope_boundary'],\n","        purpose=case['purpose']\n","    )\n","\n","    # ========================================================================\n","    # 3) CREATE DELIVERABLE BUNDLE INDEX\n","    # ========================================================================\n","\n","    deliverable_bundle = {\n","        \"case_name\": case['case_name'],\n","        \"intake_id\": intake_record['intake_id'],\n","        \"risk_tier\": controls_checklist['risk_tier'],\n","        \"artifacts\": [\n","            {\"name\": \"intake_record.json\", \"hash\": hashlib.sha256(json.dumps(intake_record).encode()).hexdigest()[:16]},\n","            {\"name\": \"controls_checklist.json\", \"hash\": hashlib.sha256(json.dumps(controls_checklist).encode()).hexdigest()[:16]},\n","            {\"name\": \"stage_A.json\", \"hash\": hashlib.sha256(json.dumps(stage_outputs['stage_A']).encode()).hexdigest()[:16]},\n","            {\"name\": \"stage_B.json\", \"hash\": hashlib.sha256(json.dumps(stage_outputs['stage_B']).encode()).hexdigest()[:16]},\n","            {\"name\": \"stage_C.json\", \"hash\": hashlib.sha256(json.dumps(stage_outputs['stage_C']).encode()).hexdigest()[:16]}\n","        ],\n","        \"created_timestamp\": datetime.datetime.now().isoformat()\n","    }\n","\n","    # Save bundle index\n","    with open(run_dir / \"deliverables\" / f\"{case['case_name']}_bundle_index.json\", \"w\") as f:\n","        json.dump(deliverable_bundle, f, indent=2)\n","\n","    # ========================================================================\n","    # 4) CREATE HUMAN-READABLE SUMMARY\n","    # ========================================================================\n","\n","    human_readable = f\"\"\"\n","DELIVERABLE BUNDLE: {case['case_name']}\n","{'=' * 70}\n","\n","INTAKE SUMMARY\n","--------------\n","Purpose: {case['purpose']}\n","Intended Reliance: {case['intended_reliance']}\n","Data Classification: {case['data_classification']}\n","Risk Tier: {controls_checklist['risk_tier']}\n","\n","SCOPE BOUNDARY\n","--------------\n","{case['scope_boundary']}\n","\n","STAGE A: INTAKE NARRATIVE\n","-------------------------\n","{stage_outputs['stage_A']['draft_output']}\n","\n","Open Questions (Stage A): {len(stage_outputs['stage_A'].get('open_questions', []))}\n","{chr(10).join('- ' + q for q in stage_outputs['stage_A'].get('open_questions', [])[:3])}\n","\n","STAGE B: DELIVERABLE DRAFT\n","--------------------------\n","{stage_outputs['stage_B']['draft_output'][:500]}...\n","[See full output in stage_B.json]\n","\n","Open Questions (Stage B): {len(stage_outputs['stage_B'].get('open_questions', []))}\n","Risks Identified: {len(stage_outputs['stage_B'].get('risks', []))}\n","\n","STAGE C: VERIFICATION PLAN\n","--------------------------\n","{stage_outputs['stage_C']['draft_output'][:500]}...\n","[See full output in stage_C.json]\n","\n","REQUIRED CONTROLS\n","-----------------\n","{chr(10).join('- ' + c for c in controls_checklist['required_controls'])}\n","\n","NEXT STEPS\n","----------\n","1. Review verification register for this case\n","2. Address open questions before using deliverables\n","3. Obtain required approvals (see approvals_log.json)\n","4. Complete QA review if selected for sampling\n","\n","VERIFICATION STATUS: Not verified\n","All outputs require human review before use.\n","\"\"\"\n","\n","    with open(run_dir / \"deliverables\" / f\"{case['case_name']}_human_readable.txt\", \"w\") as f:\n","        f.write(human_readable)\n","\n","    print(f\"   âœ“ Deliverable bundle created (5 artifacts)\")\n","\n","    # ========================================================================\n","    # 5) CREATE APPROVAL STUBS\n","    # ========================================================================\n","\n","    approver_role = \"Senior Consultant\" if controls_checklist['risk_tier'] == \"low\" else \"Partner\"\n","\n","    build_approval_stub(\n","        case_name=case['case_name'],\n","        artifact_name=f\"{case['case_name']}_bundle\",\n","        approver_role=approver_role,\n","        state=\"pending\"\n","    )\n","\n","    print(f\"   âœ“ Approval routing created (approver: {approver_role})\")\n","\n","    # ========================================================================\n","    # 6) COLLECT OUTPUTS FOR QA SAMPLING\n","    # ========================================================================\n","\n","    # Determine highest risk severity\n","    all_risks = (\n","        stage_outputs['stage_A'].get('risks', []) +\n","        stage_outputs['stage_B'].get('risks', []) +\n","        stage_outputs['stage_C'].get('risks', [])\n","    )\n","\n","    highest_severity = \"low\"\n","    if any(r.get('severity') == 'high' for r in all_risks):\n","        highest_severity = \"high\"\n","    elif any(r.get('severity') == 'medium' for r in all_risks):\n","        highest_severity = \"medium\"\n","\n","    case_outputs_for_qa.append({\n","        \"case_name\": case['case_name'],\n","        \"artifact_name\": f\"{case['case_name']}_stage_B\",\n","        \"risk_level\": highest_severity,\n","        \"stage_name\": \"stage_B\"\n","    })\n","\n","    # Aggregate results for summary table\n","    total_open_questions = (\n","        len(stage_outputs['stage_A'].get('open_questions', [])) +\n","        len(stage_outputs['stage_B'].get('open_questions', [])) +\n","        len(stage_outputs['stage_C'].get('open_questions', []))\n","    )\n","\n","    case_results.append({\n","        \"case_name\": case['case_name'],\n","        \"open_questions_total\": total_open_questions,\n","        \"highest_risk_severity\": highest_severity,\n","        \"artifacts_count\": 5,\n","        \"risk_tier\": controls_checklist['risk_tier']\n","    })\n","\n","# ============================================================================\n","# 7) QA SAMPLING\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"QA SAMPLING SELECTION\")\n","print(\"=\" * 70)\n","\n","# Load sampling plan\n","with open(run_dir / \"qa_sampling_plan.json\", \"r\") as f:\n","    sampling_plan = json.load(f)\n","\n","# Select samples\n","selected_samples = qa_sample_selector(case_outputs_for_qa, sampling_plan)\n","\n","print(f\"\\nSelected {len(selected_samples)} samples for QA review:\")\n","\n","samples_with_checklists = []\n","for sample in selected_samples:\n","    checklist = qa_reviewer_checklist(sample)\n","    samples_with_checklists.append(checklist)\n","    print(f\"   - {sample['case_name']} ({sample['sample_reason']})\")\n","\n","# Update QA results\n","update_qa_results(samples_with_checklists)\n","\n","print(f\"\\nâœ“ QA results updated (status: pending human review)\")\n","\n","# ============================================================================\n","# 8) SUMMARY TABLE\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"EXECUTION SUMMARY\")\n","print(\"=\" * 70)\n","print(f\"\\n{'Case Name':<40} {'Open Qs':<10} {'Risk':<8} {'QA?':<6} {'Artifacts':<10}\")\n","print(\"-\" * 70)\n","\n","for result in case_results:\n","    qa_selected = \"Yes\" if any(s['case_name'] == result['case_name'] for s in selected_samples) else \"No\"\n","    print(f\"{result['case_name']:<40} {result['open_questions_total']:<10} {result['highest_risk_severity']:<8} {qa_selected:<6} {result['artifacts_count']:<10}\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(f\"âœ“ All 4 mini-cases completed\")\n","print(f\"âœ“ Total artifacts created: {sum(r['artifacts_count'] for r in case_results)}\")\n","print(f\"âœ“ QA samples selected: {len(selected_samples)}\")\n","print(f\"âœ“ Approvals pending: {len(case_results)}\")\n","print(f\"\\nNext: Run Cell 9 to design your own workflow\")\n","print(\"=\" * 70)"],"metadata":{"id":"GF7UbU5xNTWW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768931273633,"user_tz":360,"elapsed":325400,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"921ea89f-17fb-470b-bff0-464e024d0eae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","RUNNING 4 MINI-CASE DEMOS (MINI-FIRM PIPELINE)\n","======================================================================\n","\n","[1/4] Case: market_entry_apac\n","      Purpose: Standardized client update memo for APAC market entry evalua...\n","      Data Classification: internal\n","   âœ“ Intake + Controls (risk tier: low)\n","\n","   Running controlled drafting for: market_entry_apac\n","   â”œâ”€â”€ Stage A: Intake narrative...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (3642 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage A complete (6 open questions)\n","   â”œâ”€â”€ Stage B: Deliverable draft...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (9986 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage B complete (7 risks identified)\n","   â””â”€â”€ Stage C: Verification plan...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (10106 chars)\n","   âœ“ Validation complete\n","       âœ“ Stage C complete\n","   âœ“ Deliverable bundle created (5 artifacts)\n","   âœ“ Approval routing created (approver: Senior Consultant)\n","\n","[2/4] Case: cost_transformation_manufacturing\n","      Purpose: Standardized workplan and weekly update drafting for cost tr...\n","      Data Classification: confidential\n","   âœ“ Intake + Controls (risk tier: medium)\n","\n","   Running controlled drafting for: cost_transformation_manufacturing\n","   â”œâ”€â”€ Stage A: Intake narrative...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (4508 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage A complete (6 open questions)\n","   â”œâ”€â”€ Stage B: Deliverable draft...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (13972 chars)\n","   â†’ Making API call (attempt 2/3)...\n","   âœ“ Received response (15060 chars)\n","   â†’ Making API call (attempt 3/3)...\n","   âœ“ Received response (12885 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage B complete (6 risks identified)\n","   â””â”€â”€ Stage C: Verification plan...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (11342 chars)\n","   âœ“ Validation complete\n","       âœ“ Stage C complete\n","   âœ“ Deliverable bundle created (5 artifacts)\n","   âœ“ Approval routing created (approver: Partner)\n","\n","[3/4] Case: capital_allocation_portfolio\n","      Purpose: Investment committee pre-read shell with scenario framing (s...\n","      Data Classification: confidential\n","   âœ“ Intake + Controls (risk tier: medium)\n","\n","   Running controlled drafting for: capital_allocation_portfolio\n","   â”œâ”€â”€ Stage A: Intake narrative...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (4302 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage A complete (8 open questions)\n","   â”œâ”€â”€ Stage B: Deliverable draft...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (12502 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage B complete (8 risks identified)\n","   â””â”€â”€ Stage C: Verification plan...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (12263 chars)\n","   âœ“ Validation complete\n","       âœ“ Stage C complete\n","   âœ“ Deliverable bundle created (5 artifacts)\n","   âœ“ Approval routing created (approver: Partner)\n","\n","[4/4] Case: operating_model_redesign_finance\n","      Purpose: RACI matrix and operating cadence documentation for finance ...\n","      Data Classification: internal\n","   âœ“ Intake + Controls (risk tier: low)\n","\n","   Running controlled drafting for: operating_model_redesign_finance\n","   â”œâ”€â”€ Stage A: Intake narrative...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (4352 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage A complete (7 open questions)\n","   â”œâ”€â”€ Stage B: Deliverable draft...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (15047 chars)\n","   â†’ Making API call (attempt 2/3)...\n","   âœ“ Received response (14871 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage B complete (6 risks identified)\n","   â””â”€â”€ Stage C: Verification plan...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (15521 chars)\n","   âœ“ Validation complete\n","       âœ“ Stage C complete\n","   âœ“ Deliverable bundle created (5 artifacts)\n","   âœ“ Approval routing created (approver: Senior Consultant)\n","\n","======================================================================\n","QA SAMPLING SELECTION\n","======================================================================\n","\n","Selected 4 samples for QA review:\n","   - market_entry_apac (high_risk)\n","   - cost_transformation_manufacturing (high_risk)\n","   - capital_allocation_portfolio (high_risk)\n","   - operating_model_redesign_finance (high_risk)\n","\n","âœ“ QA results updated (status: pending human review)\n","\n","======================================================================\n","EXECUTION SUMMARY\n","======================================================================\n","\n","Case Name                                Open Qs    Risk     QA?    Artifacts \n","----------------------------------------------------------------------\n","market_entry_apac                        25         high     Yes    5         \n","cost_transformation_manufacturing        28         high     Yes    5         \n","capital_allocation_portfolio             34         high     Yes    5         \n","operating_model_redesign_finance         34         high     Yes    5         \n","\n","======================================================================\n","âœ“ All 4 mini-cases completed\n","âœ“ Total artifacts created: 20\n","âœ“ QA samples selected: 4\n","âœ“ Approvals pending: 4\n","\n","Next: Run Cell 9 to design your own workflow\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##9.USER'S EXAMPLE"],"metadata":{"id":"3juVsof2NUJC"}},{"cell_type":"markdown","source":["###9.1.OVERVIEW"],"metadata":{"id":"0A7X8eAeNVjp"}},{"cell_type":"markdown","source":["####9.1.1.GENERAL DESCRIPTION"],"metadata":{"id":"zMlyX6C-kWWs"}},{"cell_type":"markdown","source":["\n","\n","Cell 9 transforms you from observer to participant. Everything you've watched\n","happen to the four mini-cases in Cell 8 - the intake processing, control\n","assignment, AI drafting with validation, verification extraction, approval routing,\n","QA sampling - now happens to your case, with your facts, following your decisions\n","about classification and scope. This is where the notebook stops being a\n","demonstration and becomes your personal training ground for Level 5 governance.\n","\n","The cell opens with a critical warning displayed prominently: do NOT paste\n","client-confidential data into this notebook. This isn't legal boilerplate or\n","overcautious advice. It's the foundational principle of responsible AI deployment\n","in professional services. Even though Cell 5's redaction will catch personal\n","information automatically, the first line of defense is human judgment about what\n","enters the system at all. You're learning organizational discipline: the system\n","has technical safeguards, but humans make the initial call about appropriate use.\n","\n","When you run Cell 9, it prompts you for information step by step, like a careful\n","intake interview. First comes case name - your identifier like \"supply_chain_optimization\"\n","or \"digital_transformation_retail.\" Then purpose: what are you trying to accomplish?\n","This forces you to articulate the client need clearly. Then intended reliance: how\n","will outputs actually be used? This question makes you think about stakes and\n","consequences. Board presentation for budget approval carries different weight than\n","internal discussion materials.\n","\n","The data classification question is where organizational governance becomes tangible.\n","You choose public, internal, confidential, or restricted. Watch what happens when\n","you type \"confidential\" - the system doesn't ask your opinion about what controls\n","to apply. It reads firm policy from Cell 4, executes the mapping logic from Cell 7,\n","and automatically assigns medium risk tier with seven required controls: Partner\n","approval mandatory, QA sampling required, numeric claims must be verified. You\n","didn't decide this; organizational policy decided and code enforced it.\n","\n","Scope boundary comes next, and this teaches a crucial consulting discipline:\n","explicitly stating what's in scope versus out of scope. \"In scope: technology\n","stack assessment, timeline. Out of scope: vendor selection, cost estimates.\" This\n","boundary setting guides AI drafting, creates accountability, and prevents scope\n","creep. If someone later asks why you didn't address vendor selection, your intake\n","record shows it was explicitly excluded.\n","\n","Then comes facts collection - one fact per line, Enter twice when done. This\n","seems tedious but it teaches you to separate facts from assumptions, opinions, and\n","speculation. \"Regional retail chain with 45 stores\" is a fact. \"They probably\n","need cloud migration\" is not a fact, it's an assumption or judgment. The discipline\n","of listing only what you actually know forces clarity that improves AI output\n","quality and reduces hallucination risk.\n","\n","Watch what happens immediately after you finish input: confidentiality processing\n","executes automatically. The system scans everything you typed for PII patterns.\n","Email addresses become [EMAIL_REDACTED]. Phone numbers become [PHONE_REDACTED].\n","Proper names become [NAME_REDACTED]. The system then shows you what was removed:\n","\"Removed fields: emails, phone_numbers, proper_names.\" This redaction happened\n","before anything touched the AI model. The raw text never reaches the API; only\n","the sanitized version does.\n","\n","Now you watch the exact same workflow the mini-cases followed execute for your\n","case. Build_intake_record creates your official intake document with unique ID.\n","Build_controls_checklist reads your \"confidential\" classification and assigns\n","medium risk tier. You see \"Risk tier: medium\" and \"Required controls: 7\" printed.\n","The system then launches controlled drafting - Stage A for intake narrative,\n","Stage B for deliverable template, Stage C for verification plan.\n","\n","For each stage you see the AI interaction in real time. \"Making API call (attempt 1/3)...\"\n","means the wrapper from Cell 6 is calling Claude. \"Received response (X chars)\"\n","confirms the AI replied. \"Validation complete\" means parsing succeeded, schema\n","matched, and policies were satisfied. If validation had failed, you'd see retry\n","messages explaining what went wrong and how the system is attempting to fix it.\n","\n","After drafting completes, the deliverable bundle gets created - bundle index with\n","cryptographic hashes, human-readable summary you can actually read, metadata\n","linking everything together. Five files appear in your case directory. Then\n","approval routing: the system reads risk tier (medium) and applies the routing\n","rule deterministically - Partner approval required. You see \"Approver Role: Partner,\n","Status: pending, Approval ID: [unique hash].\"\n","\n","The QA sampling decision executes next, and here you see conditional logic in\n","action. The system aggregates every risk the AI identified across your three\n","stages, finds the highest severity, and applies the sampling rule. If any risk\n","was marked high severity - maybe the AI noted \"significant information gaps\" or\n","\"unverified technical assumptions\" - your case automatically gets selected for QA\n","review. You see either \"Selected for QA review (reason: high_risk)\" or \"Not\n","selected (risk level: medium).\"\n","\n","The cell concludes with your personal summary showing exactly what happened: case\n","name, risk tier, total open questions across all stages, highest risk severity\n","detected, whether redaction was applied, approval status, and where your files\n","are saved. This summary tells you immediately: how much verification work awaits\n","you, whether your case triggered quality concerns, what level of approval is\n","required.\n","\n","But the most important output is the explicit reminder at the end: \"All outputs\n","are DRAFTS with verification_status = 'Not verified.' Human review is REQUIRED\n","before use. Approval is PENDING. Consultant owns final judgment and decisions.\"\n","This is Level 5 philosophy crystallized in a warning message. The AI drafted\n","content, the code enforced governance, but you the human consultant still own the\n","work. The system moved things forward efficiently and consistently, but it didn't\n","replace professional judgment.\n","\n","What makes Cell 9 powerful as learning is that you're experiencing real AI, real\n","governance controls, and real organizational processes - but in a safe environment.\n","You're not practicing on client work. You're not bypassing controls because \"it's\n","just practice.\" You're going through exactly what a consultant in a Level 5\n","organization experiences: structured intake, automatic control assignment,\n","AI-assisted drafting with validation, systematic gap identification, rule-based\n","routing, complete audit trails.\n","\n","The exercise also teaches through feedback. If you provided vague facts, the AI\n","drafts vague narratives and flags the vagueness as a gap. If you provided specific\n","facts, the AI produces more useful content and identifies more targeted gaps. The\n","quality of your inputs directly affects output quality, but the governance controls\n","remain constant regardless.\n","\n","By Cell 9's end, you have your own complete case in the system with full governance\n","trail. You can examine files in deliverables and stage_outputs directories. You\n","can see your case in verification_register, approvals_log, potentially qa_results.\n","You've experienced the organizational system from inside as a participant, not\n","just an observer watching demonstrations run."],"metadata":{"id":"7SgqchOZNupJ"}},{"cell_type":"markdown","source":["####9.1.2.PROMPT HELP"],"metadata":{"id":"jwSFwVPtkb5a"}},{"cell_type":"markdown","source":["Case name: digital_transformation_retail\n","\n","Purpose: Evaluate digital transformation roadmap for regional retail chain transitioning to omnichannel model\n","\n","Intended reliance: Board presentation and investment committee review for technology budget approval\n","\n","Data classification: confidential\n","\n","Scope boundary: In scope: technology stack assessment, phased implementation timeline, high-level capability gaps. Out of scope: vendor selection, detailed cost estimates, customer data migration strategy\n","\n","Fact: Regional retail chain with 45 stores across three states\n","Fact: Current point-of-sale systems are 12 years old and not cloud-compatible\n","Fact: E-commerce platform launched 18 months ago but not integrated with inventory systems\n","Fact: Board has allocated initial budget for assessment phase\n","Fact: Competition from online retailers increasing market pressure\n","Fact: Customer data currently siloed across three legacy systems\n","Fact: IT team consists of 8 full-time employees\n","Fact: Implementation timeline target is 24 months\n","Fact:"],"metadata":{"id":"fongbwHYzPkX"}},{"cell_type":"markdown","source":["###9.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"q65FZs56NXZp"}},{"cell_type":"code","source":["# Cell 9: User Exercise (Design Your Firm Workflow Safely)\n","\n","print(\"=\" * 70)\n","print(\"USER EXERCISE: DESIGN YOUR OWN WORKFLOW\")\n","print(\"=\" * 70)\n","print(\"\\nThis exercise lets you define a custom workflow and run it through\")\n","print(\"the same Level 5 governance controls as the mini-cases.\")\n","print(\"\\nâš ï¸  REMINDER: Do NOT paste client-confidential data into this notebook\")\n","print(\"=\" * 70)\n","\n","# ============================================================================\n","# USER INPUT COLLECTION\n","# ============================================================================\n","\n","print(\"\\nðŸ“ Please provide the following information:\\n\")\n","\n","user_case_name = input(\"Case name (e.g., 'supply_chain_optimization'): \").strip()\n","if not user_case_name:\n","    user_case_name = \"user_custom_case\"\n","\n","user_purpose = input(\"\\nPurpose of this work (what are you trying to accomplish?): \").strip()\n","if not user_purpose:\n","    user_purpose = \"Custom workflow design exercise\"\n","\n","user_intended_reliance = input(\"\\nIntended reliance (how will outputs be used?): \").strip()\n","if not user_intended_reliance:\n","    user_intended_reliance = \"Internal analysis and discussion\"\n","\n","user_data_classification = input(\"\\nData classification (public/internal/confidential/restricted): \").strip().lower()\n","if user_data_classification not in [\"public\", \"internal\", \"confidential\", \"restricted\"]:\n","    print(f\"   âš ï¸  Invalid classification, defaulting to 'internal'\")\n","    user_data_classification = \"internal\"\n","\n","user_scope_boundary = input(\"\\nScope boundary (what's in scope vs out of scope?): \").strip()\n","if not user_scope_boundary:\n","    user_scope_boundary = \"In scope: workflow design. Out of scope: specific recommendations\"\n","\n","print(\"\\nðŸ“„ Please provide facts about your case (one per line, press Enter twice when done):\")\n","print(\"   Example: 'Client operates in healthcare sector'\")\n","print(\"   Example: 'Project timeline is 3 months'\\n\")\n","\n","user_facts_raw = []\n","while True:\n","    fact = input(\"   Fact: \").strip()\n","    if not fact:\n","        break\n","    user_facts_raw.append(fact)\n","\n","if not user_facts_raw:\n","    user_facts_raw = [\"User-defined workflow exercise\", \"No specific facts provided\"]\n","\n","# ============================================================================\n","# CONFIDENTIALITY: REDACTION + MINIMUM NECESSARY\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CONFIDENTIALITY PROCESSING\")\n","print(\"=\" * 70)\n","\n","# Combine all user input for redaction\n","user_input_combined = f\"{user_purpose} {user_intended_reliance} {user_scope_boundary} \" + \" \".join(user_facts_raw)\n","\n","# Apply redaction\n","redaction_result = build_minimum_necessary(user_input_combined)\n","\n","# Redact individual facts\n","user_facts_sanitized = [redact(fact) for fact in user_facts_raw]\n","\n","print(f\"\\nðŸ”’ Redaction Summary:\")\n","if redaction_result['removed_fields']:\n","    print(f\"   Removed fields: {', '.join(redaction_result['removed_fields'])}\")\n","    print(f\"\\n   âš ï¸  The following PII types were detected and redacted:\")\n","    for field in redaction_result['removed_fields']:\n","        print(f\"      - {field}\")\n","else:\n","    print(f\"   âœ“ No PII detected\")\n","\n","print(f\"\\n   Preview of sanitized input (first 200 chars):\")\n","print(f\"   {redaction_result['redacted_preview']}\")\n","\n","# ============================================================================\n","# BUILD INTAKE + CONTROLS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"INTAKE + CONTROLS\")\n","print(\"=\" * 70)\n","\n","user_intake_record = build_intake_record(\n","    case_name=user_case_name,\n","    purpose=redact(user_purpose),\n","    intended_reliance=redact(user_intended_reliance),\n","    data_classification=user_data_classification,\n","    scope_boundary=redact(user_scope_boundary)\n",")\n","\n","user_controls_checklist = build_controls_checklist(user_intake_record)\n","\n","print(f\"\\nâœ“ Intake record created (ID: {user_intake_record['intake_id']})\")\n","print(f\"âœ“ Risk tier: {user_controls_checklist['risk_tier']}\")\n","print(f\"âœ“ Required controls: {len(user_controls_checklist['required_controls'])}\")\n","\n","# ============================================================================\n","# RUN CONTROLLED DRAFTING WORKFLOW (STAGES A-C)\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"CONTROLLED DRAFTING WORKFLOW\")\n","print(\"=\" * 70)\n","\n","user_stage_outputs = run_controlled_drafting(\n","    case_name=user_case_name,\n","    facts_provided=user_facts_sanitized,\n","    scope_boundary=redact(user_scope_boundary),\n","    purpose=redact(user_purpose)\n",")\n","\n","# ============================================================================\n","# CREATE USER DELIVERABLE BUNDLE\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"DELIVERABLE BUNDLE CREATION\")\n","print(\"=\" * 70)\n","\n","user_deliverable_bundle = {\n","    \"case_name\": user_case_name,\n","    \"intake_id\": user_intake_record['intake_id'],\n","    \"risk_tier\": user_controls_checklist['risk_tier'],\n","    \"artifacts\": [\n","        {\"name\": \"intake_record.json\", \"hash\": hashlib.sha256(json.dumps(user_intake_record).encode()).hexdigest()[:16]},\n","        {\"name\": \"controls_checklist.json\", \"hash\": hashlib.sha256(json.dumps(user_controls_checklist).encode()).hexdigest()[:16]},\n","        {\"name\": \"stage_A.json\", \"hash\": hashlib.sha256(json.dumps(user_stage_outputs['stage_A']).encode()).hexdigest()[:16]},\n","        {\"name\": \"stage_B.json\", \"hash\": hashlib.sha256(json.dumps(user_stage_outputs['stage_B']).encode()).hexdigest()[:16]},\n","        {\"name\": \"stage_C.json\", \"hash\": hashlib.sha256(json.dumps(user_stage_outputs['stage_C']).encode()).hexdigest()[:16]}\n","    ],\n","    \"created_timestamp\": datetime.datetime.now().isoformat(),\n","    \"redaction_applied\": len(redaction_result['removed_fields']) > 0,\n","    \"removed_fields_summary\": redaction_result['removed_fields']\n","}\n","\n","# Save bundle index\n","with open(run_dir / \"deliverables\" / f\"{user_case_name}_bundle_index.json\", \"w\") as f:\n","    json.dump(user_deliverable_bundle, f, indent=2)\n","\n","# ============================================================================\n","# CREATE HUMAN-READABLE SUMMARY\n","# ============================================================================\n","\n","user_human_readable = f\"\"\"\n","USER-DEFINED WORKFLOW: {user_case_name}\n","{'=' * 70}\n","\n","INTAKE SUMMARY\n","--------------\n","Purpose: {redact(user_purpose)}\n","Intended Reliance: {redact(user_intended_reliance)}\n","Data Classification: {user_data_classification}\n","Risk Tier: {user_controls_checklist['risk_tier']}\n","\n","REDACTION SUMMARY\n","-----------------\n","Fields Removed: {', '.join(redaction_result['removed_fields']) if redaction_result['removed_fields'] else 'None'}\n","\n","SCOPE BOUNDARY\n","--------------\n","{redact(user_scope_boundary)}\n","\n","STAGE A: INTAKE NARRATIVE\n","-------------------------\n","{user_stage_outputs['stage_A']['draft_output']}\n","\n","Open Questions (Stage A): {len(user_stage_outputs['stage_A'].get('open_questions', []))}\n","{chr(10).join('- ' + q for q in user_stage_outputs['stage_A'].get('open_questions', []))}\n","\n","STAGE B: DELIVERABLE DRAFT\n","--------------------------\n","{user_stage_outputs['stage_B']['draft_output'][:500]}...\n","[See full output in stage_B.json]\n","\n","Open Questions (Stage B): {len(user_stage_outputs['stage_B'].get('open_questions', []))}\n","Risks Identified: {len(user_stage_outputs['stage_B'].get('risks', []))}\n","\n","STAGE C: VERIFICATION PLAN\n","--------------------------\n","{user_stage_outputs['stage_C']['draft_output'][:500]}...\n","[See full output in stage_C.json]\n","\n","REQUIRED CONTROLS\n","-----------------\n","{chr(10).join('- ' + c for c in user_controls_checklist['required_controls'])}\n","\n","NEXT STEPS\n","----------\n","1. Review verification register for this case\n","2. Address open questions before using deliverables\n","3. Obtain required approvals (see approvals_log.json)\n","4. Complete QA review if selected for sampling\n","\n","âš ï¸  CRITICAL REMINDERS\n","----------------------\n","- All outputs have verification_status = \"Not verified\"\n","- Human review is REQUIRED before any use\n","- Approval routing is PENDING (see approvals_log.json)\n","- This is a DRAFT; consultant owns final judgment\n","\n","VERIFICATION STATUS: Not verified\n","All outputs require human review before use.\n","\"\"\"\n","\n","with open(run_dir / \"deliverables\" / f\"{user_case_name}_human_readable.txt\", \"w\") as f:\n","    f.write(user_human_readable)\n","\n","print(f\"\\nâœ“ Deliverable bundle saved:\")\n","print(f\"   - {user_case_name}_bundle_index.json\")\n","print(f\"   - {user_case_name}_human_readable.txt\")\n","print(f\"   - stage_outputs/{user_case_name}/ (5 files)\")\n","\n","# ============================================================================\n","# CREATE APPROVAL ROUTING\n","# ============================================================================\n","\n","approver_role = \"Senior Consultant\" if user_controls_checklist['risk_tier'] == \"low\" else \"Partner\"\n","\n","user_approval = build_approval_stub(\n","    case_name=user_case_name,\n","    artifact_name=f\"{user_case_name}_bundle\",\n","    approver_role=approver_role,\n","    state=\"pending\"\n",")\n","\n","print(f\"\\nâœ“ Approval routing created:\")\n","print(f\"   Approver Role: {approver_role}\")\n","print(f\"   Status: pending\")\n","print(f\"   Approval ID: {user_approval['approval_id']}\")\n","\n","# ============================================================================\n","# QA SAMPLE SELECTION (if applicable)\n","# ============================================================================\n","\n","# Determine if this should be QA sampled\n","user_all_risks = (\n","    user_stage_outputs['stage_A'].get('risks', []) +\n","    user_stage_outputs['stage_B'].get('risks', []) +\n","    user_stage_outputs['stage_C'].get('risks', [])\n",")\n","\n","user_highest_severity = \"low\"\n","if any(r.get('severity') == 'high' for r in user_all_risks):\n","    user_highest_severity = \"high\"\n","elif any(r.get('severity') == 'medium' for r in user_all_risks):\n","    user_highest_severity = \"medium\"\n","\n","# Add to QA sampling if high risk\n","if user_highest_severity == \"high\":\n","    # FIX: Create complete sample dict with all required fields\n","    user_qa_sample = {\n","        \"case_name\": user_case_name,\n","        \"artifact_name\": f\"{user_case_name}_stage_B\",\n","        \"risk_level\": user_highest_severity,\n","        \"stage_name\": \"stage_B\",\n","        \"sample_reason\": \"high_risk\"  # FIX: Added missing field\n","    }\n","\n","    user_qa_checklist = qa_reviewer_checklist(user_qa_sample)\n","    update_qa_results([user_qa_checklist])\n","\n","    print(f\"\\nâœ“ QA sampling:\")\n","    print(f\"   Selected for QA review (reason: high risk detected)\")\n","else:\n","    print(f\"\\nâœ“ QA sampling:\")\n","    print(f\"   Not selected (risk level: {user_highest_severity})\")\n","\n","# ============================================================================\n","# FINAL SUMMARY\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"USER EXERCISE COMPLETE\")\n","print(\"=\" * 70)\n","\n","total_open_questions = (\n","    len(user_stage_outputs['stage_A'].get('open_questions', [])) +\n","    len(user_stage_outputs['stage_B'].get('open_questions', [])) +\n","    len(user_stage_outputs['stage_C'].get('open_questions', []))\n",")\n","\n","print(f\"\\nðŸ“Š Summary:\")\n","print(f\"   Case Name: {user_case_name}\")\n","print(f\"   Risk Tier: {user_controls_checklist['risk_tier']}\")\n","print(f\"   Total Open Questions: {total_open_questions}\")\n","print(f\"   Highest Risk Severity: {user_highest_severity}\")\n","print(f\"   Artifacts Created: 5\")\n","print(f\"   Redaction Applied: {'Yes' if redaction_result['removed_fields'] else 'No'}\")\n","print(f\"   Approval Status: Pending ({approver_role})\")\n","\n","print(f\"\\nðŸ“ Your outputs are saved in:\")\n","print(f\"   {run_dir / 'deliverables' / user_case_name}_*\")\n","print(f\"   {run_dir / 'stage_outputs' / user_case_name}/\")\n","\n","print(f\"\\nâš ï¸  REMINDER:\")\n","print(f\"   - All outputs are DRAFTS with verification_status = 'Not verified'\")\n","print(f\"   - Human review is REQUIRED before use\")\n","print(f\"   - Approval is PENDING - see approvals_log.json\")\n","print(f\"   - Consultant owns final judgment and decisions\")\n","\n","print(f\"\\nâœ“ Next: Run Cell 10 to create the final audit bundle\")\n","print(\"=\" * 70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X264V5uGzG18","executionInfo":{"status":"ok","timestamp":1768936208219,"user_tz":360,"elapsed":216107,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"a0fe70e6-5e66-43b3-c14e-7993b20ec047"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","USER EXERCISE: DESIGN YOUR OWN WORKFLOW\n","======================================================================\n","\n","This exercise lets you define a custom workflow and run it through\n","the same Level 5 governance controls as the mini-cases.\n","\n","âš ï¸  REMINDER: Do NOT paste client-confidential data into this notebook\n","======================================================================\n","\n","ðŸ“ Please provide the following information:\n","\n","Case name (e.g., 'supply_chain_optimization'): digital_transformation_retail\n","\n","Purpose of this work (what are you trying to accomplish?): Evaluate digital transformation roadmap for regional retail chain transitioning to omnichannel model\n","\n","Intended reliance (how will outputs be used?): Board presentation and investment committee review for technology budget approval\n","\n","Data classification (public/internal/confidential/restricted): confidential\n","\n","Scope boundary (what's in scope vs out of scope?): In scope: technology stack assessment, phased implementation timeline, high-level capability gaps. Out of scope: vendor selection, detailed cost estimates, customer data migration strategy\n","\n","ðŸ“„ Please provide facts about your case (one per line, press Enter twice when done):\n","   Example: 'Client operates in healthcare sector'\n","   Example: 'Project timeline is 3 months'\n","\n","   Fact: \n","\n","======================================================================\n","CONFIDENTIALITY PROCESSING\n","======================================================================\n","\n","ðŸ”’ Redaction Summary:\n","   âœ“ No PII detected\n","\n","   Preview of sanitized input (first 200 chars):\n","   Evaluate digital transformation roadmap for regional retail chain transitioning to omnichannel model Board presentation and investment committee review for technology budget approval In scope: technol...\n","\n","======================================================================\n","INTAKE + CONTROLS\n","======================================================================\n","\n","âœ“ Intake record created (ID: ebfd67be0f01)\n","âœ“ Risk tier: medium\n","âœ“ Required controls: 7\n","\n","======================================================================\n","CONTROLLED DRAFTING WORKFLOW\n","======================================================================\n","\n","   Running controlled drafting for: digital_transformation_retail\n","   â”œâ”€â”€ Stage A: Intake narrative...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (4158 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage A complete (8 open questions)\n","   â”œâ”€â”€ Stage B: Deliverable draft...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (11480 chars)\n","   â†’ Making API call (attempt 2/3)...\n","   âœ“ Received response (11399 chars)\n","   âœ“ Validation complete\n","   â”‚   âœ“ Stage B complete (6 risks identified)\n","   â””â”€â”€ Stage C: Verification plan...\n","   â†’ Making API call (attempt 1/3)...\n","   âœ“ Received response (11225 chars)\n","   â†’ Making API call (attempt 2/3)...\n","   âœ“ Received response (5385 chars)\n","   âœ“ Validation complete\n","       âœ“ Stage C complete\n","\n","======================================================================\n","DELIVERABLE BUNDLE CREATION\n","======================================================================\n","\n","âœ“ Deliverable bundle saved:\n","   - digital_transformation_retail_bundle_index.json\n","   - digital_transformation_retail_human_readable.txt\n","   - stage_outputs/digital_transformation_retail/ (5 files)\n","\n","âœ“ Approval routing created:\n","   Approver Role: Partner\n","   Status: pending\n","   Approval ID: e3ef3ec08206\n","\n","âœ“ QA sampling:\n","   Selected for QA review (reason: high risk detected)\n","\n","======================================================================\n","USER EXERCISE COMPLETE\n","======================================================================\n","\n","ðŸ“Š Summary:\n","   Case Name: digital_transformation_retail\n","   Risk Tier: medium\n","   Total Open Questions: 30\n","   Highest Risk Severity: high\n","   Artifacts Created: 5\n","   Redaction Applied: No\n","   Approval Status: Pending (Partner)\n","\n","ðŸ“ Your outputs are saved in:\n","   /content/ai_consulting_ch5_runs/run_20260120_164244_582e182e/deliverables/digital_transformation_retail_*\n","   /content/ai_consulting_ch5_runs/run_20260120_164244_582e182e/stage_outputs/digital_transformation_retail/\n","\n","âš ï¸  REMINDER:\n","   - All outputs are DRAFTS with verification_status = 'Not verified'\n","   - Human review is REQUIRED before use\n","   - Approval is PENDING - see approvals_log.json\n","   - Consultant owns final judgment and decisions\n","\n","âœ“ Next: Run Cell 10 to create the final audit bundle\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##10.RECORD KEEPING AND AUDIT BUNDLE"],"metadata":{"id":"deALRI7DNc11"}},{"cell_type":"markdown","source":["###10.1.OVERVIEW"],"metadata":{"id":"hspK-tF8Nd9D"}},{"cell_type":"markdown","source":["\n","\n","Cell 10 is the final act of organizational accountability - taking everything that\n","happened during this run and packaging it into a complete, verifiable, permanent\n","record that could withstand regulatory scrutiny, client disputes, or institutional\n","knowledge transfer years from now. This cell transforms a working directory full\n","of JSON files and text outputs into an official organizational archive with\n","cryptographic integrity verification and comprehensive documentation.\n","\n","The cell begins by creating AUDIT_README.txt, which is far more than a simple\n","readme file. This is a comprehensive audit report running over two thousand words\n","that explains what this notebook does, why it exists, what artifacts it produces,\n","how to interpret them, and how to reproduce the entire run. Think of it as the\n","user manual for your organizational archive. If a regulator asks three years from\n","now \"show me your AI governance process,\" you hand them this README and they can\n","understand your complete approach without technical expertise.\n","\n","The README documents critical details: which AI model was used (Claude Sonnet 4.5),\n","what parameters governed it (temperature 0.2, max tokens 4128), what the config\n","hash was (the cryptographic fingerprint proving identical configuration throughout),\n","what cases were processed, what governance artifacts were created, and what each\n","artifact means. It explains that prompts_log.jsonl contains redacted logs using\n","hashes rather than full text to protect confidentiality. It explains that\n","verification_register.json lists what humans must verify before outputs can be\n","used. It explains that all outputs carry verification_status \"Not verified\"\n","because human review is mandatory.\n","\n","Next comes integrity verification through cryptographic hashing. The cell walks\n","through every file in your run directory - organizational policies, governance\n","logs, stage outputs, deliverable bundles, everything - and computes a SHA-256\n","hash for each. A hash is a unique fingerprint: change even one character in a\n","file and the hash changes completely. The cell creates integrity_summary.json\n","listing every file path with its corresponding hash. This enables tamper detection.\n","If someone claims a file has been altered, you can recompute the hash and compare\n","against the integrity summary. If hashes match, the file is unchanged. If they\n","differ, tampering occurred.\n","\n","This cryptographic integrity matters enormously for professional services. Imagine\n","a client dispute eighteen months from now claiming you made recommendations you\n","weren't authorized to make. You retrieve your archive, check the integrity hashes\n","to prove files weren't altered, open the human-readable summary showing your\n","deliverable was explicitly scoped as scenario framing with no recommendations,\n","check the incident log showing the policy scanner flagged zero recommendation\n","language violations, and check the approval log showing a Partner reviewed and\n","approved the neutral framing. The integrity hashes transform your archive from\n","\"we think this is what we did\" to \"we can prove this is what we did.\"\n","\n","Then comes ZIP bundle creation. The cell packages your entire run directory -\n","organizational policies, workflow runbooks, all logs, all stage outputs, all\n","deliverables, the audit README, the integrity summary, everything - into a single\n","compressed archive file named with your run identifier. This ZIP serves multiple\n","purposes. It's portable (you can download it and store it in your firm's document\n","management system). It's complete (everything needed to understand this run is in\n","one package). It's timestamped (the run name includes date and time). It's\n","versioned (each run gets a unique identifier so you can distinguish them).\n","\n","The cell then produces a bundle contents summary showing file counts by category:\n","how many policy files, how many log files, how many governance artifacts, how many\n","deliverables, how many stage outputs. This gives you an at-a-glance understanding\n","of archive completeness. A complete run should have two policy files, approximately\n","eight to ten governance logs, four to five deliverable bundles (depending on\n","whether you ran Cell 9), and twelve to twenty stage outputs.\n","\n","Next comes the audit bundle checklist - a point-by-point verification that every\n","required component exists. You see checkbox items: AUDIT_README.txt present,\n","integrity_summary.json present, run_manifest.json present, org_policy.json present,\n","prompts_log.jsonl present, stage_gate_log.jsonl present, verification_register\n","present, approvals_log present, and so on. Each item shows a checkmark if the file\n","exists. This checklist serves as a pre-archival quality gate - before you seal\n","the archive, verify everything required is actually there.\n","\n","The cell concludes with final statistics: ZIP bundle location (where to download\n","it), total file count, ZIP size in megabytes, and config hash. These statistics\n","provide metadata about your organizational output. A typical run with four\n","mini-cases plus one user case produces roughly thirty to forty files totaling\n","two to five megabytes compressed. The config hash appears again here as final\n","confirmation that all work used consistent AI configuration.\n","\n","But Cell 10's most important output is actually the mindset it reinforces. The\n","cell ends with explicit next steps for humans: download the ZIP, review the audit\n","README, check verification_register for pending verifications, review approvals_log\n","for pending approvals, complete QA reviews, address any incidents. And then the\n","critical reminder appears one final time: \"All outputs have verification_status =\n","'Not verified.' Human review is REQUIRED before any use. Consultant owns final\n","judgment and decisions.\"\n","\n","This reminder appearing at the very end, after all the sophisticated AI drafting\n","and automated governance, drives home the Level 5 philosophy. The system created\n","an impressive amount of content and governance documentation automatically. But\n","none of it is final. None of it is approved for client use. None of it substitutes\n","for human professional judgment. The AI drafted, the code enforced governance,\n","and now humans must review, verify, approve, and take ownership.\n","\n","Cell 10 represents organizational completeness. When this cell finishes, you don't\n","just have draft outputs scattered across a working directory. You have a complete\n","organizational archive with comprehensive documentation, cryptographic integrity\n","verification, systematic organization, and clear instructions for human review.\n","You have transformed AI-assisted work from ephemeral experimentation into\n","permanent institutional memory that meets professional standards for recordkeeping,\n","compliance, and knowledge transfer.\n","\n","If you implement Level 5 in your actual firm, Cell 10's archive pattern becomes\n","your standard operating procedure. Every consulting engagement produces a ZIP\n","bundle. Every bundle contains the same governance artifacts. Every bundle can be\n","retrieved years later and understood completely because the AUDIT_README explains\n","everything. This consistency enables organizational learning (analyzing verification\n","registers across cases to identify systematic gaps), compliance demonstration\n","(showing regulators your systematic governance), and knowledge transfer (new\n","consultants reading archived bundles to understand how engagements were scoped\n","and executed).\n","\n","Cell 10 is the organizational close - the final proof that Level 5 isn't about\n","having smarter AI or writing more code, but about designing systems where AI,\n","automation, and human judgment create complete, governed, auditable organizational\n","capability at scale."],"metadata":{"id":"QktoO36gNwPN"}},{"cell_type":"markdown","source":["###10.2.CODE AND IMPLEMENTATION"],"metadata":{"id":"-qPlPvQYNhIv"}},{"cell_type":"code","source":["# Cell 10: Recordkeeping - AUDIT_README + Zip + Integrity Summary\n","\n","import shutil\n","import subprocess\n","\n","print(\"=\" * 70)\n","print(\"FINAL RECORDKEEPING: AUDIT BUNDLE CREATION\")\n","print(\"=\" * 70)\n","\n","# ============================================================================\n","# CREATE AUDIT_README.txt\n","# ============================================================================\n","\n","print(\"\\nðŸ“„ Creating AUDIT_README.txt...\")\n","\n","audit_readme_content = f\"\"\"\n","{'=' * 70}\n","AUDIT README - LEVEL 5 (ORGANIZATIONS) GOVERNANCE RUN\n","{'=' * 70}\n","\n","RUN INFORMATION\n","---------------\n","Run Name: {run_name}\n","Run ID: {short_id}\n","Timestamp: {timestamp}\n","Model: {MODEL}\n","Config Hash: {config_hash}\n","\n","NOTEBOOK PURPOSE\n","----------------\n","This notebook demonstrates a Level 5 (Organizations) operating model for\n","AI-assisted consulting work. The focus is on organizational governance,\n","not individual productivity.\n","\n","Key characteristics:\n","- Firm-wide intake and controls (not ad-hoc)\n","- Systematic QA sampling (not individual judgment)\n","- Approval routing with role separation\n","- Complete audit trail for compliance\n","- All outputs flagged as \"Not verified\"\n","\n","GOVERNANCE ARTIFACTS INCLUDED\n","------------------------------\n","\n","**Organizational Policy & Workflow:**\n","1. org_policy.json - Firm policy (scope, prohibited uses, retention)\n","2. workflow_runbook.json - Lifecycle stages, gates, RACI\n","\n","**Base Artifacts:**\n","3. run_manifest.json - Run metadata and configuration\n","4. risk_log.json - Aggregated risks across all cases\n","5. verification_register.json - What needs human verification\n","6. change_log.json - Configuration or policy changes during run\n","7. approvals_log.json - Approval routing and status\n","\n","**Level 5 Organizational Artifacts:**\n","8. qa_sampling_plan.json - QA sampling strategy\n","9. qa_results.json - QA findings (pending human review)\n","10. incident_log.json - Policy violations, parse failures, high-risk outputs\n","11. exception_log.json - Operational exceptions (missing approvals, failures)\n","12. asset_registry.json - Templates and prompt packs used\n","13. logs/prompts_log.jsonl - REDACTED log of all model calls (hashes only)\n","14. logs/stage_gate_log.jsonl - Append-only log of stage gate decisions\n","\n","**Deliverables:**\n","15. deliverables/ - Final outputs per case (bundle indices + human-readable)\n","16. stage_outputs/ - Stage-by-stage outputs (stages A, B, C per case)\n","\n","CASES EXECUTED\n","--------------\n","This run includes 4 mini-case demos + optional user-defined case:\n","\n","1. market_entry_apac - Client update memo shell with verification gates\n","2. cost_transformation_manufacturing - Workplan + weekly updates with QA\n","3. capital_allocation_portfolio - IC pre-read shell (strict neutrality)\n","4. operating_model_redesign_finance - RACI + operating cadence pack\n","5. [user_case] - User-defined workflow (if Cell 9 was run)\n","\n","REPRODUCING THIS RUN\n","--------------------\n","To reproduce this run exactly:\n","\n","1. Model: {MODEL}\n","2. Parameters:\n","   - temperature: {PARAMS['temperature']}\n","   - max_tokens: {PARAMS['max_tokens']}\n","3. Config Hash: {config_hash}\n","4. Notebook Version: Chapter_5_Level_5_Organizations_v1.0\n","\n","The config hash is derived from model + parameters. If you use the same\n","model and parameters, you should get a matching config hash.\n","\n","INTERPRETING PROMPTS_LOG (REDACTED)\n","------------------------------------\n","The prompts_log.jsonl contains REDACTED logs of all model calls.\n","\n","What's stored:\n","- Timestamp of each call\n","- Task name and stage name\n","- Prompt hash (SHA256, first 16 chars)\n","- Response hash (SHA256, first 16 chars)\n","- Model and parameters used\n","- Parsing status (success/failure)\n","- Incidents (if any)\n","- Config hash for reproducibility\n","\n","What's NOT stored:\n","- Full text of prompts (redacted for confidentiality)\n","- Full text of responses (redacted for confidentiality)\n","\n","Why hashes? This allows audit trail without storing potentially confidential\n","content. If you need to verify a specific call, you can:\n","1. Re-run the same prompt\n","2. Hash the response\n","3. Compare with the stored hash\n","\n","VERIFICATION STATUS\n","-------------------\n","âš ï¸  CRITICAL: All outputs have verification_status = \"Not verified\"\n","\n","This means:\n","- Outputs are DRAFTS, not final deliverables\n","- Human review is REQUIRED before any use\n","- Open questions must be addressed\n","- Facts must be verified against source data\n","- Approvals must be obtained (see approvals_log.json)\n","\n","Human consultant owns final judgment and decisions.\n","\n","The AI assistant produces drafts; it does not make recommendations or\n","substitute for human professional judgment.\n","\n","APPROVAL WORKFLOW\n","-----------------\n","All deliverables require approval before release. See approvals_log.json\n","for current approval status and assigned approvers.\n","\n","Approval routing is based on risk tier:\n","- Low risk: Senior Consultant approval\n","- Medium/High risk: Partner approval\n","\n","QA SAMPLING\n","-----------\n","A subset of outputs are selected for QA review based on the sampling plan.\n","See qa_results.json for selected samples and review checklists.\n","\n","QA samples are selected based on:\n","- High-risk outputs (always sampled)\n","- Random selection from medium-risk outputs\n","- First deliverable from each case type (baseline)\n","\n","INCIDENT AND EXCEPTION HANDLING\n","--------------------------------\n","See incident_log.json for:\n","- Policy violations (e.g., recommendation language detected)\n","- Parse failures\n","- High-risk outputs flagged\n","\n","See exception_log.json for:\n","- Operational exceptions (missing approvals, failed validation)\n","- Remediation actions required\n","\n","FILE INTEGRITY\n","--------------\n","See integrity_summary.json for SHA256 hashes of all key artifacts.\n","This allows you to verify that files have not been tampered with.\n","\n","CONTACT\n","-------\n","For questions about this governance framework:\n","Alejandro Reynoso\n","Chief Scientist, DEFI CAPITAL RESEARCH\n","External Lecturer, Judge Business School Cambridge\n","\n","{'=' * 70}\n","END OF AUDIT README\n","{'=' * 70}\n","\"\"\"\n","\n","with open(run_dir / \"AUDIT_README.txt\", \"w\") as f:\n","    f.write(audit_readme_content)\n","\n","print(\"   âœ“ AUDIT_README.txt created\")\n","\n","# ============================================================================\n","# CREATE INTEGRITY_SUMMARY.json\n","# ============================================================================\n","\n","print(\"\\nðŸ” Creating integrity_summary.json...\")\n","\n","def compute_file_hash(filepath):\n","    \"\"\"Compute SHA256 hash of a file.\"\"\"\n","    sha256_hash = hashlib.sha256()\n","    try:\n","        with open(filepath, \"rb\") as f:\n","            for byte_block in iter(lambda: f.read(4096), b\"\"):\n","                sha256_hash.update(byte_block)\n","        return sha256_hash.hexdigest()\n","    except Exception as e:\n","        return f\"ERROR: {str(e)}\"\n","\n","# Collect all key files\n","key_files = [\n","    run_dir / \"AUDIT_README.txt\",\n","    run_dir / \"run_manifest.json\",\n","    run_dir / \"org_policy.json\",\n","    run_dir / \"workflow_runbook.json\",\n","    run_dir / \"risk_log.json\",\n","    run_dir / \"verification_register.json\",\n","    run_dir / \"change_log.json\",\n","    run_dir / \"approvals_log.json\",\n","    run_dir / \"qa_sampling_plan.json\",\n","    run_dir / \"qa_results.json\",\n","    run_dir / \"incident_log.json\",\n","    run_dir / \"exception_log.json\",\n","    run_dir / \"asset_registry.json\",\n","    run_dir / \"logs\" / \"prompts_log.jsonl\",\n","    run_dir / \"logs\" / \"stage_gate_log.jsonl\"\n","]\n","\n","# Add deliverables\n","deliverables_dir = run_dir / \"deliverables\"\n","if deliverables_dir.exists():\n","    for f in deliverables_dir.iterdir():\n","        if f.is_file():\n","            key_files.append(f)\n","\n","# Add stage outputs\n","stage_outputs_dir = run_dir / \"stage_outputs\"\n","if stage_outputs_dir.exists():\n","    for case_dir in stage_outputs_dir.iterdir():\n","        if case_dir.is_dir():\n","            for f in case_dir.iterdir():\n","                if f.is_file():\n","                    key_files.append(f)\n","\n","# Compute hashes\n","file_hashes = []\n","for filepath in key_files:\n","    if filepath.exists():\n","        relative_path = filepath.relative_to(run_dir)\n","        file_hash = compute_file_hash(filepath)\n","        file_hashes.append({\n","            \"file\": str(relative_path),\n","            \"sha256\": file_hash\n","        })\n","\n","integrity_summary = {\n","    \"run_name\": run_name,\n","    \"run_id\": short_id,\n","    \"timestamp\": timestamp,\n","    \"config_hash\": config_hash,\n","    \"total_files\": len(file_hashes),\n","    \"file_hashes\": file_hashes,\n","    \"integrity_check_timestamp\": datetime.datetime.now().isoformat()\n","}\n","\n","with open(run_dir / \"integrity_summary.json\", \"w\") as f:\n","    json.dump(integrity_summary, f, indent=2)\n","\n","print(f\"   âœ“ integrity_summary.json created ({len(file_hashes)} files hashed)\")\n","\n","# ============================================================================\n","# CREATE ZIP BUNDLE\n","# ============================================================================\n","\n","print(\"\\nðŸ“¦ Creating ZIP bundle...\")\n","\n","zip_filename = f\"{run_name}.zip\"\n","zip_path = base_dir / zip_filename\n","\n","# Use shutil to create zip\n","shutil.make_archive(\n","    base_name=str(base_dir / run_name),\n","    format='zip',\n","    root_dir=run_dir.parent,\n","    base_dir=run_dir.name\n",")\n","\n","print(f\"   âœ“ ZIP bundle created: {zip_path}\")\n","\n","# ============================================================================\n","# LIST BUNDLE CONTENTS\n","# ============================================================================\n","\n","print(\"\\nðŸ“‹ Bundle Contents:\")\n","print(\"-\" * 70)\n","\n","# Count files by type\n","total_files = 0\n","file_counts = {\n","    \"Policy & Workflow\": 0,\n","    \"Logs\": 0,\n","    \"Governance Artifacts\": 0,\n","    \"Deliverables\": 0,\n","    \"Stage Outputs\": 0,\n","    \"Other\": 0\n","}\n","\n","for root, dirs, files in os.walk(run_dir):\n","    for file in files:\n","        total_files += 1\n","        rel_path = Path(root).relative_to(run_dir)\n","\n","        if file in [\"org_policy.json\", \"workflow_runbook.json\"]:\n","            file_counts[\"Policy & Workflow\"] += 1\n","        elif \"logs\" in str(rel_path):\n","            file_counts[\"Logs\"] += 1\n","        elif file in [\"risk_log.json\", \"verification_register.json\", \"approvals_log.json\",\n","                      \"qa_results.json\", \"incident_log.json\", \"exception_log.json\"]:\n","            file_counts[\"Governance Artifacts\"] += 1\n","        elif \"deliverables\" in str(rel_path):\n","            file_counts[\"Deliverables\"] += 1\n","        elif \"stage_outputs\" in str(rel_path):\n","            file_counts[\"Stage Outputs\"] += 1\n","        else:\n","            file_counts[\"Other\"] += 1\n","\n","for category, count in file_counts.items():\n","    print(f\"   {category:<25} {count:>3} files\")\n","\n","print(\"-\" * 70)\n","print(f\"   {'TOTAL':<25} {total_files:>3} files\")\n","\n","# ============================================================================\n","# FINAL CHECKLIST\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"AUDIT BUNDLE CHECKLIST\")\n","print(\"=\" * 70)\n","\n","checklist_items = [\n","    (\"AUDIT_README.txt\", (run_dir / \"AUDIT_README.txt\").exists()),\n","    (\"integrity_summary.json\", (run_dir / \"integrity_summary.json\").exists()),\n","    (\"run_manifest.json\", (run_dir / \"run_manifest.json\").exists()),\n","    (\"org_policy.json\", (run_dir / \"org_policy.json\").exists()),\n","    (\"workflow_runbook.json\", (run_dir / \"workflow_runbook.json\").exists()),\n","    (\"prompts_log.jsonl\", (run_dir / \"logs\" / \"prompts_log.jsonl\").exists()),\n","    (\"stage_gate_log.jsonl\", (run_dir / \"logs\" / \"stage_gate_log.jsonl\").exists()),\n","    (\"verification_register.json\", (run_dir / \"verification_register.json\").exists()),\n","    (\"approvals_log.json\", (run_dir / \"approvals_log.json\").exists()),\n","    (\"qa_results.json\", (run_dir / \"qa_results.json\").exists()),\n","    (\"incident_log.json\", (run_dir / \"incident_log.json\").exists()),\n","    (\"deliverables/ directory\", (run_dir / \"deliverables\").exists()),\n","    (\"stage_outputs/ directory\", (run_dir / \"stage_outputs\").exists()),\n","    (\"ZIP bundle created\", zip_path.exists())\n","]\n","\n","print()\n","for item, status in checklist_items:\n","    status_symbol = \"âœ“\" if status else \"âœ—\"\n","    print(f\"   [{status_symbol}] {item}\")\n","\n","# ============================================================================\n","# FINAL OUTPUT\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"RECORDKEEPING COMPLETE\")\n","print(\"=\" * 70)\n","\n","print(f\"\\nðŸ“¦ ZIP Bundle Location:\")\n","print(f\"   {zip_path}\")\n","\n","print(f\"\\nðŸ“ Run Directory:\")\n","print(f\"   {run_dir}\")\n","\n","print(f\"\\nðŸ” Integrity Summary:\")\n","print(f\"   {run_dir / 'integrity_summary.json'}\")\n","print(f\"   Total files hashed: {len(file_hashes)}\")\n","\n","zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n","print(f\"\\nðŸ“Š Bundle Statistics:\")\n","print(f\"   Total files: {total_files}\")\n","print(f\"   ZIP size: {zip_size_mb:.2f} MB\")\n","print(f\"   Config hash: {config_hash}\")\n","\n","print(f\"\\nâœ“ Complete audit trail created\")\n","print(f\"âœ“ All governance artifacts included\")\n","print(f\"âœ“ Integrity hashes computed\")\n","print(f\"âœ“ Ready for compliance review\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"LEVEL 5 (ORGANIZATIONS) EXECUTION COMPLETE\")\n","print(\"=\" * 70)\n","\n","print(f\"\\nðŸ“– Next Steps:\")\n","print(f\"   1. Download the ZIP bundle: {zip_filename}\")\n","print(f\"   2. Review AUDIT_README.txt for complete documentation\")\n","print(f\"   3. Check verification_register.json for pending verifications\")\n","print(f\"   4. Review approvals_log.json for pending approvals\")\n","print(f\"   5. Complete QA reviews (see qa_results.json)\")\n","print(f\"   6. Address incidents (see incident_log.json)\")\n","\n","print(f\"\\nâš ï¸  CRITICAL REMINDER:\")\n","print(f\"   All outputs have verification_status = 'Not verified'\")\n","print(f\"   Human review is REQUIRED before any use\")\n","print(f\"   Consultant owns final judgment and decisions\")\n","\n","print(\"\\n\" + \"=\" * 70)"],"metadata":{"id":"STPTAD0YNi9b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768936263181,"user_tz":360,"elapsed":54,"user":{"displayName":"Alejandro Reynoso del Valle","userId":"04174712603211483042"}},"outputId":"30129609-4140-4bbc-f12e-2c8f907b3f32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","FINAL RECORDKEEPING: AUDIT BUNDLE CREATION\n","======================================================================\n","\n","ðŸ“„ Creating AUDIT_README.txt...\n","   âœ“ AUDIT_README.txt created\n","\n","ðŸ” Creating integrity_summary.json...\n","   âœ“ integrity_summary.json created (57 files hashed)\n","\n","ðŸ“¦ Creating ZIP bundle...\n","   âœ“ ZIP bundle created: /content/ai_consulting_ch5_runs/run_20260120_164244_582e182e.zip\n","\n","ðŸ“‹ Bundle Contents:\n","----------------------------------------------------------------------\n","   Policy & Workflow           2 files\n","   Logs                        4 files\n","   Governance Artifacts        6 files\n","   Deliverables               12 files\n","   Stage Outputs              30 files\n","   Other                       6 files\n","----------------------------------------------------------------------\n","   TOTAL                      60 files\n","\n","======================================================================\n","AUDIT BUNDLE CHECKLIST\n","======================================================================\n","\n","   [âœ“] AUDIT_README.txt\n","   [âœ“] integrity_summary.json\n","   [âœ“] run_manifest.json\n","   [âœ“] org_policy.json\n","   [âœ“] workflow_runbook.json\n","   [âœ“] prompts_log.jsonl\n","   [âœ“] stage_gate_log.jsonl\n","   [âœ“] verification_register.json\n","   [âœ“] approvals_log.json\n","   [âœ“] qa_results.json\n","   [âœ“] incident_log.json\n","   [âœ“] deliverables/ directory\n","   [âœ“] stage_outputs/ directory\n","   [âœ“] ZIP bundle created\n","\n","======================================================================\n","RECORDKEEPING COMPLETE\n","======================================================================\n","\n","ðŸ“¦ ZIP Bundle Location:\n","   /content/ai_consulting_ch5_runs/run_20260120_164244_582e182e.zip\n","\n","ðŸ“ Run Directory:\n","   /content/ai_consulting_ch5_runs/run_20260120_164244_582e182e\n","\n","ðŸ” Integrity Summary:\n","   /content/ai_consulting_ch5_runs/run_20260120_164244_582e182e/integrity_summary.json\n","   Total files hashed: 57\n","\n","ðŸ“Š Bundle Statistics:\n","   Total files: 60\n","   ZIP size: 0.10 MB\n","   Config hash: d2ef82f08f0c34b9\n","\n","âœ“ Complete audit trail created\n","âœ“ All governance artifacts included\n","âœ“ Integrity hashes computed\n","âœ“ Ready for compliance review\n","\n","======================================================================\n","LEVEL 5 (ORGANIZATIONS) EXECUTION COMPLETE\n","======================================================================\n","\n","ðŸ“– Next Steps:\n","   1. Download the ZIP bundle: run_20260120_164244_582e182e.zip\n","   2. Review AUDIT_README.txt for complete documentation\n","   3. Check verification_register.json for pending verifications\n","   4. Review approvals_log.json for pending approvals\n","   5. Complete QA reviews (see qa_results.json)\n","   6. Address incidents (see incident_log.json)\n","\n","âš ï¸  CRITICAL REMINDER:\n","   All outputs have verification_status = 'Not verified'\n","   Human review is REQUIRED before any use\n","   Consultant owns final judgment and decisions\n","\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["##11.CONCLUSIONS"],"metadata":{"id":"7X2_AKt3NkAR"}},{"cell_type":"markdown","source":["Cell 10: Sealing the Organizational Memory in a Complete Audit Package\n","\n","Cell 10 is the final act of organizational accountability - taking everything that\n","happened during this run and packaging it into a complete, verifiable, permanent\n","record that could withstand regulatory scrutiny, client disputes, or institutional\n","knowledge transfer years from now. This cell transforms a working directory full\n","of JSON files and text outputs into an official organizational archive with\n","cryptographic integrity verification and comprehensive documentation.\n","\n","The cell begins by creating AUDIT_README.txt, which is far more than a simple\n","readme file. This is a comprehensive audit report running over two thousand words\n","that explains what this notebook does, why it exists, what artifacts it produces,\n","how to interpret them, and how to reproduce the entire run. Think of it as the\n","user manual for your organizational archive. If a regulator asks three years from\n","now \"show me your AI governance process,\" you hand them this README and they can\n","understand your complete approach without technical expertise.\n","\n","The README documents critical details: which AI model was used (Claude Sonnet 4.5),\n","what parameters governed it (temperature 0.2, max tokens 4128), what the config\n","hash was (the cryptographic fingerprint proving identical configuration throughout),\n","what cases were processed, what governance artifacts were created, and what each\n","artifact means. It explains that prompts_log.jsonl contains redacted logs using\n","hashes rather than full text to protect confidentiality. It explains that\n","verification_register.json lists what humans must verify before outputs can be\n","used. It explains that all outputs carry verification_status \"Not verified\"\n","because human review is mandatory.\n","\n","Next comes integrity verification through cryptographic hashing. The cell walks\n","through every file in your run directory - organizational policies, governance\n","logs, stage outputs, deliverable bundles, everything - and computes a SHA-256\n","hash for each. A hash is a unique fingerprint: change even one character in a\n","file and the hash changes completely. The cell creates integrity_summary.json\n","listing every file path with its corresponding hash. This enables tamper detection.\n","If someone claims a file has been altered, you can recompute the hash and compare\n","against the integrity summary. If hashes match, the file is unchanged. If they\n","differ, tampering occurred.\n","\n","This cryptographic integrity matters enormously for professional services. Imagine\n","a client dispute eighteen months from now claiming you made recommendations you\n","weren't authorized to make. You retrieve your archive, check the integrity hashes\n","to prove files weren't altered, open the human-readable summary showing your\n","deliverable was explicitly scoped as scenario framing with no recommendations,\n","check the incident log showing the policy scanner flagged zero recommendation\n","language violations, and check the approval log showing a Partner reviewed and\n","approved the neutral framing. The integrity hashes transform your archive from\n","\"we think this is what we did\" to \"we can prove this is what we did.\"\n","\n","Then comes ZIP bundle creation. The cell packages your entire run directory -\n","organizational policies, workflow runbooks, all logs, all stage outputs, all\n","deliverables, the audit README, the integrity summary, everything - into a single\n","compressed archive file named with your run identifier. This ZIP serves multiple\n","purposes. It's portable (you can download it and store it in your firm's document\n","management system). It's complete (everything needed to understand this run is in\n","one package). It's timestamped (the run name includes date and time). It's\n","versioned (each run gets a unique identifier so you can distinguish them).\n","\n","The cell then produces a bundle contents summary showing file counts by category:\n","how many policy files, how many log files, how many governance artifacts, how many\n","deliverables, how many stage outputs. This gives you an at-a-glance understanding\n","of archive completeness. A complete run should have two policy files, approximately\n","eight to ten governance logs, four to five deliverable bundles (depending on\n","whether you ran Cell 9), and twelve to twenty stage outputs.\n","\n","Next comes the audit bundle checklist - a point-by-point verification that every\n","required component exists. You see checkbox items: AUDIT_README.txt present,\n","integrity_summary.json present, run_manifest.json present, org_policy.json present,\n","prompts_log.jsonl present, stage_gate_log.jsonl present, verification_register\n","present, approvals_log present, and so on. Each item shows a checkmark if the file\n","exists. This checklist serves as a pre-archival quality gate - before you seal\n","the archive, verify everything required is actually there.\n","\n","The cell concludes with final statistics: ZIP bundle location (where to download\n","it), total file count, ZIP size in megabytes, and config hash. These statistics\n","provide metadata about your organizational output. A typical run with four\n","mini-cases plus one user case produces roughly thirty to forty files totaling\n","two to five megabytes compressed. The config hash appears again here as final\n","confirmation that all work used consistent AI configuration.\n","\n","But Cell 10's most important output is actually the mindset it reinforces. The\n","cell ends with explicit next steps for humans: download the ZIP, review the audit\n","README, check verification_register for pending verifications, review approvals_log\n","for pending approvals, complete QA reviews, address any incidents. And then the\n","critical reminder appears one final time: \"All outputs have verification_status =\n","'Not verified.' Human review is REQUIRED before any use. Consultant owns final\n","judgment and decisions.\"\n","\n","This reminder appearing at the very end, after all the sophisticated AI drafting\n","and automated governance, drives home the Level 5 philosophy. The system created\n","an impressive amount of content and governance documentation automatically. But\n","none of it is final. None of it is approved for client use. None of it substitutes\n","for human professional judgment. The AI drafted, the code enforced governance,\n","and now humans must review, verify, approve, and take ownership.\n","\n","Cell 10 represents organizational completeness. When this cell finishes, you don't\n","just have draft outputs scattered across a working directory. You have a complete\n","organizational archive with comprehensive documentation, cryptographic integrity\n","verification, systematic organization, and clear instructions for human review.\n","You have transformed AI-assisted work from ephemeral experimentation into\n","permanent institutional memory that meets professional standards for recordkeeping,\n","compliance, and knowledge transfer.\n","\n","If you implement Level 5 in your actual firm, Cell 10's archive pattern becomes\n","your standard operating procedure. Every consulting engagement produces a ZIP\n","bundle. Every bundle contains the same governance artifacts. Every bundle can be\n","retrieved years later and understood completely because the AUDIT_README explains\n","everything. This consistency enables organizational learning (analyzing verification\n","registers across cases to identify systematic gaps), compliance demonstration\n","(showing regulators your systematic governance), and knowledge transfer (new\n","consultants reading archived bundles to understand how engagements were scoped\n","and executed).\n","\n","Cell 10 is the organizational close - the final proof that Level 5 isn't about\n","having smarter AI or writing more code, but about designing systems where AI,\n","automation, and human judgment create complete, governed, auditable organizational\n","capability at scale."],"metadata":{"id":"aV65a4QjNzQV"}},{"cell_type":"markdown","source":["##12.APPENDIX: CODE STRUCTURE"],"metadata":{"id":"TfD0tcni03h-"}},{"cell_type":"markdown","source":["###12.1.GATES"],"metadata":{"id":"GSoYnNaG07aK"}},{"cell_type":"markdown","source":["GATES FOR THE DIGITAL TRANSFORMATION RETAIL EXAMPLE\n","\n","HARD-CODED GATES (Programmatic - No LLM Involved)\n","\n","These gates are enforced by the code logic in Cells 4 and 7. They execute\n","automatically based on rules and data classification.\n","\n","\n","**Gate 1: Data Classification Check**\n","  - Trigger: User inputs data_classification = \"confidential\"\n","  - Action: System automatically determines risk_tier = \"medium\"\n","  - Location: Cell 7, build_controls_checklist() function\n","  - Code Logic:\n","    - if data_class == \"restricted\" â†’ risk_tier = \"high\"\n","    - if data_class == \"confidential\" â†’ risk_tier = \"medium\"\n","    - else â†’ risk_tier = \"low\"\n","  - Gate Status: PASSED (automatically, no human decision)\n","\n","\n","**Gate 2: Controls Assignment**\n","  - Trigger: risk_tier = \"medium\" determined\n","  - Action: System assigns required controls\n","  - Location: Cell 7, build_controls_checklist() function\n","  - Code Logic:\n","    - Base controls (all tiers): Redaction, minimum necessary, Not verified flag, human review\n","    - Medium tier adds: Senior approver required, QA sampling mandatory, numeric claims verified\n","  - Gate Status: PASSED (automatically)\n","  - Gate Logged: log_stage_gate(case_name, \"controls\", \"controls_assigned\", \"passed\")\n","\n","\n","**Gate 3: Approval Routing**\n","  - Trigger: risk_tier = \"medium\"\n","  - Action: System routes to \"Partner\" (not \"Senior Consultant\")\n","  - Location: Cell 9, line ~235\n","  - Code Logic:\n","    - approver_role = \"Senior Consultant\" if risk_tier == \"low\" else \"Partner\"\n","  - Gate Status: Creates PENDING approval (not auto-approved)\n","  - Gate Logged: Recorded in approvals_log.json\n","\n","\n","**Gate 4: QA Sampling Trigger**\n","  - Trigger: Highest risk severity detected in Stage A/B/C outputs\n","  - Action: If any risk has severity = \"high\" â†’ automatic QA sample selection\n","  - Location: Cell 9, lines ~240-265\n","  - Code Logic:\n","    - Scans all risks from stage_A, stage_B, stage_C\n","    - if any risk.severity == 'high' â†’ select for QA\n","    - Creates sample_reason = \"high_risk\"\n","  - Gate Status: CONDITIONAL (depends on LLM risk identification)\n","  - Gate Logged: Added to qa_results.json\n","\n","\n","**Gate 5: Redaction Gate**\n","  - Trigger: User input contains PII (emails, phone numbers, names, addresses, IDs)\n","  - Action: Automatic redaction before any LLM processing\n","  - Location: Cell 9, lines ~55-75 (build_minimum_necessary)\n","  - Code Logic: Regex pattern matching for PII\n","  - Gate Status: PASSED (automatically)\n","  - Output: removed_fields_summary shows what was redacted\n","\n","\n","**Gate 6: Stage Gate Logging**\n","  - Trigger: After each stage (A, B, C) completes successfully\n","  - Action: Append to stage_gate_log.jsonl\n","  - Location: Cell 8, run_controlled_drafting() function\n","  - Code Logic:\n","    - log_stage_gate(case_name, \"stage_A\", \"intake_narrative_drafted\", \"passed\")\n","    - log_stage_gate(case_name, \"stage_B\", \"deliverable_drafted\", \"passed\")\n","    - log_stage_gate(case_name, \"stage_C\", \"verification_plan_drafted\", \"passed\")\n","  - Gate Status: PASSED (logged after successful LLM calls)\n","\n","\n","LLM-DRIVEN GATES (Model Output Dependent)\n","\n","These gates depend on what the LLM returns. They check the LLM's output and\n","enforce rules based on content.\n","\n","\n","**Gate 7: JSON Schema Validation**\n","  - Trigger: After every LLM call (Stages A, B, C)\n","  - Action: Validate that LLM returned exact schema with correct keys and types\n","  - Location: Cell 6, validate_exact_schema() function\n","  - LLM Dependency: LLM must return valid JSON with exact keys:\n","    - task, facts_provided, assumptions, open_questions, risks,\n","      draft_output, verification_status, questions_to_verify\n","  - Decision Logic:\n","    - Missing keys â†’ FAIL â†’ retry with schema reminder\n","    - Extra keys â†’ FAIL â†’ retry\n","    - Wrong types â†’ FAIL â†’ retry\n","    - After 3 attempts â†’ EXCEPTION (stops pipeline)\n","  - Gate Status: PASS/FAIL with retries\n","\n","\n","**Gate 8: Verification Status Check**\n","  - Trigger: After every LLM call\n","  - Action: Verify that verification_status = \"Not verified\" (exact string)\n","  - Location: Cell 6, validate_exact_schema() function\n","  - LLM Dependency: LLM must return exactly \"Not verified\"\n","  - Decision Logic:\n","    - If verification_status != \"Not verified\" â†’ FAIL validation â†’ retry\n","  - Gate Status: ENFORCED (zero tolerance)\n","\n","\n","**Gate 9: Recommendation Language Detection**\n","  - Trigger: After every LLM call, checks draft_output\n","  - Action: Scan for prohibited phrases like \"we recommend\", \"you should\", \"best option\"\n","  - Location: Cell 6, reject_recommendations() function\n","  - LLM Dependency: LLM must NOT include recommendation language\n","  - Decision Logic:\n","    - If prohibited phrase detected â†’ Log incident (severity: high)\n","    - Add decision_laundering risk to output\n","    - Does NOT stop pipeline, but flags for human review\n","  - Gate Status: SOFT FAIL (logged, not blocking)\n","\n","\n","**Gate 10: Numeric Claims Hallucination Check**\n","  - Trigger: After every LLM call, checks draft_output\n","  - Action: Extract currency/percentages/large numbers and verify against facts_provided + assumptions\n","  - Location: Cell 6, numeric_claim_check() function\n","  - LLM Dependency: LLM must only use numbers from input facts\n","  - Decision Logic:\n","    - Extract patterns: $1,000, 25%, 1,000,000\n","    - Check if each number appears in facts_provided or assumptions\n","    - If suspicious number found â†’ Log incident (severity: high)\n","    - Add hallucination risk to output\n","  - Gate Status: SOFT FAIL (logged, not blocking)\n","\n","\n","**Gate 11: Risk Identification Gate**\n","  - Trigger: After Stage B (deliverable draft)\n","  - Action: Check if LLM identified risks with proper severity ratings\n","  - Location: Implicit in Cell 8 (aggregates risks for QA sampling)\n","  - LLM Dependency: LLM must return risks array with type, severity, note\n","  - Decision Logic:\n","    - Collect all risks from stages A, B, C\n","    - Determine highest_severity\n","    - If highest_severity == \"high\" â†’ trigger QA sampling (Gate 4)\n","  - Gate Status: INFORMATIONAL (affects downstream gates)\n","\n","\n","**Gate 12: Open Questions Gate**\n","  - Trigger: After each stage (A, B, C)\n","  - Action: Collect open_questions and questions_to_verify\n","  - Location: Cell 7, build_verification_register_stub()\n","  - LLM Dependency: LLM must identify gaps in facts and what needs verification\n","  - Decision Logic:\n","    - Extract open_questions and questions_to_verify\n","    - Add to verification_register.json\n","    - Does NOT block pipeline, but creates verification work for humans\n","  - Gate Status: INFORMATIONAL (creates work items)\n","\n","\n","**Gate 13: Parsing Robustness Gate**\n","  - Trigger: After every LLM call\n","  - Action: Handle malformed JSON (markdown fences, trailing commas, extraneous text)\n","  - Location: Cell 6, parse_with_repair() function\n","  - LLM Dependency: LLM might return imperfect JSON\n","  - Decision Logic:\n","    - Try direct parse\n","    - If fails, extract JSON from text\n","    - If fails, fix trailing commas\n","    - If fails after 3 attempts â†’ Write debug file â†’ EXCEPTION\n","  - Gate Status: DEFENSIVE (multiple fallbacks before failure)\n","\n","\n","GATE EXECUTION SEQUENCE FOR YOUR EXAMPLE\n","\n","When you run the digital transformation retail example, here's the gate sequence:\n","\n","\n","**Step 1: User Input**\n","  - Gate 5 (Redaction) executes\n","  - Removes any PII if present\n","\n","\n","**Step 2: Intake Record Creation**\n","  - Gate 1 (Data Classification) executes\n","  - confidential â†’ risk_tier = medium\n","  - Gate 2 (Controls Assignment) executes\n","  - Assigns medium-tier controls\n","  - Logged to stage_gate_log.jsonl\n","\n","\n","**Step 3: Stage A (Intake Narrative)**\n","  - LLM call happens\n","  - Gate 13 (Parsing) executes\n","  - Gate 7 (Schema Validation) executes\n","  - Gate 8 (Verification Status) executes\n","  - Gate 9 (Recommendation Check) executes\n","  - Gate 10 (Numeric Claims Check) executes\n","  - Gate 12 (Open Questions) executes\n","  - Stage gate logged: \"intake_narrative_drafted\" = \"passed\"\n","\n","\n","**Step 4: Stage B (Deliverable Draft)**\n","  - LLM call happens\n","  - Gates 13, 7, 8, 9, 10, 12 execute (same as Stage A)\n","  - Gate 11 (Risk Identification) executes\n","  - Stage gate logged: \"deliverable_drafted\" = \"passed\"\n","\n","\n","**Step 5: Stage C (Verification Plan)**\n","  - LLM call happens\n","  - Gates 13, 7, 8, 9, 10, 12 execute (same as Stage A)\n","  - Stage gate logged: \"verification_plan_drafted\" = \"passed\"\n","\n","\n","**Step 6: Approval Routing**\n","  - Gate 3 (Approval Routing) executes\n","  - risk_tier = medium â†’ approver = \"Partner\"\n","  - Creates pending approval\n","\n","\n","**Step 7: QA Sampling**\n","  - Gate 4 (QA Sampling Trigger) executes\n","  - If highest_severity = \"high\" â†’ select for QA\n","  - Otherwise, skip QA sampling\n","\n","\n","**Step 8: Archive**\n","  - All outputs saved with governance artifacts\n","  - Complete audit trail created\n","\n","\n","SUMMARY: HARD-CODED vs LLM-DRIVEN\n","\n","**Hard-Coded Gates (6 total):**\n","\n","These execute based on rules and user input, no LLM involvement:\n","  - Data Classification Check\n","  - Controls Assignment\n","  - Approval Routing\n","  - QA Sampling Trigger (conditional on LLM risks)\n","  - Redaction Gate\n","  - Stage Gate Logging\n","\n","\n","**LLM-Driven Gates (7 total):**\n","\n","These depend on LLM output quality and content:\n","  - JSON Schema Validation\n","  - Verification Status Check\n","  - Recommendation Language Detection\n","  - Numeric Claims Hallucination Check\n","  - Risk Identification Gate\n","  - Open Questions Gate\n","  - Parsing Robustness Gate\n","\n","\n","**Key Insight:**\n","\n","Hard-coded gates create the ORGANIZATIONAL STRUCTURE (who approves, what\n","controls apply, what gets sampled).\n","\n","LLM-driven gates ensure OUTPUT QUALITY (valid format, no recommendations,\n","no hallucinations, gaps identified).\n","\n","Together, they create a Level 5 system where:\n","  - The organization controls the process (hard-coded gates)\n","  - The LLM produces quality drafts (LLM-driven gates)\n","  - Humans make final decisions (approval gates, verification register)"],"metadata":{"id":"VInY9Z6X2o_Z"}},{"cell_type":"markdown","source":["###12.2.LIFECYCLE FUNCTIONS"],"metadata":{"id":"oi7Ybmwu216f"}},{"cell_type":"markdown","source":["LIFECYCLE FUNCTIONS FOR THE DIGITAL TRANSFORMATION RETAIL EXAMPLE\n","\n","INTAKE & CONTROLS FUNCTIONS\n","\n","These functions create the organizational intake record and determine required\n","controls based on risk classification.\n","\n","\n","**Function 1: build_intake_record()**\n","  - Purpose: Create formal intake documentation for the case\n","  - Inputs: case_name, purpose, intended_reliance, data_classification, scope_boundary\n","  - Location: Cell 7\n","  - What it does:\n","    - Creates structured intake record with timestamp\n","    - Generates unique intake_id (SHA256 hash of case_name + timestamp)\n","    - Saves intake_record.json to stage_outputs/{case_name}/\n","  - Output: intake_record dict\n","  - Example for your case:\n","    - case_name: \"digital_transformation_retail\"\n","    - data_classification: \"confidential\"\n","    - intake_id: auto-generated (e.g., \"a3f2c8d91e4b\")\n","  - Organizational role: This is the \"mouth\" - how work enters the system\n","\n","\n","**Function 2: build_controls_checklist()**\n","  - Purpose: Determine required controls based on risk tier\n","  - Inputs: intake_record (from Function 1)\n","  - Location: Cell 7\n","  - What it does:\n","    - Reads data_classification from intake_record\n","    - Maps to risk_tier: restrictedâ†’high, confidentialâ†’medium, elseâ†’low\n","    - Assigns controls based on tier:\n","      - All tiers: Redaction, minimum necessary, Not verified flag, human review\n","      - Medium+: Senior approver, QA sampling, numeric claims verification\n","      - High: Legal review, dual approval, enhanced audit trail, 30-day retention\n","    - Saves controls_checklist.json to stage_outputs/{case_name}/\n","  - Output: controls_checklist dict with risk_tier and required_controls list\n","  - Example for your case:\n","    - Input: data_classification = \"confidential\"\n","    - Output: risk_tier = \"medium\"\n","    - Controls: 7 total (4 base + 3 medium-tier)\n","  - Organizational role: This is the \"immune system\" - safety checks before processing\n","\n","\n","VERIFICATION & APPROVAL FUNCTIONS\n","\n","These functions manage what needs human verification and route approvals to\n","the right people.\n","\n","\n","**Function 3: build_verification_register_stub()**\n","  - Purpose: Extract verification needs from LLM outputs and track them\n","  - Inputs: case_name, stage_name, model_output (from LLM call)\n","  - Location: Cell 7\n","  - What it does:\n","    - Extracts open_questions array from model_output\n","    - Extracts questions_to_verify array from model_output\n","    - Creates verification entry with timestamp, assigned_to, priority\n","    - Appends to verification_register.json (central register)\n","  - Output: verification entry dict\n","  - Example for your case:\n","    - Stage A might flag: \"What is the specific initial budget allocation?\"\n","    - Stage B might flag: \"Integration complexity not quantified - needs technical assessment\"\n","    - Stage C might flag: \"Verify IT team capacity for 24-month timeline\"\n","  - Organizational role: This is the \"quality control sensor\" - tracks what humans must verify\n","\n","\n","**Function 4: build_approval_stub()**\n","  - Purpose: Create approval routing for deliverables\n","  - Inputs: case_name, artifact_name, approver_role, state\n","  - Location: Cell 7\n","  - What it does:\n","    - Creates approval entry with unique approval_id\n","    - Sets approver_role based on risk tier (Senior Consultant or Partner)\n","    - Sets state to \"pending\" (default)\n","    - Records requested_timestamp\n","    - Appends to approvals_log.json\n","  - Output: approval_entry dict\n","  - Example for your case:\n","    - artifact_name: \"digital_transformation_retail_bundle\"\n","    - approver_role: \"Partner\" (because risk_tier = medium)\n","    - state: \"pending\"\n","    - approval_id: auto-generated (e.g., \"52c9c792926b\")\n","  - Organizational role: This is the \"executive brain\" - who decides what gets released\n","\n","\n","QA SAMPLING FUNCTIONS\n","\n","These functions implement systematic quality assurance through sampling rather\n","than reviewing everything.\n","\n","\n","**Function 5: qa_sample_selector()**\n","  - Purpose: Select which outputs get human QA review\n","  - Inputs: case_outputs (list of artifacts), sampling_plan\n","  - Location: Cell 7\n","  - What it does:\n","    - Implements sampling strategy: 1-2 artifacts per case\n","    - Always includes high-risk outputs\n","    - Random selection from medium-risk outputs\n","    - First deliverable from each case type (baseline)\n","    - Limits to 2 samples per case maximum\n","  - Output: selected_samples list\n","  - Example for your case:\n","    - If Stage B output has severity=\"high\" risk â†’ automatically selected\n","    - sample_reason: \"high_risk\" or \"baseline_first_deliverable\"\n","  - Organizational role: This is the \"internal auditor\" - systematic spot checks\n","\n","\n","**Function 6: qa_reviewer_checklist()**\n","  - Purpose: Generate human QA checklist for selected samples\n","  - Inputs: sample dict (from Function 5)\n","  - Location: Cell 7\n","  - What it does:\n","    - Creates structured checklist with 6 review items:\n","      1. verification_status is 'Not verified'\n","      2. open_questions are substantive and relevant\n","      3. No recommendation language detected\n","      4. Numeric claims sourced from facts/assumptions\n","      5. Draft output coherent and aligned with scope\n","      6. Risks appropriately identified and severity-rated\n","    - Each item has status: \"pending\" (for human to complete)\n","    - Generates unique sample_id\n","  - Output: checklist dict\n","  - Example for your case:\n","    - sample_id: auto-generated hash\n","    - reviewer: \"Human QA Lead (TBD)\"\n","    - 6 checklist items, all status=\"pending\"\n","    - overall_assessment: \"pending\"\n","  - Organizational role: This is the \"QA protocol\" - standardized review process\n","\n","\n","**Function 7: update_qa_results()**\n","  - Purpose: Record QA samples and checklists centrally\n","  - Inputs: samples_with_checklists (list of checklist dicts)\n","  - Location: Cell 7\n","  - What it does:\n","    - Reads current qa_results.json\n","    - Appends new samples to samples array\n","    - Updates summary with total_samples count and pending_review count\n","    - Writes back to qa_results.json\n","  - Output: None (updates file in place)\n","  - Example for your case:\n","    - Adds 1 sample (your digital transformation case)\n","    - summary: {\"total_samples\": 5, \"pending_review\": 5}\n","  - Organizational role: This is the \"QA register\" - central tracking of all QA activities\n","\n","\n","STAGE GATE LOGGING FUNCTION\n","\n","This function creates an append-only audit trail of stage transitions.\n","\n","\n","**Function 8: log_stage_gate()**\n","  - Purpose: Record every stage gate transition with timestamp\n","  - Inputs: case_name, stage_name, gate_name, gate_status, notes\n","  - Location: Cell 7\n","  - What it does:\n","    - Creates gate entry with timestamp\n","    - Appends to stage_gate_log.jsonl (append-only log, never modified)\n","    - Records which case, which stage, which gate, pass/fail, optional notes\n","  - Output: None (appends to log file)\n","  - Example for your case:\n","    - After Stage A: log_stage_gate(\"digital_transformation_retail\", \"stage_A\", \"intake_narrative_drafted\", \"passed\")\n","    - After Stage B: log_stage_gate(\"digital_transformation_retail\", \"stage_B\", \"deliverable_drafted\", \"passed\")\n","    - After Stage C: log_stage_gate(\"digital_transformation_retail\", \"stage_C\", \"verification_plan_drafted\", \"passed\")\n","  - Organizational role: This is the \"nervous system\" - records everything that happens\n","\n","\n","LIFECYCLE EXECUTION SEQUENCE FOR YOUR EXAMPLE\n","\n","When Cell 9 runs your digital transformation retail case, here's how the\n","lifecycle functions execute in order:\n","\n","\n","**Phase 1: Intake & Classification**\n","  - Function 1 (build_intake_record) executes\n","    - Creates intake_record.json\n","    - Assigns intake_id\n","  - Function 2 (build_controls_checklist) executes\n","    - Determines risk_tier = \"medium\"\n","    - Assigns 7 required controls\n","    - Creates controls_checklist.json\n","  - Function 8 (log_stage_gate) executes\n","    - Logs: \"controls_assigned\" = \"passed\"\n","\n","\n","**Phase 2: Stage A Drafting (Intake Narrative)**\n","  - LLM call happens (via call_llm_structured from Cell 6)\n","  - Function 3 (build_verification_register_stub) executes\n","    - Extracts open_questions from Stage A output\n","    - Adds to verification_register.json\n","  - Function 8 (log_stage_gate) executes\n","    - Logs: \"intake_narrative_drafted\" = \"passed\"\n","\n","\n","**Phase 3: Stage B Drafting (Deliverable)**\n","  - LLM call happens\n","  - Function 3 (build_verification_register_stub) executes\n","    - Extracts open_questions from Stage B output\n","    - Adds to verification_register.json\n","  - Function 8 (log_stage_gate) executes\n","    - Logs: \"deliverable_drafted\" = \"passed\"\n","\n","\n","**Phase 4: Stage C Drafting (Verification Plan)**\n","  - LLM call happens\n","  - Function 3 (build_verification_register_stub) executes\n","    - Extracts open_questions from Stage C output\n","    - Adds to verification_register.json\n","  - Function 8 (log_stage_gate) executes\n","    - Logs: \"verification_plan_drafted\" = \"passed\"\n","\n","\n","**Phase 5: Approval Routing**\n","  - Function 4 (build_approval_stub) executes\n","    - Creates approval entry\n","    - Sets approver_role = \"Partner\" (risk_tier = medium)\n","    - Sets state = \"pending\"\n","    - Adds to approvals_log.json\n","\n","\n","**Phase 6: QA Sampling (Conditional)**\n","  - Risk aggregation happens (collects all risks from A, B, C)\n","  - If highest_severity = \"high\":\n","    - Function 5 (qa_sample_selector) executes (implicitly via dict creation)\n","    - Function 6 (qa_reviewer_checklist) executes\n","      - Creates QA checklist\n","    - Function 7 (update_qa_results) executes\n","      - Adds sample to qa_results.json\n","  - If highest_severity = \"low\" or \"medium\":\n","    - QA sampling skipped\n","\n","\n","**Phase 7: Deliverable Bundle Creation**\n","  - Creates bundle_index.json with artifact hashes\n","  - Creates human_readable.txt summary\n","  - Saves all artifacts to deliverables/ and stage_outputs/\n","\n","\n","FUNCTION INTERACTION MAP\n","\n","How the functions work together:\n","\n","\n","**Intake â†’ Controls Flow:**\n","  - build_intake_record() creates intake record\n","  - build_controls_checklist() reads intake record, outputs controls\n","  - Both save files to stage_outputs/{case_name}/\n","\n","\n","**Drafting â†’ Verification Flow:**\n","  - LLM produces stage_A/B/C outputs\n","  - build_verification_register_stub() extracts questions from each stage\n","  - Accumulates in central verification_register.json\n","\n","\n","**Controls â†’ Approval Flow:**\n","  - build_controls_checklist() determines risk_tier\n","  - build_approval_stub() reads risk_tier, sets approver_role\n","  - Partner approval required for medium/high risk\n","\n","\n","**Drafting â†’ QA Flow:**\n","  - Stages A/B/C produce risks arrays\n","  - Risk aggregation determines highest_severity\n","  - If high: qa_sample_selector() + qa_reviewer_checklist() + update_qa_results()\n","  - Creates QA work items in qa_results.json\n","\n","\n","**Everything â†’ Audit Trail Flow:**\n","  - log_stage_gate() called after every major transition\n","  - Creates append-only log in stage_gate_log.jsonl\n","  - Provides complete timeline of case progression\n","\n","\n","SUMMARY: LIFECYCLE FUNCTIONS AS ORGANIZATIONAL MACHINERY\n","\n","**Intake Functions (2):**\n","  - build_intake_record() - Document the work request\n","  - build_controls_checklist() - Assign safety controls\n","\n","**Verification & Approval Functions (2):**\n","  - build_verification_register_stub() - Track what needs human verification\n","  - build_approval_stub() - Route for human approval\n","\n","**QA Functions (3):**\n","  - qa_sample_selector() - Pick what to review\n","  - qa_reviewer_checklist() - Create review protocol\n","  - update_qa_results() - Record QA activities\n","\n","**Audit Functions (1):**\n","  - log_stage_gate() - Record every transition\n","\n","**Key Insight:**\n","\n","These 8 functions create the ORGANIZATIONAL OPERATING MODEL. They ensure that:\n","  - Work is formally documented (intake)\n","  - Controls are systematically assigned (not ad-hoc)\n","  - Verification needs are tracked (not forgotten)\n","  - Approvals are routed correctly (not \"email my boss\")\n","  - QA is systematic (not random)\n","  - Everything is logged (audit trail)\n","\n","Without these functions, you'd have Level 3 (individual workflow).\n","With these functions, you have Level 5 (organizational system)."],"metadata":{"id":"zy3ilrvz3Ywm"}},{"cell_type":"markdown","source":["WHICH LIFECYCLE FUNCTIONS CALL THE LLM?\n","\n","SHORT ANSWER: NONE OF THEM\n","\n","The 8 lifecycle functions in Cell 7 do NOT call the LLM.\n","They are pure organizational infrastructure - they manage governance artifacts.\n","\n","\n","DETAILED BREAKDOWN\n","\n","**Lifecycle Functions in Cell 7 (NO LLM CALLS):**\n","\n","Function 1: build_intake_record()\n","  - LLM Call: NO\n","  - What it does: Creates JSON file from user inputs\n","  - Pure data manipulation: Takes strings, creates dict, saves file\n","\n","Function 2: build_controls_checklist()\n","  - LLM Call: NO\n","  - What it does: If/then logic based on risk tier\n","  - Pure business rules: if confidential â†’ assign these controls\n","\n","Function 3: build_verification_register_stub()\n","  - LLM Call: NO\n","  - What it does: Extracts arrays from already-generated LLM output\n","  - Pure data extraction: model_output['open_questions'] â†’ register\n","\n","Function 4: build_approval_stub()\n","  - LLM Call: NO\n","  - What it does: Creates approval entry based on risk tier\n","  - Pure routing logic: if medium â†’ Partner, else Senior Consultant\n","\n","Function 5: qa_sample_selector()\n","  - LLM Call: NO\n","  - What it does: Filters list based on sampling criteria\n","  - Pure list filtering: select items where risk_level='high'\n","\n","Function 6: qa_reviewer_checklist()\n","  - LLM Call: NO\n","  - What it does: Creates structured checklist dict for humans\n","  - Pure template generation: Returns hardcoded checklist structure\n","\n","Function 7: update_qa_results()\n","  - LLM Call: NO\n","  - What it does: Appends to qa_results.json\n","  - Pure file I/O: Read JSON, append, write JSON\n","\n","Function 8: log_stage_gate()\n","  - LLM Call: NO\n","  - What it does: Appends to stage_gate_log.jsonl\n","  - Pure logging: Timestamp + metadata â†’ append to file\n","\n","\n","WHERE LLM CALLS ACTUALLY HAPPEN\n","\n","**The ONLY function that calls the LLM is in Cell 6:**\n","\n","call_llm_structured()\n","  - Location: Cell 6\n","  - Purpose: Wrapper for all LLM API calls\n","  - What it does:\n","    - Makes actual API call to Anthropic Claude\n","    - Handles JSON parsing with retries\n","    - Validates schema\n","    - Checks for policy violations\n","    - Logs to prompts_log.jsonl\n","  - Used by: run_controlled_drafting() function in Cell 8\n","\n","\n","**The function that ORCHESTRATES LLM calls is in Cell 8:**\n","\n","run_controlled_drafting()\n","  - Location: Cell 8\n","  - Purpose: Execute 3-stage drafting workflow\n","  - LLM Calls: 3 (one per stage A, B, C)\n","  - What it does:\n","    - Builds prompts for each stage\n","    - Calls call_llm_structured() three times\n","    - Saves stage outputs\n","    - Calls lifecycle functions to process outputs\n","\n","\n","CONCEPTUAL DISTINCTION\n","\n","**Lifecycle Functions (Cell 7) = Organizational Machinery**\n","  - No AI/LLM involvement\n","  - Pure business logic, data manipulation, file I/O\n","  - Could be implemented in any programming language\n","  - These are the \"governance controls\"\n","  - Example: \"If risk tier is high, route to Partner for approval\"\n","\n","**LLM Call Function (Cell 6) = AI Interface**\n","  - Makes API calls to Claude\n","  - Handles AI model responses\n","  - Defensive parsing and validation\n","  - This is the \"AI assistant\"\n","  - Example: \"Draft an intake narrative given these facts\"\n","\n","**Orchestration Function (Cell 8) = Workflow Execution**\n","  - Combines LLM calls + lifecycle functions\n","  - Manages the sequence: intake â†’ draft â†’ verify â†’ approve â†’ QA\n","  - This is the \"process manager\"\n","  - Example: \"First call LLM for Stage A, then call lifecycle functions to process results\"\n","\n","\n","EXECUTION FLOW FOR YOUR DIGITAL TRANSFORMATION EXAMPLE\n","\n","**Step 1: User Input (Cell 9)**\n","  - NO LLM CALL\n","  - Collects user inputs\n","  - Applies redaction (regex, no LLM)\n","\n","\n","**Step 2: Intake & Controls**\n","  - NO LLM CALL\n","  - Calls: build_intake_record() [Cell 7 function]\n","  - Calls: build_controls_checklist() [Cell 7 function]\n","\n","\n","**Step 3: Stage A Drafting**\n","  - LLM CALL #1\n","  - Calls: run_controlled_drafting() [Cell 8 function]\n","    - Which calls: call_llm_structured() [Cell 6 function] â† ACTUAL LLM CALL\n","  - Then calls: build_verification_register_stub() [Cell 7 function] â† NO LLM\n","  - Then calls: log_stage_gate() [Cell 7 function] â† NO LLM\n","\n","\n","**Step 4: Stage B Drafting**\n","  - LLM CALL #2\n","  - Same pattern as Stage A\n","\n","\n","**Step 5: Stage C Drafting**\n","  - LLM CALL #3\n","  - Same pattern as Stage A\n","\n","\n","**Step 6: Approval Routing**\n","  - NO LLM CALL\n","  - Calls: build_approval_stub() [Cell 7 function]\n","\n","\n","**Step 7: QA Sampling (if high risk)**\n","  - NO LLM CALL\n","  - Calls: qa_sample_selector() [Cell 7 function]\n","  - Calls: qa_reviewer_checklist() [Cell 7 function]\n","  - Calls: update_qa_results() [Cell 7 function]\n","\n","\n","TOTAL LLM CALLS FOR YOUR EXAMPLE: 3\n","\n","One call for each stage (A, B, C)\n","All 3 calls go through call_llm_structured() in Cell 6\n","All 8 lifecycle functions execute WITHOUT calling the LLM\n","\n","\n","WHY THIS DESIGN MATTERS\n","\n","**Separation of Concerns:**\n","  - LLM does what LLMs do well: Draft text, identify gaps, flag risks\n","  - Lifecycle functions do what code does well: Route approvals, track samples, log events\n","\n","**Auditability:**\n","  - LLM calls are logged (prompts_log.jsonl)\n","  - Lifecycle functions create governance artifacts\n","  - You can trace: \"Was this approved?\" â†’ check approvals_log.json (no LLM involved)\n","\n","**Organizational Control:**\n","  - The firm controls the lifecycle functions (hard-coded business rules)\n","  - The LLM is just a tool used within the lifecycle\n","  - Example: The firm decides \"confidential = medium risk = Partner approval\"\n","    - This is NOT an LLM decision\n","    - This is build_controls_checklist() executing firm policy\n","\n","**Reproducibility:**\n","  - If you re-run with same inputs and same model:\n","    - LLM might produce slightly different text (temperature > 0)\n","    - But lifecycle functions will ALWAYS execute identically\n","  - Governance is deterministic, drafting has controlled variability\n","\n","\n","ANALOGY\n","\n","Think of a restaurant kitchen:\n","\n","**LLM (call_llm_structured):**\n","  - The chef who cooks the dish\n","  - Creative, but needs oversight\n","  - Called 3 times: appetizer, main, dessert\n","\n","**Lifecycle Functions (Cell 7):**\n","  - The kitchen systems: inventory, quality checks, health inspections, plating standards\n","  - No cooking involved\n","  - Run before, during, and after the chef works\n","\n","**Orchestration (run_controlled_drafting):**\n","  - The kitchen manager who coordinates: \"Chef, cook the appetizer. QA, taste it. Server, plate it.\"\n","\n","\n","SUMMARY TABLE\n","\n","Function                              | Location | LLM Call? | Purpose\n","--------------------------------------|----------|-----------|------------------------------------------\n","build_intake_record()                 | Cell 7   | NO        | Document work request\n","build_controls_checklist()            | Cell 7   | NO        | Assign controls based on risk\n","build_verification_register_stub()    | Cell 7   | NO        | Track verification needs\n","build_approval_stub()                 | Cell 7   | NO        | Route for approval\n","qa_sample_selector()                  | Cell 7   | NO        | Select QA samples\n","qa_reviewer_checklist()               | Cell 7   | NO        | Create QA protocol\n","update_qa_results()                   | Cell 7   | NO        | Record QA activities\n","log_stage_gate()                      | Cell 7   | NO        | Audit trail logging\n","call_llm_structured()                 | Cell 6   | YES       | Make API call to Claude\n","run_controlled_drafting()             | Cell 8   | Indirect  | Orchestrates 3 LLM calls\n","\n","\n","KEY INSIGHT:\n","\n","Lifecycle functions = Organizational operating model (no AI needed)\n","LLM calls = Content generation tool (used within the operating model)\n","\n","Level 5 is NOT \"smarter AI\" - it's \"organizational system that uses AI responsibly\""],"metadata":{"id":"FatuhzTm3VlJ"}},{"cell_type":"markdown","source":["###12.3.HUMANS, OLD MACHINES AND AI\n"],"metadata":{"id":"keNAQ-DF3qRx"}},{"cell_type":"markdown","source":["WHERE DO WE USE THE LLM IN THE WORKFLOW?\n","\n","COMPLETE WORKFLOW WITH LLM / HUMAN / HARD-CODED ATTRIBUTION\n","\n","\n","STAGE 1: INTAKE & CLASSIFICATION\n","\n","**Step 1.1: User Provides Information**\n","  - Actor: HUMAN\n","  - What happens: User inputs case details in Cell 9\n","    - Case name, purpose, intended reliance, data classification, scope, facts\n","  - Output: Raw user input strings\n","\n","\n","**Step 1.2: Redaction**\n","  - Actor: HARD-CODED\n","  - What happens: Regex pattern matching removes PII\n","  - Function: redact() and build_minimum_necessary() [Cell 5]\n","  - Output: Sanitized inputs with removed_fields summary\n","\n","\n","**Step 1.3: Create Intake Record**\n","  - Actor: HARD-CODED\n","  - What happens: Build intake documentation\n","  - Function: build_intake_record() [Cell 7]\n","  - Output: intake_record.json\n","\n","\n","**Step 1.4: Determine Risk Tier**\n","  - Actor: HARD-CODED\n","  - What happens: Map data classification to risk tier\n","  - Function: build_controls_checklist() [Cell 7]\n","  - Logic:\n","    - confidential â†’ medium\n","    - restricted â†’ high\n","    - else â†’ low\n","  - Output: risk_tier\n","\n","\n","**Step 1.5: Assign Controls**\n","  - Actor: HARD-CODED\n","  - What happens: Assign required controls based on risk tier\n","  - Function: build_controls_checklist() [Cell 7]\n","  - Output: controls_checklist.json with 4-9 controls\n","\n","\n","**Step 1.6: Log Intake Gate**\n","  - Actor: HARD-CODED\n","  - What happens: Record intake completion\n","  - Function: log_stage_gate() [Cell 7]\n","  - Output: Entry in stage_gate_log.jsonl\n","  - Gate: \"controls_assigned\" = \"passed\"\n","\n","\n","STAGE 2: CONTROLLED DRAFTING - STAGE A (INTAKE NARRATIVE)\n","\n","**Step 2.1: Build Stage A Prompt**\n","  - Actor: HARD-CODED\n","  - What happens: Construct prompt with facts, scope, purpose\n","  - Function: run_controlled_drafting() [Cell 8]\n","  - Output: Prompt string (600-800 words)\n","\n","\n","**Step 2.2: Call LLM for Stage A**\n","  - Actor: LLM â† FIRST LLM USE\n","  - What happens: LLM drafts intake narrative\n","  - Function: call_llm_structured() [Cell 6]\n","  - LLM Task:\n","    - Draft 2-3 paragraph intake narrative\n","    - Identify open questions\n","    - Flag risks\n","    - List assumptions\n","    - Suggest what to verify\n","  - Output: JSON with draft_output, open_questions, risks, etc.\n","\n","\n","**Step 2.3: Parse & Validate LLM Response**\n","  - Actor: HARD-CODED\n","  - What happens: Parse JSON, validate schema, check policies\n","  - Function: parse_with_repair(), validate_exact_schema(), reject_recommendations() [Cell 6]\n","  - Checks:\n","    - Valid JSON?\n","    - Correct schema keys?\n","    - verification_status = \"Not verified\"?\n","    - No recommendation language?\n","    - No hallucinated numbers?\n","  - Output: Validated stage_A output dict\n","\n","\n","**Step 2.4: Save Stage A Output**\n","  - Actor: HARD-CODED\n","  - What happens: Write stage_A.json to disk\n","  - Function: run_controlled_drafting() [Cell 8]\n","  - Output: stage_outputs/{case_name}/stage_A.json\n","\n","\n","**Step 2.5: Update Verification Register**\n","  - Actor: HARD-CODED\n","  - What happens: Extract open_questions and questions_to_verify from LLM output\n","  - Function: build_verification_register_stub() [Cell 7]\n","  - Output: Entry added to verification_register.json\n","\n","\n","**Step 2.6: Log Stage A Gate**\n","  - Actor: HARD-CODED\n","  - What happens: Record stage completion\n","  - Function: log_stage_gate() [Cell 7]\n","  - Output: Entry in stage_gate_log.jsonl\n","  - Gate: \"intake_narrative_drafted\" = \"passed\"\n","\n","\n","STAGE 3: CONTROLLED DRAFTING - STAGE B (DELIVERABLE DRAFT)\n","\n","**Step 3.1: Build Stage B Prompt**\n","  - Actor: HARD-CODED\n","  - What happens: Construct prompt using Stage A output as context\n","  - Function: run_controlled_drafting() [Cell 8]\n","  - Output: Prompt string including Stage A narrative\n","\n","\n","**Step 3.2: Call LLM for Stage B**\n","  - Actor: LLM â† SECOND LLM USE\n","  - What happens: LLM drafts deliverable shell/template\n","  - Function: call_llm_structured() [Cell 6]\n","  - LLM Task:\n","    - Draft deliverable template (memo/workplan/IC shell/RACI)\n","    - Use placeholders for missing facts: [TO BE VERIFIED: ...]\n","    - Identify what information is missing\n","    - Flag risks specific to deliverable\n","  - Output: JSON with draft_output, open_questions, risks, etc.\n","\n","\n","**Step 3.3: Parse & Validate LLM Response**\n","  - Actor: HARD-CODED\n","  - What happens: Same validation as Step 2.3\n","  - Function: parse_with_repair(), validate_exact_schema(), reject_recommendations() [Cell 6]\n","  - Output: Validated stage_B output dict\n","\n","\n","**Step 3.4: Save Stage B Output**\n","  - Actor: HARD-CODED\n","  - What happens: Write stage_B.json to disk\n","  - Function: run_controlled_drafting() [Cell 8]\n","  - Output: stage_outputs/{case_name}/stage_B.json\n","\n","\n","**Step 3.5: Update Verification Register**\n","  - Actor: HARD-CODED\n","  - What happens: Extract open_questions from Stage B\n","  - Function: build_verification_register_stub() [Cell 7]\n","  - Output: Additional entry in verification_register.json\n","\n","\n","**Step 3.6: Log Stage B Gate**\n","  - Actor: HARD-CODED\n","  - What happens: Record stage completion\n","  - Function: log_stage_gate() [Cell 7]\n","  - Output: Entry in stage_gate_log.jsonl\n","  - Gate: \"deliverable_drafted\" = \"passed\"\n","\n","\n","STAGE 4: CONTROLLED DRAFTING - STAGE C (VERIFICATION PLAN)\n","\n","**Step 4.1: Aggregate Open Questions**\n","  - Actor: HARD-CODED\n","  - What happens: Combine open questions from Stages A and B\n","  - Function: run_controlled_drafting() [Cell 8]\n","  - Output: Combined list of all open questions\n","\n","\n","**Step 4.2: Build Stage C Prompt**\n","  - Actor: HARD-CODED\n","  - What happens: Construct prompt with aggregated open questions\n","  - Function: run_controlled_drafting() [Cell 8]\n","  - Output: Prompt string asking for verification plan\n","\n","\n","**Step 4.3: Call LLM for Stage C**\n","  - Actor: LLM â† THIRD LLM USE\n","  - What happens: LLM creates verification plan\n","  - Function: call_llm_structured() [Cell 6]\n","  - LLM Task:\n","    - List what needs verification\n","    - Suggest verification sources\n","    - Prioritize verifications (blockers vs nice-to-have)\n","    - Identify which assumptions need validation\n","  - Output: JSON with verification plan in draft_output\n","\n","\n","**Step 4.4: Parse & Validate LLM Response**\n","  - Actor: HARD-CODED\n","  - What happens: Same validation as Steps 2.3 and 3.3\n","  - Function: parse_with_repair(), validate_exact_schema(), reject_recommendations() [Cell 6]\n","  - Output: Validated stage_C output dict\n","\n","\n","**Step 4.5: Save Stage C Output**\n","  - Actor: HARD-CODED\n","  - What happens: Write stage_C.json to disk\n","  - Function: run_controlled_drafting() [Cell 8]\n","  - Output: stage_outputs/{case_name}/stage_C.json\n","\n","\n","**Step 4.6: Update Verification Register**\n","  - Actor: HARD-CODED\n","  - What happens: Extract verification items from Stage C\n","  - Function: build_verification_register_stub() [Cell 7]\n","  - Output: Final entry in verification_register.json\n","\n","\n","**Step 4.7: Log Stage C Gate**\n","  - Actor: HARD-CODED\n","  - What happens: Record stage completion\n","  - Function: log_stage_gate() [Cell 7]\n","  - Output: Entry in stage_gate_log.jsonl\n","  - Gate: \"verification_plan_drafted\" = \"passed\"\n","\n","\n","STAGE 5: DELIVERABLE BUNDLE CREATION\n","\n","**Step 5.1: Create Bundle Index**\n","  - Actor: HARD-CODED\n","  - What happens: Compile list of artifacts with hashes\n","  - Function: Cell 9 logic\n","  - Output: {case_name}_bundle_index.json\n","\n","\n","**Step 5.2: Create Human-Readable Summary**\n","  - Actor: HARD-CODED\n","  - What happens: Format LLM outputs into readable text file\n","  - Function: Cell 9 logic (string formatting)\n","  - Output: {case_name}_human_readable.txt\n","\n","\n","**Step 5.3: Save to Deliverables**\n","  - Actor: HARD-CODED\n","  - What happens: Write files to deliverables/ directory\n","  - Function: Cell 9 file I/O\n","  - Output: Files in /deliverables/\n","\n","\n","STAGE 6: APPROVAL ROUTING\n","\n","**Step 6.1: Determine Approver Role**\n","  - Actor: HARD-CODED\n","  - What happens: Map risk tier to approver\n","  - Function: Cell 9 logic\n","  - Logic:\n","    - risk_tier = \"low\" â†’ \"Senior Consultant\"\n","    - risk_tier = \"medium\" or \"high\" â†’ \"Partner\"\n","  - Output: approver_role string\n","\n","\n","**Step 6.2: Create Approval Entry**\n","  - Actor: HARD-CODED\n","  - What happens: Create pending approval record\n","  - Function: build_approval_stub() [Cell 7]\n","  - Output: Entry in approvals_log.json with state=\"pending\"\n","\n","\n","**Step 6.3: Human Approver Review**\n","  - Actor: HUMAN â† HUMAN DECISION POINT\n","  - What happens: Human reviews deliverable bundle\n","  - Actions:\n","    - Read human_readable.txt\n","    - Review stage outputs\n","    - Check verification_register.json\n","    - Decide: approve or reject\n","  - Output: approval_status (updated by human, not in this notebook)\n","\n","\n","STAGE 7: QA SAMPLING\n","\n","**Step 7.1: Aggregate Risks**\n","  - Actor: HARD-CODED\n","  - What happens: Collect all risks from Stages A, B, C\n","  - Function: Cell 9 logic\n","  - Output: List of all risk dicts\n","\n","\n","**Step 7.2: Determine Highest Risk Severity**\n","  - Actor: HARD-CODED\n","  - What happens: Find max severity across all risks\n","  - Function: Cell 9 logic\n","  - Logic:\n","    - if any risk.severity == \"high\" â†’ highest_severity = \"high\"\n","    - elif any risk.severity == \"medium\" â†’ highest_severity = \"medium\"\n","    - else â†’ highest_severity = \"low\"\n","  - Output: highest_severity string\n","\n","\n","**Step 7.3: QA Sample Selection Decision**\n","  - Actor: HARD-CODED\n","  - What happens: Decide if this case gets QA review\n","  - Function: Cell 9 conditional logic\n","  - Logic:\n","    - if highest_severity == \"high\" â†’ select for QA\n","    - else â†’ skip QA\n","  - Output: Boolean decision\n","\n","\n","**Step 7.4: Create QA Checklist (if selected)**\n","  - Actor: HARD-CODED\n","  - What happens: Generate QA review checklist\n","  - Function: qa_reviewer_checklist() [Cell 7]\n","  - Output: Checklist with 6 review items, all status=\"pending\"\n","\n","\n","**Step 7.5: Update QA Results**\n","  - Actor: HARD-CODED\n","  - What happens: Add sample to qa_results.json\n","  - Function: update_qa_results() [Cell 7]\n","  - Output: Updated qa_results.json\n","\n","\n","**Step 7.6: Human QA Review**\n","  - Actor: HUMAN â† HUMAN QUALITY CHECK\n","  - What happens: Human QA lead reviews sampled artifact\n","  - Actions:\n","    - Check verification_status = \"Not verified\" âœ“\n","    - Verify open_questions are substantive âœ“\n","    - Confirm no recommendation language âœ“\n","    - Verify numeric claims are sourced âœ“\n","    - Check draft coherence âœ“\n","    - Validate risk identification âœ“\n","  - Output: Completed checklist (updated by human, not in this notebook)\n","\n","\n","STAGE 8: RECORDKEEPING & ARCHIVE\n","\n","**Step 8.1: Create AUDIT_README**\n","  - Actor: HARD-CODED\n","  - What happens: Generate comprehensive audit documentation\n","  - Function: Cell 10\n","  - Output: AUDIT_README.txt (2,000+ words)\n","\n","\n","**Step 8.2: Compute File Hashes**\n","  - Actor: HARD-CODED\n","  - What happens: SHA256 hash all artifacts for integrity verification\n","  - Function: Cell 10, compute_file_hash()\n","  - Output: integrity_summary.json with all file hashes\n","\n","\n","**Step 8.3: Create ZIP Bundle**\n","  - Actor: HARD-CODED\n","  - What happens: Package entire run directory\n","  - Function: Cell 10, shutil.make_archive()\n","  - Output: {run_name}.zip\n","\n","\n","**Step 8.4: Human Archive Review**\n","  - Actor: HUMAN â† HUMAN FINAL REVIEW\n","  - What happens: Human reviews audit bundle before final storage\n","  - Actions:\n","    - Verify all artifacts present\n","    - Check integrity hashes\n","    - Review AUDIT_README\n","    - Confirm compliance requirements met\n","  - Output: Archive approval (external to notebook)\n","\n","\n","SUMMARY: LLM vs HUMAN vs HARD-CODED BY STAGE\n","\n","**Stage 1: Intake & Classification**\n","  - HUMAN: Provides inputs\n","  - HARD-CODED: Redaction, risk tier, controls, logging\n","  - LLM: Not used\n","\n","\n","**Stage 2: Drafting Stage A**\n","  - HARD-CODED: Builds prompt, validates output, saves files, logs gates\n","  - LLM: Drafts intake narrative â† LLM USE #1\n","  - HUMAN: Not involved (yet)\n","\n","\n","**Stage 3: Drafting Stage B**\n","  - HARD-CODED: Builds prompt, validates output, saves files, logs gates\n","  - LLM: Drafts deliverable template â† LLM USE #2\n","  - HUMAN: Not involved (yet)\n","\n","\n","**Stage 4: Drafting Stage C**\n","  - HARD-CODED: Builds prompt, validates output, saves files, logs gates\n","  - LLM: Creates verification plan â† LLM USE #3\n","  - HUMAN: Not involved (yet)\n","\n","\n","**Stage 5: Bundle Creation**\n","  - HARD-CODED: Compiles artifacts, creates summaries\n","  - LLM: Not used\n","  - HUMAN: Not involved (yet)\n","\n","\n","**Stage 6: Approval Routing**\n","  - HARD-CODED: Determines approver, creates pending approval\n","  - LLM: Not used\n","  - HUMAN: Reviews and approves/rejects â† HUMAN DECISION\n","\n","\n","**Stage 7: QA Sampling**\n","  - HARD-CODED: Selects samples, creates checklists\n","  - LLM: Not used\n","  - HUMAN: Completes QA review â† HUMAN QUALITY CHECK\n","\n","\n","**Stage 8: Archive**\n","  - HARD-CODED: Creates README, hashes, ZIP\n","  - LLM: Not used\n","  - HUMAN: Final archive review â† HUMAN FINAL REVIEW\n","\n","\n","TOTAL COUNT\n","\n","**LLM Uses: 3**\n","  - Stage A drafting\n","  - Stage B drafting\n","  - Stage C drafting\n","\n","**Human Decision Points: 3**\n","  - Approval (Stage 6)\n","  - QA Review (Stage 7)\n","  - Archive Review (Stage 8)\n","\n","**Hard-Coded Operations: 30+**\n","  - Everything else (redaction, validation, routing, logging, file I/O)\n","\n","\n","KEY INSIGHT\n","\n","The LLM is used for CONTENT GENERATION (drafting text, identifying gaps).\n","\n","Humans are used for JUDGMENT & DECISIONS (approval, quality checks, final review).\n","\n","Hard-coded logic handles ORGANIZATIONAL PROCESS (routing, controls, logging, gates).\n","\n","This is Level 5: The organization controls the process (hard-coded), uses AI as\n","a tool (LLM), and reserves judgment for humans (decision points)."],"metadata":{"id":"QVHS5lxp4qNi"}},{"cell_type":"code","source":[],"metadata":{"id":"3BdM6IPANlZ-"},"execution_count":null,"outputs":[]}]}